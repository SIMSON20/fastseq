{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# default_exp data.load_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "from fastseq.data.external import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.tabular.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Load Dataframe\n",
    "\n",
    "\n",
    "> Using the fastai2 `Datasets` to make an time series dataset.\n",
    "\n",
    "A multivaraite time-series dataloader. \n",
    "\n",
    "TODO reduce mem: https://forums.fast.ai/t/how-to-handle-dataframes-too-large-to-fit-in-memory/39208/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TSMulti(MultiTuple):pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Transform catagorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorCatI(TensorBase):pass\n",
    "class CatSeqI(TensorSeqs):pass\n",
    "def unpack_list(o, r=None):\n",
    "    r = ifnone(r,L())\n",
    "    for a in o:\n",
    "        if isinstance(a,list) or isinstance(a,L):\n",
    "            r = unpack_list(a, r)\n",
    "        else:\n",
    "            r.append(a)\n",
    "    return r\n",
    "            \n",
    "class CatTfm(Transform):\n",
    "    def __init__(self, df, cat_cols:[]): # maybe change to proccs\n",
    "        self.vocab,self.o2i = {},{}\n",
    "        for i, col in enumerate(L(cat_cols)):\n",
    "            r = unpack_list(list(df[col]))\n",
    "            self.vocab[i], self.o2i[i] = uniqueify(r, sort=True, bidir=True)\n",
    "            \n",
    "    def encodes(self, o:TensorCat):\n",
    "        r = []\n",
    "        for i in self.o2i:\n",
    "            r.append(self.o2i[i][o.o[i]])            \n",
    "        return TensorCatI(r, label = o._meta['label'])\n",
    "    \n",
    "    def decodes(self, o:TensorCatI): \n",
    "        r = []\n",
    "        for i_cat in self.vocab:\n",
    "            r.append(self.vocab[i_cat][o[i_cat]])\n",
    "        return TensorCat(r, label = o._meta.get('label',None))\n",
    "    \n",
    "    def encodes(self, o:CatSeq):\n",
    "        r = []\n",
    "        for i in self.o2i:\n",
    "            r.append([])\n",
    "            for a in o.o[i]:\n",
    "                r[i].append(self.o2i[i][a])            \n",
    "        return CatSeqI(r, label = o._meta['label'])\n",
    "    \n",
    "    def decodes(self, o:CatSeqI):\n",
    "        r = []\n",
    "        for i in self.o2i:\n",
    "            r.append([])\n",
    "            for a in o[i]:\n",
    "                r[i].append(self.vocab[i][a])  \n",
    "        return CatSeq(r, label = o._meta.get('label',None))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'])\n",
    "o_tmf = tmf(TensorCat(['a']))\n",
    "test_eq_type(o_tmf,TensorCatI([0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o_tmf = tmf(TensorCat(['a','b']))\n",
    "test_eq_type(o_tmf,TensorCatI([0,0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a','b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatSeqI([[0, 1, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CatSeq([['a', 'b', 'a', 'a']], label = ['a'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[[i,'a'] for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'])\n",
    "o = CatSeq([['a','b','a','a']], label='a')\n",
    "o_tmf = tmf(o)\n",
    "print(o_tmf)\n",
    "test_eq(o_tmf, TensorCatI([[0, 1, 0, 0]]))\n",
    "test_eq(o_tmf._meta['label'], 'a')\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o,o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatSeqI([[0, 1, 0, 0],\n",
      "        [0, 0, 1, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CatSeq([['a', 'b', 'a', 'a'], ['b', 'b', 'c', 'c']], label = ['a', 'a_2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o = CatSeq([['a','b','a','a'],['b','b','c','c']], label=['a','a_2'])\n",
    "o_tmf = tmf(o)\n",
    "print(o_tmf)\n",
    "test_eq(o_tmf, CatSeqI([[0, 1, 0, 0],\n",
    "                        [0, 0, 1, 1]]))\n",
    "test_eq(o_tmf._meta['label'], ['a','a_2'])\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o,o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TSMulti_(Tuple):pass\n",
    "\n",
    "class CatMultiTfm(ItemTransform):\n",
    "    @delegates(CatTfm.__init__)\n",
    "    def __init__(self, *args, **kwargs): # maybe change to proccs\n",
    "        self.f = CatTfm(*args, **kwargs)\n",
    "        \n",
    "    def encodes(self, o:TSMulti):\n",
    "        return TSMulti_(self.f(a) for a in o)\n",
    "    \n",
    "    def decodes(self, o:TSMulti_): \n",
    "        return TSMulti(self.f.decode(a) for a in o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatMultiTfm: True (TSMulti,object) -> encodes (TSMulti_,object) -> decodes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb']})\n",
    "tmf = CatMultiTfm(df,'a')\n",
    "print(tmf)\n",
    "o = TSMulti(TensorBase([1]), TensorCat('a'))\n",
    "o_tmf = tmf(o)\n",
    "test_eq(o_tmf,(TensorBase([1]), TensorCatI([0])) )\n",
    "o_b =tmf.decode(o_tmf)\n",
    "test_eq(o_b, o)\n",
    "test_eq(type(o_b), type(TSMulti(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>con_ts_1</th>\n",
       "      <th>con_ts_0</th>\n",
       "      <th>cat_ts_1</th>\n",
       "      <th>cat_ts_0</th>\n",
       "      <th>con_0</th>\n",
       "      <th>con_1</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0    -0.397057\n",
       "1     0.742402\n",
       "2     3.338075\n",
       "3     3.981841\n",
       "4     4.482663\n",
       "5     4.539409\n",
       "6     5.740296\n",
       "7     5.815583\n",
       "8     6.786242\n",
       "9    10.698944\n",
       "dtype: float64</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]</td>\n",
       "      <td>[y, z, y, z, y, z, y, z, y, z]</td>\n",
       "      <td>[a, b, a, b, a, b, a, b, a, b]</td>\n",
       "      <td>-0.479305</td>\n",
       "      <td>10.429260</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>0     -2.100359\n",
       "1      0.509973\n",
       "2      3.262948\n",
       "3      3.883042\n",
       "4      4.023184\n",
       "5      3.295666\n",
       "6      5.306996\n",
       "7      7.766818\n",
       "8      6.803480\n",
       "9     10.602652\n",
       "10    10.386768\n",
       "11    12.795048\n",
       "dtype: float64</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]</td>\n",
       "      <td>[y, z, y, z, y, z, y, z, y, z, y, z]</td>\n",
       "      <td>[a, b, a, b, a, b, a, b, a, b, a, b]</td>\n",
       "      <td>-0.631020</td>\n",
       "      <td>11.233439</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0    0.127216\n",
       "1    0.261255\n",
       "2    2.811576\n",
       "3    1.925198\n",
       "4    3.844308\n",
       "5    3.922653\n",
       "dtype: float64</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]</td>\n",
       "      <td>[y, z, y, z, y, z]</td>\n",
       "      <td>[a, b, a, b, a, b]</td>\n",
       "      <td>1.556760</td>\n",
       "      <td>10.280112</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        x  \\\n",
       "0          [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]   \n",
       "2                      [0, 1, 2, 3, 4, 5]   \n",
       "\n",
       "                                                                                                                                                                                                         con_ts_1  \\\n",
       "0                                            0    -0.397057\n",
       "1     0.742402\n",
       "2     3.338075\n",
       "3     3.981841\n",
       "4     4.482663\n",
       "5     4.539409\n",
       "6     5.740296\n",
       "7     5.815583\n",
       "8     6.786242\n",
       "9    10.698944\n",
       "dtype: float64   \n",
       "1  0     -2.100359\n",
       "1      0.509973\n",
       "2      3.262948\n",
       "3      3.883042\n",
       "4      4.023184\n",
       "5      3.295666\n",
       "6      5.306996\n",
       "7      7.766818\n",
       "8      6.803480\n",
       "9     10.602652\n",
       "10    10.386768\n",
       "11    12.795048\n",
       "dtype: float64   \n",
       "2                                                                                                              0    0.127216\n",
       "1    0.261255\n",
       "2    2.811576\n",
       "3    1.925198\n",
       "4    3.844308\n",
       "5    3.922653\n",
       "dtype: float64   \n",
       "\n",
       "                                                         con_ts_0  \\\n",
       "0            [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]   \n",
       "1  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]   \n",
       "2                                [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]   \n",
       "\n",
       "                               cat_ts_1                              cat_ts_0  \\\n",
       "0        [y, z, y, z, y, z, y, z, y, z]        [a, b, a, b, a, b, a, b, a, b]   \n",
       "1  [y, z, y, z, y, z, y, z, y, z, y, z]  [a, b, a, b, a, b, a, b, a, b, a, b]   \n",
       "2                    [y, z, y, z, y, z]                    [a, b, a, b, a, b]   \n",
       "\n",
       "      con_0      con_1 cat_0 cat_1  \n",
       "0 -0.479305  10.429260     a     d  \n",
       "1 -0.631020  11.233439     b     c  \n",
       "2  1.556760  10.280112     a     d  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df(length = [100,120]):\n",
    "    dct = {'x':[],'con_ts_1':[],'con_ts_0':[],'cat_ts_1':[],'cat_ts_0':[],'con_0':[],'con_1':[], 'cat_0':[],'cat_1':[]}\n",
    "    for i, l in enumerate(length):\n",
    "        assert int(l/2) == l/2\n",
    "        dct['x'].append(np.arange(l))\n",
    "        dct['con_ts_0'].append(np.ones(l)[None,:])\n",
    "        dct['con_ts_1'].append(pd.Series(np.arange(l)+np.random.randn(l)))\n",
    "        dct['con_0'].append(np.random.randn())\n",
    "        dct['con_1'].append(10+np.random.randn()*2)\n",
    "        dct['cat_ts_0'].append(L(['a','b']*int(l/2)))\n",
    "        dct['cat_ts_1'].append(L(['y','z']*int(l/2)))\n",
    "        dct['cat_0'].append(['a','b'][i%2])\n",
    "        dct['cat_1'].append(['d','c'][i%2])\n",
    "    return pd.DataFrame(data=dct)\n",
    "df = get_df([10,12,6])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array2series(o):\n",
    "    return pd.Series(o.flatten())\n",
    "def arrays2series(s:pd.Series):\n",
    "    return pd.Series([array2series(o) for o in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'x':  [np.arange(10.),\n",
    "                               np.arange(12.)],\n",
    "                       'ts_0':[np.ones(10)[None,:],\n",
    "                               np.ones(12)[None,:]],\n",
    "                       })\n",
    "df['x'] = arrays2series(df['x'])\n",
    "df['ts_0'] = arrays2series(df['ts_0'])\n",
    "test_eq(type(df['ts_0']), pd.Series)\n",
    "test_eq(type(df['x']), pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "df = pd.DataFrame(data={'x':  [np.arange(10.)]*100,\n",
    "                       'ts_0':[np.ones(10)[None,:]]*100,\n",
    "                       })\n",
    "df['x'] = arrays2series(df['x'])\n",
    "df['ts_0'] = arrays2series(df['ts_0'])\n",
    "test_eq(type(df['ts_0']), pd.Series)\n",
    "test_eq(type(df['x']), pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def reconize_cols(dataset):\n",
    "    con_names, cat_names, con_ts_names, cat_ts_names, classes = L(), L(), L(), L(), {}\n",
    "    for col in dataset.columns:\n",
    "        t = type(dataset[col].iloc[0])\n",
    "        if t is pd.core.series.Series:\n",
    "            con_ts_names.append(col)\n",
    "        elif t is np.ndarray:\n",
    "            o = arrays2series(dataset[col])\n",
    "            dataset[col] = o\n",
    "            con_ts_names.append(col)\n",
    "        elif isinstance(dataset[col].iloc[0], str):\n",
    "            cat_names.append(col)\n",
    "            classes[col] = uniqueify(list(dataset[col].values))\n",
    "        elif isinstance(dataset[col].iloc[0], float) or isinstance(dataset[col].iloc[0], int) or t is np.int64:\n",
    "            con_names.append(col)            \n",
    "        elif isinstance(dataset[col].iloc[0], L) or isinstance(dataset[col].iloc[0],list):\n",
    "            cat_ts_names.append(col)\n",
    "            classes[col] = uniqueify(unpack_list(list(dataset[col])))\n",
    "        else:\n",
    "            raise Exception(t)\n",
    "    return con_names, cat_names, con_ts_names, cat_ts_names, classes, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#2) ['con_0','con_1'],\n",
       " (#2) ['cat_0','cat_1'],\n",
       " (#3) ['x','con_ts_1','con_ts_0'],\n",
       " (#2) ['cat_ts_1','cat_ts_0'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df()\n",
    "con_names, cat_names, con_ts_names, cat_ts_names, classes, dataset = reconize_cols(df)\n",
    "test_eq(con_names, ['con_0','con_1'])\n",
    "test_eq(cat_names, ['cat_0','cat_1'])\n",
    "test_eq(set(con_ts_names), set(['x','con_ts_0','con_ts_1']))\n",
    "test_eq(set(cat_ts_names), set(['cat_ts_0','cat_ts_1']))\n",
    "test_eq(classes, {'cat_ts_0': ['a','b'],\n",
    "                  'cat_ts_1': ['y','z'],\n",
    "                  'cat_0': ['a','b'],\n",
    "                  'cat_1': ['d','c']\n",
    "                 })\n",
    "con_names, cat_names, con_ts_names, cat_ts_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#2) [(#100) ['a','b','a','b','a','b','a','b','a','b'...],(#100) ['y','z','y','z','y','z','y','z','y','z'...]],\n",
       " (#2) [(#120) ['a','b','a','b','a','b','a','b','a','b'...],(#120) ['y','z','y','z','y','z','y','z','y','z'...]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([L([a for a in o]) for o in df[['cat_ts_0','cat_ts_1']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class PrepDF(TabularProc):\n",
    "    def setup(self, dl, train_setup):\n",
    "        # speed up retrival\n",
    "        dl.con = dl.dataset.loc[:,dl.con_names].values.astype(float)\n",
    "        dl.cat = [list(dl.dataset.loc[i,dl.cat_names]) for i in range(dl.dataset.shape[0])]\n",
    "        if len(dl.con_ts_names):\n",
    "            dl.tsx_con = [np.concatenate([o[None,:] for o in dl.dataset.loc[i,dl.con_ts_names].values]) for i in range(dl.dataset.shape[0])]\n",
    "        else:\n",
    "            dl.tsx_con = [np.empty([0,0]) for i in range(dl.dataset.shape[0])]\n",
    "            \n",
    "        if len(dl.cat_ts_names):\n",
    "            dl.tsx_cat = list([L([a for a in o]) for o in df[dl.cat_ts_names].values])\n",
    "        else:\n",
    "            dl.tsx_cat = ['']*dl.dataset.shape[0]   \n",
    "        assert len(dl.cat) == len(dl.tsx_con) == dl.con.shape[0] == len(dl.tsx_cat), f\"{len(dl.cat)} == {len(dl.tsx_con)} == {dl.con.shape[0]} == {len(dl.tsx_cat)}\"\n",
    "        return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#2) [(#100) ['y','z','y','z','y','z','y','z','y','z'...],(#100) ['a','b','a','b','a','b','a','b','a','b'...]],\n",
       " (#2) [(#120) ['y','z','y','z','y','z','y','z','y','z'...],(#120) ['a','b','a','b','a','b','a','b','a','b'...]]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_dl(TfmdDL):    \n",
    "    def __init__(self, dataset:pd.DataFrame, y_name, lookback = 10, horizon=3,step=1,min_seq_len=None):\n",
    "        con_names, cat_names, con_ts_names, cat_ts_names, classes, dataset = reconize_cols(dataset)  \n",
    "        store_attr(self,'lookback,horizon,step,y_name,con_names,cat_names,con_ts_names,cat_ts_names,classes,dataset')     \n",
    "        assert y_name in self.con_ts_names, {k:getattr(self,k) for k in 'con_names,cat_names,con_ts_names,cat_ts_names'.split(',')}\n",
    "        self.con_ts_names.remove(y_name) \n",
    "        PrepDF().setup(self, True)    \n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback)\n",
    "        \n",
    "df = get_df()\n",
    "dl = test_dl(df, 'x')\n",
    "test_eq(dl.cat,[['a', 'd'], ['b', 'c']])\n",
    "test_eq(dl.con.shape,(2,2))\n",
    "test_eq(dl.tsx_con[0].shape, [2,100])\n",
    "test_eq(len(dl.tsx_cat), 2)\n",
    "test_eq(len(dl.tsx_cat[0]), 2)\n",
    "test_eq(len(dl.tsx_cat[0][0]), 100)\n",
    "dl.tsx_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x']\n",
      "['x', 'cat_ts_0']\n",
      "['x', 'con_ts_1']\n",
      "['x', 'cat_1']\n",
      "['x', 'con_0']\n"
     ]
    }
   ],
   "source": [
    "for cols in [['x'],['x','cat_ts_0'],['x','con_ts_1'],['x','cat_1'],['x','con_0']]:\n",
    "    print(cols)\n",
    "    df = get_df()[cols]\n",
    "    dl = test_dl(df, 'x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def same_size_ts(ts:pd.Series, ts_names, _raise = True):\n",
    "    shapes = {k:ts[k].shape if hasattr(ts[k],'shape') else (len(ts[k]),) for k in ts_names}\n",
    "    all_same = [[(shapes[c] == shapes[a]) for c in ts_names] for a in ts_names]\n",
    "    mask = np.array(all_same)\n",
    "    if _raise:\n",
    "        assert np.sum(mask) == len(ts_names)**2, shapes\n",
    "    return np.sum(mask) == len(ts_names)**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df()\n",
    "con_names, cat_names, con_ts_names, cat_ts_names, classes, dataset = reconize_cols(df)\n",
    "same_size_ts(dataset.iloc[0,:], ['x','con_ts_0','con_ts_1','cat_ts_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "df = pd.DataFrame(data={'ts_0':[pd.Series(np.arange(10)),\n",
    "                           pd.Series(np.arange(10))],\n",
    "                   'ts_1':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,12))],\n",
    "                   'var_0':[0.,1.],\n",
    "                   'con_0':[0,1]})\n",
    "for i, row in df.iterrows():\n",
    "    if i == 0:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1'], False),True)\n",
    "    if i == 1:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1'], False),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def make_ids(dl):\n",
    "    \"\"\"Make ids if the sequence is shorter than `min_seq_len`, it will drop that sequence.\"\"\"\n",
    "    # Slice each time series into examples, assigning IDs to each\n",
    "    last_id = 0\n",
    "    n_dropped = 0\n",
    "    n_needs_padding = 0\n",
    "    dl._ids = {}\n",
    "    for i, ts in dl.dataset.iterrows():\n",
    "        same_size_ts(ts, dl.con_ts_names + dl.cat_ts_names)\n",
    "        num_examples = (ts[dl.y_name].shape[-1] - dl.lookback - dl.horizon + dl.step) // dl.step\n",
    "        # Time series shorter than the forecast horizon need to be dropped.\n",
    "        if ts[dl.y_name].shape[-1] < dl.min_seq_len:\n",
    "            n_dropped += 1\n",
    "            continue\n",
    "        # For short time series zero pad the input\n",
    "        if ts[dl.y_name].shape[-1] < dl.lookback + dl.horizon:\n",
    "            n_needs_padding += 1\n",
    "            num_examples = 1\n",
    "        for j in range(num_examples):\n",
    "            dl._ids[last_id + j] = (i, j * dl.step)\n",
    "        last_id += num_examples\n",
    "\n",
    "    # Inform user about time series that were too short\n",
    "    if n_dropped > 0:\n",
    "        print(\"Dropped {}/{} time series due to length.\".format(\n",
    "                n_dropped, len(dl.dataset)))\n",
    "\n",
    "    # Inform user about time series that were short\n",
    "    if n_needs_padding > 0:\n",
    "        print(\"Need to pad {}/{} time series due to length.\".format(\n",
    "                n_needs_padding, len(dl.dataset)))\n",
    "    # Store the number of training examples\n",
    "    dl.n = int(dl._ids.__len__() )\n",
    "    return dl, int(dl._ids.__len__() )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([14,14,16])\n",
    "dl = test_dl(df, 'x', lookback= 10,horizon = 2)\n",
    "dl, n = make_ids(dl)\n",
    "test_eq(dl._ids,{0: (0, 0),\n",
    "                 1: (0, 1),\n",
    "                 2: (0, 2),\n",
    "                 3: (1, 0),\n",
    "                 4: (1, 1),\n",
    "                 5: (1, 2),\n",
    "                 6: (2, 0),\n",
    "                 7: (2, 1),\n",
    "                 8: (2, 2),\n",
    "                 9: (2, 3),\n",
    "                 10: (2, 4)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x, lookback_id, length, pad=np.mean, t = tensor, **kwargs):\n",
    "#     if len(x.shape) == 1:\n",
    "#         x = x[None,:]\n",
    "#     if isinstance(x[0,0],int):\n",
    "#         x = x.astype(float)\n",
    "    if x.shape[-1] < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = pad(x, -1)\n",
    "        x = t(np.pad(\n",
    "            x, # report issue https://github.com/numpy/numpy/issues/15606\n",
    "            pad_width=((0, 0), (length - x.shape[-1], 0)),\n",
    "            mode='constant',\n",
    "            constant_values=padding\n",
    "        ), **kwargs).float()\n",
    "        assert x.shape == (x.shape[0],length), f\"{x.shape}\\t,{lookback_id}, 'tsshape':{x.shape}\"\n",
    "    else:\n",
    "        x = t(x[:,lookback_id:lookback_id + length], **kwargs).float()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = np.vstack([np.arange(10.)]*2)\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.cat([torch.arange(2,7.)[None,:]]*2))\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                          [4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))\n",
    "\n",
    "# report issue https://github.com/numpy/numpy/issues/15606\n",
    "x = np.arange(10.)[None,:]\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "x = np.arange(10.)[None,:]\n",
    "o =get_part_of_ts(x, 0, 11, t = TensorBase, label='a')\n",
    "test_eq_type(o, TensorBase([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])) \n",
    "test_eq(o._meta, {'label':'a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x:L, lookback_id, length, t = L, **kwargs):\n",
    "    if len(x[0]) < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = [o[-1] for o in x]\n",
    "        pad_len = length - len(x[0])\n",
    "        x = t(L(o[lookback_id:lookback_id + length] + [padding[i]]*pad_len) for i,o in enumerate(x))\n",
    "    else:\n",
    "        x = t([o[lookback_id:lookback_id + length] for o in x], **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*5,['z','x']*5)\n",
    "o =get_part_of_ts(x, 1, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*2, ['z','x']*2)\n",
    "o =get_part_of_ts(x, 0, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "def get_id(dl, ts_id, lookback_id):\n",
    "    y = get_part_of_ts(dl.dataset.loc[ts_id, dl.y_name].values[None,:], lookback_id, dl.lookback + dl.horizon,\n",
    "                       t = TensorSeqs, label=[dl.y_name + '_y'], m=['g'])\n",
    "    x = TensorSeqs(y[:,:dl.lookback], label=[dl.y_name + '_x'], m=['g'])\n",
    "    if len(dl.con_ts_names):\n",
    "        tsx_con = get_part_of_ts(dl.tsx_con[ts_id], lookback_id, dl.lookback + dl.horizon,\n",
    "                             t = TensorSeqs, label=dl.con_ts_names)\n",
    "    else: tsx_con = TensorSeqs(np.empty([0]), label=dl.con_ts_names)\n",
    "    if len(dl.cat_ts_names):\n",
    "        tsx_cat = get_part_of_ts(dl.tsx_cat[ts_id], lookback_id, dl.lookback + dl.horizon,\n",
    "                             t = CatSeq, label=dl.cat_ts_names)\n",
    "    else: tsx_cat = CatSeq('', label=dl.cat_ts_names)\n",
    "        \n",
    "    r = [x, tsx_con, tsx_cat]\n",
    "    r.append(TensorCat(dl.cat[ts_id], label=dl.cat_names))\n",
    "    r.append(TensorCon(dl.con[ts_id,:], label=dl.con_names))      \n",
    "    r.append(y)\n",
    "    return tuple(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSeqs([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " TensorSeqs([[ 0.7595, -0.2018,  3.6567,  3.9557,  2.3628,  4.5180,  5.8373,  7.1024,\n",
       "           7.2677,  7.7250,  9.2480, 10.4108],\n",
       "         [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "           1.0000,  1.0000,  1.0000,  1.0000]]),\n",
       " CatSeq([(#12) ['y','z','y','z','y','z','y','z','y','z'...], (#12) ['a','b','a','b','a','b','a','b','a','b'...]], label = ['cat_ts_1', 'cat_ts_0']),\n",
       " TensorCat(['a', 'd'], label = ['cat_0', 'cat_1']),\n",
       " TensorCon([1.1779, 9.2421]),\n",
       " TensorSeqs([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df([14,14,16])\n",
    "dl = test_dl(df, 'x', lookback= 10,horizon = 2)\n",
    "dl, n = make_ids(dl)\n",
    "for k, (ts_id, lookback_id) in dl._ids.items():\n",
    "    r = get_id(dl, ts_id, lookback_id)\n",
    "    break\n",
    "r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TfmDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates()\n",
    "class DfDataLoader(TfmdDL):\n",
    "    def __init__(self, dataset:pd.DataFrame, y_name:str, horizon:int, lookback=72, step=1,\n",
    "                 min_seq_len=None, procs = None, train = True, **kwargs):\n",
    "        con_names, cat_names, con_ts_names, cat_ts_names, classes, dataset = reconize_cols(dataset)  \n",
    "        store_attr(self,'horizon,lookback,step,y_name,con_names,cat_names,con_ts_names,cat_ts_names,classes,dataset')     \n",
    "        assert y_name in self.con_ts_names, {k:getattr(self,k) for k in 'con_names,cat_names,con_ts_names,cat_ts_names'.split(',')}\n",
    "        self.con_ts_names.remove(y_name)         \n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback)\n",
    "        self, n = make_ids(self)\n",
    "        kwargs['after_item'] = kwargs.get('after_item', CatMultiTfm(dataset, self.cat_names+self.cat_ts_names))\n",
    "        super().__init__(dataset=self.dataset, **kwargs)\n",
    "        self.n = n\n",
    "        self.procs = Pipeline(PrepDF() +L(procs), as_item=True)\n",
    "        self.procs.setup(self, train)            \n",
    "\n",
    "    @delegates(TfmdDL.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        for k,v in {k:getattr(self,k) for k in ['horizon', 'lookback', 'step']}.items():\n",
    "            if k not in kwargs:\n",
    "                kwargs[k] = v\n",
    "        res = super().new(dataset = dataset,cls= cls, y_name= self.y_name, **kwargs)\n",
    "        res, n = make_ids(res)\n",
    "        res.n = n\n",
    "        return res    \n",
    "    \n",
    "    def create_item(self, idx):\n",
    "        if idx>=self.n:\n",
    "            raise IndexError\n",
    "        ts_id, lookback_id = self._ids[idx]\n",
    "        r  = get_id(self, ts_id, lookback_id) \n",
    "        return TSMulti(r)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The data will be stored in pandas DataFrames. This can be use for time series by nesting series into a cell. An example is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 020_data.load_pd.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 030_data.core_pd.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 050_nbeats.models_multi.ipynb.\n",
      "Converted 05_nbeats.models.ipynb.\n",
      "Converted 06_nbeats.callbacks.ipynb.\n",
      "Converted 07_nbeats.learner.ipynb.\n",
      "Converted 08_nbeats.interpret.ipynb.\n",
      "Converted 11_metrics.ipynb.\n",
      "Converted 12_compare.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tab.model.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 020_data.load_pd.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/tako/dev/fastseq/fastseq/data/load_pd.py',\n",
       " '/home/tako/dev/fastseq/nbs/020_data.load_pd.ipynb']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_add('020_data.load_pd.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
