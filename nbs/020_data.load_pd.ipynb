{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.load_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "from fastseq.data.external import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.tabular.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "\n",
    "> Using the fastai2 `Datasets` to make an time series dataset.\n",
    "\n",
    "For now all is univerable but in the future I would also like to add multiplevariable. \n",
    "\n",
    "TODO reduce mem: https://forums.fast.ai/t/how-to-handle-dataframes-too-large-to-fit-in-memory/39208/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "types = {pd.core.series.Series:'ts',}\n",
    "@delegates()\n",
    "class DfDataLoader(TfmdDL):\n",
    "    def __init__(self, dataset:pd.DataFrame, y_name, horizon, lookback=72, step=1, min_seq_len=None, max_std= 2, norm=True, **kwargs):\n",
    "        store_attr(self,'horizon,lookback,step,max_std,norm,y_name')\n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback)\n",
    "        self.dataset = dataset\n",
    "        self.con_names, self.cat_names, self.ts_names = L(), L(), L()\n",
    "        for col in dataset.columns:\n",
    "            t = type(dataset[col].iloc[0])\n",
    "            print(t)\n",
    "            if t is pd.core.series.Series:\n",
    "                self.ts_names.append(col)\n",
    "            elif isinstance(dataset[col].iloc[0], int) or t is np.int64:\n",
    "                self.con_names.append(col)\n",
    "            elif isinstance(dataset[col].iloc[0], float):\n",
    "                self.con_names.append(col)\n",
    "            else:\n",
    "                raise Exception(t) \n",
    "        assert y_name in self.ts_names\n",
    "        n = self.make_ids()\n",
    "        super().__init__(dataset=self.dataset, **kwargs)\n",
    "        self.n = n\n",
    "        self.skipped= []\n",
    "        self.ms = {}\n",
    "\n",
    "    @delegates(TfmdDL.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        res = super().new(dataset, cls, horizon=self.horizon, lookback=self.lookback, step=self.step , **kwargs)\n",
    "        res.make_ids()\n",
    "        return res\n",
    "\n",
    "    def make_ids(self):\n",
    "        \"\"\"Make ids if the sequence is shorter than `min_seq_len`, it will drop that sequence.\"\"\"\n",
    "        # Slice each time series into examples, assigning IDs to each\n",
    "        last_id = 0\n",
    "        n_dropped = 0\n",
    "        n_needs_padding = 0\n",
    "        self._ids = {}\n",
    "        for i, ts in self.dataset.iterrows(): \n",
    "            assert same_size_ts(ts, self.ts_names), f\"row {i} are not all the time series the same length\"\n",
    "            num_examples = (ts[self.y_name].shape[-1] - self.lookback - self.horizon + self.step) // self.step\n",
    "            # Time series shorter than the forecast horizon need to be dropped.\n",
    "            if ts[self.y_name].shape[-1] < self.min_seq_len:\n",
    "                n_dropped += 1\n",
    "                continue\n",
    "            # For short time series zero pad the input\n",
    "            if ts[self.y_name].shape[-1] < self.lookback + self.horizon:\n",
    "                n_needs_padding += 1\n",
    "                num_examples = 1\n",
    "            for j in range(num_examples):\n",
    "                self._ids[last_id + j] = (i, j * self.step)\n",
    "            last_id += num_examples\n",
    "\n",
    "        # Inform user about time series that were too short\n",
    "        if n_dropped > 0:\n",
    "            print(\"Dropped {}/{} time series due to length.\".format(\n",
    "                    n_dropped, len(self.dataset)))\n",
    "\n",
    "        # Inform user about time series that were short\n",
    "        if n_needs_padding > 0:\n",
    "            print(\"Need to pad {}/{} time series due to length.\".format(\n",
    "                    n_needs_padding, len(self.dataset)))\n",
    "        # Store the number of training examples\n",
    "        return int(self._ids.__len__() )\n",
    "#         def shuffle_fn(self, idxs):\n",
    "# #         self.dataset.shuffle()        \n",
    "#         return idxs\n",
    "\n",
    "#     def get_id(self, idx):\n",
    "#         # Get time series\n",
    "#         ts_id, lookback_id = self._ids[idx]\n",
    "#         ts = self.dataset[ts_id]\n",
    "#         if isinstance(ts,tuple):\n",
    "#             ts = ts[0] # no idea why they become tuples\n",
    "#         # Prepare input and target. Zero pad if necessary.\n",
    "#         if ts.shape[-1] < self.lookback + self.horizon:\n",
    "#             # If the time series is too short, we zero pad\n",
    "#             x = ts[:, :-self.horizon]\n",
    "#             mean = x.mean()\n",
    "#             x = tensor(np.pad(\n",
    "#                 x,\n",
    "#                 pad_width=((0, 0), (self.lookback - x.shape[-1], 0)),\n",
    "#                 mode='constant',\n",
    "#                 constant_values=mean\n",
    "#             ))\n",
    "#             y = ts[:,-self.lookback + self.horizon:]\n",
    "#             y = tensor(np.pad(\n",
    "#                 y,\n",
    "#                 pad_width=((0, 0), (self.lookback + self.horizon - y.shape[-1], 0)),\n",
    "#                 mode='constant',\n",
    "#                 constant_values=mean\n",
    "#             ))\n",
    "#             assert y.shape == (1,self.lookback+self.horizon), f\"{y.shape}\\t,{idx}, , 'tsshape':{ts.shape},'ts_id':{ts_id}\"\n",
    "#         else:\n",
    "#             x = ts[:,lookback_id:lookback_id + self.lookback]\n",
    "#             y = ts[:,lookback_id:lookback_id + self.lookback + self.horizon]\n",
    "#         return x, y\n",
    "\n",
    "#     def create_item(self, idx):\n",
    "#         if idx>=self.n:\n",
    "#             raise IndexError\n",
    "#         x, y  = self.get_id(idx)\n",
    "#         if self.norm:\n",
    "#             x, y = self.normalize(x,y,idx)\n",
    "#         if (y/(x.std()+1e-7)).std() > self.max_std:\n",
    "#             if idx not in self.skipped:\n",
    "# #                 print(f\"idx: {idx};y.std to high: {(y/x.std()).std()} > {self.max_std}\")\n",
    "#                 self.skipped.append(idx)\n",
    "#             raise SkipItemException()\n",
    "\n",
    "#         return TSTensorSeq(x),TSTensorSeqy(y)\n",
    "\n",
    "#     def normalize(self, x, y, idx, eps = 1e-7):\n",
    "#         m, s = torch.mean(x,-1,keepdim=True), torch.std(x, -1,keepdim=True) + eps\n",
    "#         self.ms[idx] = (m,s)\n",
    "#         return (x-m)/s, (y-m)/s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be stored in pandas DataFrames. This can be use for time series by nesting series into a cell. An example is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_0</th>\n",
       "      <th>ts_1</th>\n",
       "      <th>var_0</th>\n",
       "      <th>con_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "9    9\n",
       "dtype: int64</td>\n",
       "      <td>0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "5      5\n",
       "6      6\n",
       "7      7\n",
       "8      8\n",
       "9      9\n",
       "10    10\n",
       "11    11\n",
       "dtype: int64</td>\n",
       "      <td>0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       ts_0  \\\n",
       "0                                        0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "9    9\n",
       "dtype: int64   \n",
       "1  0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "5      5\n",
       "6      6\n",
       "7      7\n",
       "8      8\n",
       "9      9\n",
       "10    10\n",
       "11    11\n",
       "dtype: int64   \n",
       "\n",
       "                                                                                                                       ts_1  \\\n",
       "0                              0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64   \n",
       "1  0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64   \n",
       "\n",
       "   var_0  con_0  \n",
       "0    0.0      0  \n",
       "1    1.0      1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'ts_0':[pd.Series(np.arange(10)),\n",
    "                           pd.Series(np.arange(12))],\n",
    "                   'ts_1':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,13))],\n",
    "                   'var_0':[0.,1.],\n",
    "                   'con_0':[0,1]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "Need to pad 1/2 time series due to length.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# basic test\n",
    "horizon,lookback = 2,9\n",
    "dl = DfDataLoader(df,'ts_0', horizon = horizon, lookback = lookback)\n",
    "test_eq(len(dl._ids), 3)\n",
    "\n",
    "# test_eq(len([o for o in dl]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import List\n",
    "def same_size_ts(ts:pd.Series, ts_names:List[str]):    \n",
    "    all_same = [[(ts[c].shape == ts[a].shape) for c in ts_names] for a in ts_names]\n",
    "    mask = np.array(all_same)    \n",
    "    return np.sum(mask) == len(ts_names)**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'ts_0':[pd.Series(np.arange(10)),\n",
    "                           pd.Series(np.arange(10))],\n",
    "                   'ts_1':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,12))],\n",
    "                   'var_0':[0.,1.],\n",
    "                   'con_0':[0,1]})\n",
    "for i, row in df.iterrows():\n",
    "    if i == 0:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1']),True)\n",
    "    if i == 1:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1']),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 020_data.load_pd.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 05_nbeats.models.ipynb.\n",
      "Converted 06_nbeats.callbacks.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
