{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.load_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "from fastseq.data.external import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.tabular.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "\n",
    "> Using the fastai2 `Datasets` to make an time series dataset.\n",
    "\n",
    "A multivaraite time-series dataloader. \n",
    "\n",
    "TODO reduce mem: https://forums.fast.ai/t/how-to-handle-dataframes-too-large-to-fit-in-memory/39208/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5, 0. , 1. , 2. , 3. , 4. , 5. , 6. , 7. , 8. , 9. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)[None,:].astype(float)\n",
    "\n",
    "a = np.pad(a, pad_width=[(0,0),(1,0)], mode='constant', constant_values = 4.5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import List\n",
    "def same_size_ts(ts:pd.Series, ts_names:List[str]):    \n",
    "    all_same = [[(ts[c].shape == ts[a].shape) for c in ts_names] for a in ts_names]\n",
    "    mask = np.array(all_same)    \n",
    "    return np.sum(mask) == len(ts_names)**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'ts_0':[pd.Series(np.arange(10)),\n",
    "                           pd.Series(np.arange(10))],\n",
    "                   'ts_1':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,12))],\n",
    "                   'var_0':[0.,1.],\n",
    "                   'con_0':[0,1]})\n",
    "for i, row in df.iterrows():\n",
    "    if i == 0:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1']),True)\n",
    "    if i == 1:\n",
    "        test_eq(same_size_ts(row,['ts_0','ts_1']),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_part_of_ts(x, lookback_id, length, pad=np.mean):\n",
    "    if len(x.shape) == 1:\n",
    "        x = x[None,:]\n",
    "    if isinstance(x[0,0],int):\n",
    "        x = x.astype(float)\n",
    "    if x.shape[-1] < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = pad(x, -1)\n",
    "        x = tensor(np.pad(\n",
    "            x, # report issue https://github.com/numpy/numpy/issues/15606\n",
    "            pad_width=((0, 0), (length - x.shape[-1], 0)),\n",
    "            mode='constant',\n",
    "            constant_values=padding\n",
    "        )).float()\n",
    "        assert x.shape == (x.shape[0],length), f\"{x.shape}\\t,{lookback_id}, 'tsshape':{x.shape}\"\n",
    "    else:\n",
    "        x = tensor(x[:,lookback_id:lookback_id + length]).float()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.arange(2,7.)[None,:])\n",
    "x = np.arange(10)[None,:]\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.arange(2,7.)[None,:])\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4., 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))\n",
    "x = np.vstack([np.arange(10)]*2)\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.cat([torch.arange(2,7.)[None,:]]*2))\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4., 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                          [4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))\n",
    "\n",
    "# report issue https://github.com/numpy/numpy/issues/15606\n",
    "x = np.arange(10)[None,:]\n",
    "# test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates()\n",
    "class DfDataLoader(TfmdDL):\n",
    "    def __init__(self, dataset:pd.DataFrame, y_name, horizon, lookback=72, step=1, min_seq_len=None, max_std= 2, norm=True, **kwargs):\n",
    "        store_attr(self,'horizon,lookback,step,max_std,norm,y_name')\n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback)\n",
    "        self.dataset = dataset\n",
    "        self.con_names, self.cat_names, self.ts_names = L(), L(), L()\n",
    "        for col in dataset.columns:\n",
    "            t = type(dataset[col].iloc[0])\n",
    "            if t is pd.core.series.Series:\n",
    "                self.ts_names.append(col)\n",
    "            elif isinstance(dataset[col].iloc[0], int) or t is np.int64:\n",
    "                self.con_names.append(col)\n",
    "            elif isinstance(dataset[col].iloc[0], float):\n",
    "                self.cat_names.append(col)\n",
    "            else:\n",
    "                raise Exception(t) \n",
    "        assert y_name in self.ts_names\n",
    "        self.ts_names.remove(y_name)\n",
    "        n = self.make_ids()\n",
    "        super().__init__(dataset=self.dataset, **kwargs)\n",
    "        self.n = n\n",
    "        self.skipped= []\n",
    "        self.ms = {}\n",
    "\n",
    "    @delegates(TfmdDL.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        res = super().new(dataset, cls, horizon=self.horizon, lookback=self.lookback, step=self.step , **kwargs)\n",
    "        res.make_ids()\n",
    "        return res\n",
    "\n",
    "    def make_ids(self):\n",
    "        \"\"\"Make ids if the sequence is shorter than `min_seq_len`, it will drop that sequence.\"\"\"\n",
    "        # Slice each time series into examples, assigning IDs to each\n",
    "        last_id = 0\n",
    "        n_dropped = 0\n",
    "        n_needs_padding = 0\n",
    "        self._ids = {}\n",
    "        for i, ts in self.dataset.iterrows(): \n",
    "            assert same_size_ts(ts, self.ts_names), f\"row {i} are not all the time series the same length\"\n",
    "            num_examples = (ts[self.y_name].shape[-1] - self.lookback - self.horizon + self.step) // self.step\n",
    "            # Time series shorter than the forecast horizon need to be dropped.\n",
    "            if ts[self.y_name].shape[-1] < self.min_seq_len:\n",
    "                n_dropped += 1\n",
    "                continue\n",
    "            # For short time series zero pad the input\n",
    "            if ts[self.y_name].shape[-1] < self.lookback + self.horizon:\n",
    "                n_needs_padding += 1\n",
    "                num_examples = 1\n",
    "            for j in range(num_examples):\n",
    "                self._ids[last_id + j] = (i, j * self.step)\n",
    "            last_id += num_examples\n",
    "\n",
    "        # Inform user about time series that were too short\n",
    "        if n_dropped > 0:\n",
    "            print(\"Dropped {}/{} time series due to length.\".format(\n",
    "                    n_dropped, len(self.dataset)))\n",
    "\n",
    "        # Inform user about time series that were short\n",
    "        if n_needs_padding > 0:\n",
    "            print(\"Need to pad {}/{} time series due to length.\".format(\n",
    "                    n_needs_padding, len(self.dataset)))\n",
    "        # Store the number of training examples\n",
    "        return int(self._ids.__len__() )\n",
    "    \n",
    "        def shuffle_fn(self, idxs):\n",
    "#         self.dataset.shuffle()        \n",
    "            return idxs\n",
    "\n",
    "    def get_id(self, idx):\n",
    "        ts_id, lookback_id = self._ids[idx]\n",
    "        row = self.dataset.iloc[ts_id, :]\n",
    "        x = get_part_of_ts(row[self.y_name].values, lookback_id, self.lookback)        \n",
    "        y = get_part_of_ts(row[self.y_name].values, lookback_id, self.lookback + self.horizon)\n",
    "        tsx = np.concatenate([o[None,:] for o in row[self.ts_names].to_numpy()])\n",
    "        tsx = get_part_of_ts(tsx, lookback_id, self.lookback + self.horizon)\n",
    "        cat, con = row[self.cat_names].to_numpy().astype(int), row[self.con_names].to_numpy().astype(float)\n",
    "        return x, tsx, cat, con, y\n",
    "\n",
    "    def create_item(self, idx):\n",
    "        if idx>=self.n:\n",
    "            raise IndexError\n",
    "        x, tsx, cat, con, y  = self.get_id(idx)\n",
    "        if (y/(x.std()+1e-7)).std() > self.max_std:\n",
    "            if idx not in self.skipped:\n",
    "#                 print(f\"idx: {idx};y.std to high: {(y/x.std()).std()} > {self.max_std}\")\n",
    "                self.skipped.append(idx)\n",
    "            raise SkipItemException()\n",
    "        \n",
    "#         print({k:(o,o.dtype,o.shape) for k,o in zip(['x','tsx','cat','con','y'],[x,tsx,cat,con,y])})        \n",
    "        return TSTensorSeq(x),TSTensorSeq(tsx), tensor(cat).long(), tensor(con),TSTensorSeqy(y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be stored in pandas DataFrames. This can be use for time series by nesting series into a cell. An example is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>ts_0</th>\n",
       "      <th>ts_1</th>\n",
       "      <th>var_0</th>\n",
       "      <th>con_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "9    9\n",
       "dtype: int64</td>\n",
       "      <td>0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64</td>\n",
       "      <td>0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "5      5\n",
       "6      6\n",
       "7      7\n",
       "8      8\n",
       "9      9\n",
       "10    10\n",
       "11    11\n",
       "dtype: int64</td>\n",
       "      <td>0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64</td>\n",
       "      <td>0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       pred  \\\n",
       "0                                        0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "9    9\n",
       "dtype: int64   \n",
       "1  0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "5      5\n",
       "6      6\n",
       "7      7\n",
       "8      8\n",
       "9      9\n",
       "10    10\n",
       "11    11\n",
       "dtype: int64   \n",
       "\n",
       "                                                                                                                       ts_0  \\\n",
       "0                              0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64   \n",
       "1  0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64   \n",
       "\n",
       "                                                                                                                       ts_1  \\\n",
       "0                              0     1\n",
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "dtype: int64   \n",
       "1  0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "5      6\n",
       "6      7\n",
       "7      8\n",
       "8      9\n",
       "9     10\n",
       "10    11\n",
       "11    12\n",
       "dtype: int64   \n",
       "\n",
       "   var_0  con_0  \n",
       "0    0.0      0  \n",
       "1    1.0      1  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'pred':[pd.Series(np.arange(10)),\n",
    "                           pd.Series(np.arange(12))],\n",
    "                   'ts_0':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,13))],\n",
    "                   'ts_1':[pd.Series(np.arange(1,11)),\n",
    "                           pd.Series(np.arange(1,13))],\n",
    "                   'var_0':[0.,1.],\n",
    "                   'con_0':[0,1]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to pad 1/2 time series due to length.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# basic test\n",
    "horizon,lookback = 2,9\n",
    "dl = DfDataLoader(df,'ts_0', horizon = horizon, lookback = lookback)\n",
    "test_eq(len(dl._ids), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': torch.Size([3, 1, 9]), 'tsx': torch.Size([3, 2, 11]), 'cat': torch.Size([3, 1]), 'con': torch.Size([3, 1]), 'y': torch.Size([3, 1, 11])}\n"
     ]
    }
   ],
   "source": [
    "for o in dl:\n",
    "    dct = {k:v for k,v in zip(['x','tsx','cat','con','y'],o)}\n",
    "    print({k:v.shape for k,v in dct.items()})\n",
    "    test_eq(dct['x'].shape,(3,1,9))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 020_data.load_pd.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 05_nbeats.models.ipynb.\n",
      "Converted 06_nbeats.callbacks.ipynb.\n",
      "Converted 07_nbeats.learner.ipynb.\n",
      "Converted 08_nbeats.interpret.ipynb.\n",
      "Converted 11_metrics.ipynb.\n",
      "Converted 12_compare.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
