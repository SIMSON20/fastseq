{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Metrics to evaluate time-series.\n",
    "\n",
    "Mostly copied from <https://github.com/MSRDL/Deep4Cast>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def mape(data_samples, data_truth, agg=None, **kwargs) -> np.array:\n",
    "    \"\"\"Computes mean absolute percentage error (MAPE)\n",
    "    Arguments:\n",
    "        * data_samples (``np.array``): Sampled predictions (n_samples, n_timeseries, n_variables, n_timesteps).\n",
    "        * data_truth (``np.array``): Ground truth time series values (n_timeseries, n_variables, n_timesteps).\n",
    "        * agg: Aggregation function applied to sampled predictions (defaults to ``np.median``).\n",
    "    \"\"\"\n",
    "    if data_samples.shape[1:] != data_truth.shape:\n",
    "        raise ValueError('Last three dimensions of data_samples and data_truth need to be compatible')\n",
    "    agg = np.median if not agg else agg\n",
    "\n",
    "    # Aggregate over samples\n",
    "    data = agg(data_samples, axis=0)\n",
    "    \n",
    "    norm = np.abs(data_truth)\n",
    "\n",
    "    return np.mean(np.abs(data - data_truth) / norm, axis=(1, 2)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _smape(data_samples, data_truth, agg=None, **kwargs) -> np.array:\n",
    "    \"\"\"Computes symmetric mean absolute percentage error (SMAPE) on the mean\n",
    "    \n",
    "    Arguments:\n",
    "        * data_samples (``np.array``): Sampled predictions (n_samples, n_timeseries, n_variables, n_timesteps).\n",
    "        * data_truth (``np.array``): Ground truth time series values (n_timeseries, n_variables, n_timesteps).\n",
    "        * agg: Aggregation function applied to sampled predictions (defaults to ``np.median``).\n",
    "    \"\"\"\n",
    "    if data_samples.shape[1:] != data_truth.shape:\n",
    "        raise ValueError('Last three dimensions of data_samples and data_truth need to be compatible')\n",
    "    agg = np.median if not agg else agg\n",
    "\n",
    "    # Aggregate over samples\n",
    "    data = agg(data_samples, axis=0)\n",
    "\n",
    "    eps = 1e-16  # Need to make sure that denominator is not zero\n",
    "    norm = 0.5 * (np.abs(data) + np.abs(data_truth)) + eps\n",
    "\n",
    "    return np.mean(np.abs(data - data_truth) / norm, axis=(1, 2)) * 100\n",
    "\n",
    "def smape(pred, truth, agg=None, **kwargs) -> np.array:\n",
    "    \"\"\"Computes symmetric mean absolute percentage error (SMAPE) on the mean\n",
    "    \n",
    "    Arguments:\n",
    "        * data_samples (``np.array``): Sampled predictions (n_timeseries, n_variables, n_timesteps).\n",
    "        * data_truth (``np.array``): Ground truth time series values (n_timeseries, n_variables, n_timesteps).\n",
    "        * agg: Aggregation function applied to sampled predictions (defaults to ``np.median``).\n",
    "    \"\"\"\n",
    "    if len(pred.shape)==4:\n",
    "        agg = np.median if not agg else agg\n",
    "        # Aggregate over samples\n",
    "        pred = agg(pred, axis=0)\n",
    "        \n",
    "    if pred.shape != truth.shape:\n",
    "        raise ValueError('Last three dimensions of data_samples and data_truth need to be compatible')\n",
    "        \n",
    "    eps = 1e-16  # Need to make sure that denominator is not zero\n",
    "    norm = 0.5 * (np.abs(pred) + np.abs(truth)) + eps\n",
    "\n",
    "    return np.mean(np.abs(pred - truth) / norm, axis=(1, 2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_hat = np.random.rand(10,10,10,12)*.7+.1,np.random.rand(10,10,12)*.8+.05\n",
    "test_eq(_smape(y,y_hat),smape(y,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I'm only going to bother with `smape` or `mape`. Maybe later also look at `mase`. It is an intressting metric but requires better DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _mase(data_samples, \n",
    "         data_truth, \n",
    "         data_insample, \n",
    "         frequencies, \n",
    "         agg=None,\n",
    "         **kwargs) -> np.array:\n",
    "    \"\"\"Computes mean absolute scaled error (MASE) as in the `M4 competition\n",
    "    <https://www.m4.unic.ac.cy/wp-content/uploads/2018/03/M4-Competitors-Guide.pdf>`_.\n",
    "    Arguments:\n",
    "        * data_samples (``np.array``): Sampled predictions (n_samples, n_timeseries, n_variables, n_timesteps).\n",
    "        * data_truth (``np.array``): Ground truth time series values (n_timeseries, n_variables, n_timesteps).\n",
    "        * data_insample (``np.array``): In-sample time series data (n_timeseries, n_variables, n_timesteps).\n",
    "        * frequencies (list): Frequencies to be used when calculating the naive forecast.\n",
    "        * agg: Aggregation function applied to sampled predictions (defaults to ``np.median``).\n",
    "    \"\"\"\n",
    "    if data_samples.shape[1:] != data_truth.shape:\n",
    "        raise ValueError('Last three dimensions of data_samples and data_truth need to be compatible')\n",
    "    agg = np.median if not agg else agg\n",
    "\n",
    "    # Calculate mean absolute for forecast and naive forecast per time series\n",
    "    errs, naive_errs = [], []\n",
    "    for i in range(data_samples.shape[1]):\n",
    "        ts_sample = data_samples[:, i]\n",
    "        ts_truth = data_truth[i]\n",
    "        ts = data_insample[i]\n",
    "        freq = int(frequencies[i])\n",
    "\n",
    "        data = agg(ts_sample, axis=0)\n",
    "\n",
    "        # Build mean absolute error\n",
    "        err = np.mean(np.abs(data - ts_truth))\n",
    "\n",
    "        # naive forecast is calculated using insample\n",
    "        t_in = ts.shape[-1]\n",
    "        naive_forecast = ts[:, :t_in-freq]\n",
    "        naive_target = ts[:, freq:]\n",
    "        err_naive = np.mean(np.abs(naive_target - naive_forecast))\n",
    "\n",
    "        errs.append(err)\n",
    "        naive_errs.append(err_naive)\n",
    "    \n",
    "    errs = np.array(errs)\n",
    "    naive_errs = np.array(naive_errs)\n",
    "\n",
    "    return errs / naive_errs\n",
    "\n",
    "def mase(data_samples, \n",
    "         data_truth, \n",
    "         data_insample, \n",
    "         frequencies, \n",
    "         agg=None,\n",
    "         **kwargs) -> np.array:\n",
    "    \"\"\"Computes mean absolute scaled error (MASE) as in the `M4 competition\n",
    "    <https://www.m4.unic.ac.cy/wp-content/uploads/2018/03/M4-Competitors-Guide.pdf>`_.\n",
    "    Arguments:\n",
    "        * data_samples (``np.array``): Sampled predictions (n_samples, n_timeseries, n_variables, n_timesteps).\n",
    "        * data_truth (``np.array``): Ground truth time series values (n_timeseries, n_variables, n_timesteps).\n",
    "        * data_insample (``np.array``): In-sample time series data (n_timeseries, n_variables, n_timesteps).\n",
    "        * frequencies (list): Frequencies to be used when calculating the naive forecast.\n",
    "        * agg: Aggregation function applied to sampled predictions (defaults to ``np.median``).\n",
    "    \"\"\"\n",
    "    if data_samples.shape[1:] != data_truth.shape:\n",
    "        raise ValueError('Last three dimensions of data_samples and data_truth need to be compatible')\n",
    "    if len(data_samples.shape)==4:\n",
    "        agg = np.median if not agg else agg\n",
    "        data_samples = agg(data_samples,\n",
    "                           axis = 0)\n",
    "\n",
    "    # Calculate mean absolute for forecast and naive forecast per time series\n",
    "    errs, naive_errs = [], []\n",
    "    for i in range(data_samples.shape[0]):\n",
    "        ts_sample = data_samples[i]\n",
    "        ts_truth = data_truth[i]\n",
    "        ts = data_insample[i]\n",
    "        freq = int(frequencies[i])\n",
    "        # Build mean absolute error\n",
    "        err = np.mean(np.abs(ts_sample - ts_truth))\n",
    "\n",
    "        # naive forecast is calculated using insample\n",
    "        t_in = ts.shape[-1]\n",
    "        naive_forecast = ts[:, :t_in-freq]\n",
    "        naive_target = ts[:, freq:]\n",
    "        err_naive = np.mean(np.abs(naive_target - naive_forecast))\n",
    "\n",
    "        errs.append(err)\n",
    "        naive_errs.append(err_naive)\n",
    "    \n",
    "    errs = np.array(errs)\n",
    "    naive_errs = np.array(naive_errs)\n",
    "\n",
    "    return errs / naive_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 02_deep4cast_m4_example.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_models.wavenet.ipynb.\n",
      "Converted 06_models.dnn.ipynb.\n",
      "Converted 07_forecaster.ipynb.\n",
      "Converted 08_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
