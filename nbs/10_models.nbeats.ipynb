{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.nbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Beats model\n",
    "\n",
    "> A basic architecture for time series forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.hook import num_features_model\n",
    "from fastai2.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(\n",
       "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (theta_b_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (theta_f_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "def linspace(backcast_length, forecast_length):\n",
    "    lin_space = np.linspace(\n",
    "        -backcast_length, forecast_length, backcast_length + forecast_length\n",
    "    )\n",
    "    b_ls = lin_space[:backcast_length]\n",
    "    f_ls = lin_space[backcast_length:]\n",
    "    return b_ls, f_ls\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        thetas_dim,\n",
    "        device,\n",
    "        backcast_length=10,\n",
    "        forecast_length=5,\n",
    "        share_thetas=False,\n",
    "    ):\n",
    "        super(Block, self).__init__()\n",
    "        self.units = units\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.backcast_length = backcast_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.share_thetas = share_thetas\n",
    "        self.fc1 = nn.Linear(backcast_length, units)\n",
    "        self.fc2 = nn.Linear(units, units)\n",
    "        self.fc3 = nn.Linear(units, units)\n",
    "        self.fc4 = nn.Linear(units, units)\n",
    "        self.device = device\n",
    "        self.backcast_linspace, self.forecast_linspace = linspace(\n",
    "            backcast_length, forecast_length\n",
    "        )\n",
    "        if share_thetas:\n",
    "            self.theta_f_fc = self.theta_b_fc = nn.Linear(units, thetas_dim)\n",
    "        else:\n",
    "            self.theta_b_fc = nn.Linear(units, thetas_dim)\n",
    "            self.theta_f_fc = nn.Linear(units, thetas_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.to(self.device)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        block_type = type(self).__name__\n",
    "        return (\n",
    "            f\"{block_type}(units={self.units}, thetas_dim={self.thetas_dim}, \"\n",
    "            f\"backcast_length={self.backcast_length}, forecast_length={self.forecast_length}, \"\n",
    "            f\"share_thetas={self.share_thetas}) at @{id(self)}\"\n",
    "        )\n",
    "\n",
    "Block(units=256, thetas_dim=8, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericBlock(\n",
       "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (theta_b_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (theta_f_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (backcast_fc): Linear(in_features=8, out_features=10, bias=True)\n",
       "  (forecast_fc): Linear(in_features=8, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "class GenericBlock(Block):\n",
    "    def __init__(\n",
    "        self, units, thetas_dim, device, backcast_length=10, forecast_length=5\n",
    "    ):\n",
    "        super(GenericBlock, self).__init__(\n",
    "            units, thetas_dim, device, backcast_length, forecast_length\n",
    "        )\n",
    "\n",
    "        self.backcast_fc = nn.Linear(thetas_dim, backcast_length)\n",
    "        self.forecast_fc = nn.Linear(thetas_dim, forecast_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # no constraint for generic arch.\n",
    "        x = super(GenericBlock, self).forward(x)\n",
    "\n",
    "        theta_b = F.relu(self.theta_b_fc(x))\n",
    "        theta_f = F.relu(self.theta_f_fc(x))\n",
    "\n",
    "        backcast = self.backcast_fc(theta_b)  # generic. 3.3.\n",
    "        forecast = self.forecast_fc(theta_f)  # generic. 3.3.\n",
    "\n",
    "        return backcast, forecast\n",
    "    \n",
    "GenericBlock(units=256,thetas_dim=8,device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeasonalityBlock(\n",
       "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (theta_f_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (theta_b_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "def seasonality_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    assert p < 10, \"thetas_dim is too big.\"\n",
    "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
    "    s1 = torch.tensor([np.cos(2 * np.pi * i * t) for i in range(p1)]).float()  # H/2-1\n",
    "    s2 = torch.tensor([np.sin(2 * np.pi * i * t) for i in range(p2)]).float()\n",
    "    S = torch.cat([s1, s2])\n",
    "    return thetas.mm(S.to(device))\n",
    "\n",
    "class SeasonalityBlock(Block):\n",
    "    def __init__(\n",
    "        self, units, thetas_dim, device, backcast_length=10, forecast_length=5\n",
    "    ):\n",
    "        super(SeasonalityBlock, self).__init__(\n",
    "            units,\n",
    "            thetas_dim,\n",
    "            device,\n",
    "            backcast_length,\n",
    "            forecast_length,\n",
    "            share_thetas=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(SeasonalityBlock, self).forward(x)\n",
    "        backcast = seasonality_model(\n",
    "            self.theta_b_fc(x), self.backcast_linspace, self.device\n",
    "        )\n",
    "        forecast = seasonality_model(\n",
    "            self.theta_f_fc(x), self.forecast_linspace, self.device\n",
    "        )\n",
    "        return backcast, forecast\n",
    "SeasonalityBlock(units=256,thetas_dim=8,device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrendBlock(\n",
       "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (theta_f_fc): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (theta_b_fc): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "def trend_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    print(t,p)\n",
    "    assert p <= 4, \"thetas_dim is too big.\"\n",
    "    T = torch.tensor([t ** i for i in range(p)]).float()\n",
    "    return thetas.mm(T.to(device))\n",
    "\n",
    "class TrendBlock(Block):\n",
    "    def __init__(\n",
    "        self, units, thetas_dim, device, backcast_length=10, forecast_length=5\n",
    "    ):\n",
    "        super(TrendBlock, self).__init__(\n",
    "            units,\n",
    "            thetas_dim,\n",
    "            device,\n",
    "            backcast_length,\n",
    "            forecast_length,\n",
    "            share_thetas=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(TrendBlock, self).forward(x)\n",
    "        backcast = trend_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
    "        forecast = trend_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
    "        return backcast, forecast\n",
    "    \n",
    "TrendBlock(units=256, thetas_dim=4, device=torch.device('cpu'), backcast_length=100, forecast_length=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class NBeatsNet(nn.Module):\n",
    "    SEASONALITY_BLOCK = \"seasonality\"\n",
    "    TREND_BLOCK = \"trend\"\n",
    "    GENERIC_BLOCK = \"generic\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
    "        nb_blocks_per_stack=3,\n",
    "        forecast_length=5,\n",
    "        backcast_length=10,\n",
    "        thetas_dims=(4, 8),\n",
    "        share_weights_in_stack=False,\n",
    "        hidden_layer_units=256,\n",
    "    ):\n",
    "        super(NBeatsNet, self).__init__()\n",
    "        self.forecast_length = forecast_length\n",
    "        self.backcast_length = backcast_length\n",
    "        self.hidden_layer_units = hidden_layer_units\n",
    "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
    "        self.share_weights_in_stack = share_weights_in_stack\n",
    "        self.stack_types = stack_types\n",
    "        self.stacks = []\n",
    "        self.thetas_dim = thetas_dims\n",
    "        self.parameters = []\n",
    "        self.device = device\n",
    "        print(f\"| N-Beats\")\n",
    "        for stack_id in range(len(self.stack_types)):\n",
    "            self.stacks.append(self.create_stack(stack_id))\n",
    "        self.parameters = nn.ParameterList(self.parameters)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def create_stack(self, stack_id):\n",
    "        stack_type = self.stack_types[stack_id]\n",
    "        print(\n",
    "            f\"| --  Stack {stack_type.title()} (#{stack_id}) (share_weights_in_stack={self.share_weights_in_stack})\"\n",
    "        )\n",
    "        blocks = []\n",
    "        for block_id in range(self.nb_blocks_per_stack):\n",
    "            block_init = NBeatsNet.select_block(stack_type)\n",
    "            if self.share_weights_in_stack and block_id != 0:\n",
    "                block = blocks[-1]  # pick up the last one when we share weights.\n",
    "            else:\n",
    "                block = block_init(\n",
    "                    self.hidden_layer_units,\n",
    "                    self.thetas_dim[stack_id],\n",
    "                    self.device,\n",
    "                    self.backcast_length,\n",
    "                    self.forecast_length,\n",
    "                )\n",
    "                self.parameters.extend(block.parameters())\n",
    "            print(f\"     | -- {block}\")\n",
    "            blocks.append(block)\n",
    "        return blocks\n",
    "\n",
    "    @staticmethod\n",
    "    def select_block(block_type):\n",
    "        if block_type == NBeatsNet.SEASONALITY_BLOCK:\n",
    "            return SeasonalityBlock\n",
    "        elif block_type == NBeatsNet.TREND_BLOCK:\n",
    "            return TrendBlock\n",
    "        else:\n",
    "            return GenericBlock\n",
    "\n",
    "    def forward(self, backcast):\n",
    "        forecast = torch.zeros(\n",
    "            size=(backcast.size()[0], self.forecast_length,)\n",
    "        )  # maybe batch size here.\n",
    "        for stack_id in range(len(self.stacks)):\n",
    "            for block_id in range(len(self.stacks[stack_id])):\n",
    "                b, f = self.stacks[stack_id][block_id](backcast)\n",
    "                backcast = backcast.to(self.device) - b\n",
    "                forecast = forecast.to(self.device) + f\n",
    "        return backcast, forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| N-Beats\n",
      "| --  Stack Trend (#0) (share_weights_in_stack=True)\n",
      "     | -- TrendBlock(units=2048, thetas_dim=7, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924703760\n",
      "     | -- TrendBlock(units=2048, thetas_dim=7, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924703760\n",
      "     | -- TrendBlock(units=2048, thetas_dim=7, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924703760\n",
      "| --  Stack Seasonality (#1) (share_weights_in_stack=True)\n",
      "     | -- SeasonalityBlock(units=2048, thetas_dim=8, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924648784\n",
      "     | -- SeasonalityBlock(units=2048, thetas_dim=8, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924648784\n",
      "     | -- SeasonalityBlock(units=2048, thetas_dim=8, backcast_length=140, forecast_length=14, share_thetas=True) at @139710924648784\n"
     ]
    }
   ],
   "source": [
    "net = NBeatsNet(stack_types=[NBeatsNet.TREND_BLOCK, NBeatsNet.SEASONALITY_BLOCK],\n",
    "                forecast_length=14,\n",
    "                thetas_dims=[7, 8],\n",
    "                nb_blocks_per_stack=3,\n",
    "                backcast_length=140,\n",
    "                hidden_layer_units=2048,\n",
    "                share_weights_in_stack=True,\n",
    "                device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from fastai2.basics import *\n",
    "# from fastseq.all import *\n",
    "\n",
    "# @delegates(DNN.__init__)\n",
    "# def dnn_learner(dbunch, output_channels=None, metrics=None, **kwargs):\n",
    "#     \"Build a dnn style learner\"\n",
    "#     output_channels = ifnone(output_channels,dbunch.train[0][0].shape[0])\n",
    "    \n",
    "#     model = DNN(input_channels=dbunch.train[0][0].shape[0],\n",
    "#         output_channels=output_channels, \n",
    "#         horizon = dbunch.train_dl.horizon,\n",
    "#         lookback = dbunch.train_dl.lookback, \n",
    "#         **kwargs\n",
    "#        )\n",
    "    \n",
    "#     learn = Learner(dbunch, model, loss_func=F.mse_loss, opt_func= Adam, metrics=L(metrics)+L(mae, smape))\n",
    "#     return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'URLs' has no attribute 'm4_daily'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-f98deb41d01b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURLs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm4_daily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'URLs' has no attribute 'm4_daily'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataBunch.from_folder(path, horizon = 14, lookback = 128, bs = 64, nrows=100)\n",
    "learn = dnn_learner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-bd8b18fd11a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "from fastai2.callback.all import *\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-749224a75fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "learn.fit(2,1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_models.wavenet.ipynb.\n",
      "Converted 06_models.dnn.ipynb.\n",
      "Converted 08_metrics.ipynb.\n",
      "Converted 09_learner.ipynb.\n",
      "Converted 10_models.nbeats.ipynb.\n",
      "Converted 20_models.cnn.learner.ipynb.\n",
      "Converted 21_models.cnn.transforms.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
