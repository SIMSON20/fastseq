{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "from fastseq.data.external import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.tabular.core import *\n",
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Load Dataframe\n",
    "\n",
    "\n",
    "> Using the fastai2 `Datasets` to make an time series dataset.\n",
    "\n",
    "A multivaraite time-series dataloader. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data saving and restoring from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TSMulti(MultiTuple):pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_df(length = [100,120]):\n",
    "    dct = {'x':[],'con_ts_1':[],'con_ts_0':[],'cat_ts_1':[],'cat_ts_0':[],'con_0':[],'con_1':[], 'cat_0':[],'cat_1':[]}\n",
    "    for i, l in enumerate(length):\n",
    "        assert int(l/2) == l/2\n",
    "        dct['x'].append(np.arange(l))\n",
    "        dct['con_ts_0'].append(np.arange(l)[None,:])\n",
    "        dct['con_ts_1'].append(pd.Series(np.arange(l)+np.random.randn(l)))\n",
    "        dct['con_0'].append(np.random.rand()*2-1)\n",
    "        dct['con_1'].append(10+np.random.rand()*2)\n",
    "        dct['cat_ts_0'].append(L(['a','b']*int(l/2)))\n",
    "        dct['cat_ts_1'].append(L(['david','john']*int(l/2)))\n",
    "        dct['cat_0'].append(['a','b'][i%2])\n",
    "        dct['cat_1'].append(['adam','rdam'][i%2])\n",
    "    return pd.DataFrame(data=dct)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>con_ts_1</th>\n",
       "      <th>con_ts_0</th>\n",
       "      <th>cat_ts_1</th>\n",
       "      <th>cat_ts_0</th>\n",
       "      <th>con_0</th>\n",
       "      <th>con_1</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0    1.631405\n",
       "1    2.263540\n",
       "2    2.286147\n",
       "3    1.292152\n",
       "4    1.618599\n",
       "5    3.815206\n",
       "6    5.079730\n",
       "7    7.270119\n",
       "8    8.986712\n",
       "9    9.638568\n",
       "dtype: float64</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]</td>\n",
       "      <td>[david, john, david, john, david, john, david, john, david, john]</td>\n",
       "      <td>[a, b, a, b, a, b, a, b, a, b]</td>\n",
       "      <td>0.576248</td>\n",
       "      <td>11.203675</td>\n",
       "      <td>a</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>0      0.431903\n",
       "1      0.900727\n",
       "2      3.531509\n",
       "3      3.370649\n",
       "4      4.472495\n",
       "5      4.127667\n",
       "6      5.709715\n",
       "7      6.678178\n",
       "8      6.015037\n",
       "9      9.963636\n",
       "10     9.104967\n",
       "11    11.060055\n",
       "dtype: float64</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]</td>\n",
       "      <td>[david, john, david, john, david, john, david, john, david, john, david, john]</td>\n",
       "      <td>[a, b, a, b, a, b, a, b, a, b, a, b]</td>\n",
       "      <td>0.276560</td>\n",
       "      <td>10.685775</td>\n",
       "      <td>b</td>\n",
       "      <td>rdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0    0.342758\n",
       "1   -0.609929\n",
       "2    3.238574\n",
       "3    3.273522\n",
       "4    5.006514\n",
       "5    3.983544\n",
       "dtype: float64</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5]]</td>\n",
       "      <td>[david, john, david, john, david, john]</td>\n",
       "      <td>[a, b, a, b, a, b]</td>\n",
       "      <td>0.251666</td>\n",
       "      <td>10.288675</td>\n",
       "      <td>a</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        x  \\\n",
       "0          [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]   \n",
       "2                      [0, 1, 2, 3, 4, 5]   \n",
       "\n",
       "                                                                                                                                                                                                         con_ts_1  \\\n",
       "0                                                      0    1.631405\n",
       "1    2.263540\n",
       "2    2.286147\n",
       "3    1.292152\n",
       "4    1.618599\n",
       "5    3.815206\n",
       "6    5.079730\n",
       "7    7.270119\n",
       "8    8.986712\n",
       "9    9.638568\n",
       "dtype: float64   \n",
       "1  0      0.431903\n",
       "1      0.900727\n",
       "2      3.531509\n",
       "3      3.370649\n",
       "4      4.472495\n",
       "5      4.127667\n",
       "6      5.709715\n",
       "7      6.678178\n",
       "8      6.015037\n",
       "9      9.963636\n",
       "10     9.104967\n",
       "11    11.060055\n",
       "dtype: float64   \n",
       "2                                                                                                              0    0.342758\n",
       "1   -0.609929\n",
       "2    3.238574\n",
       "3    3.273522\n",
       "4    5.006514\n",
       "5    3.983544\n",
       "dtype: float64   \n",
       "\n",
       "                                   con_ts_0  \\\n",
       "0          [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]   \n",
       "1  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]   \n",
       "2                      [[0, 1, 2, 3, 4, 5]]   \n",
       "\n",
       "                                                                         cat_ts_1  \\\n",
       "0               [david, john, david, john, david, john, david, john, david, john]   \n",
       "1  [david, john, david, john, david, john, david, john, david, john, david, john]   \n",
       "2                                         [david, john, david, john, david, john]   \n",
       "\n",
       "                               cat_ts_0     con_0      con_1 cat_0 cat_1  \n",
       "0        [a, b, a, b, a, b, a, b, a, b]  0.576248  11.203675     a  adam  \n",
       "1  [a, b, a, b, a, b, a, b, a, b, a, b]  0.276560  10.685775     b  rdam  \n",
       "2                    [a, b, a, b, a, b]  0.251666  10.288675     a  adam  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df([10,12,6])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class Meta(dict):pass\n",
    "class TS(dict):\n",
    "    @classmethod\n",
    "    def load(cls, f):\n",
    "        return cls(orjson.loads(open(f,'rb').read()))\n",
    "    \n",
    "    def get_ts(self, meta:Meta, key):\n",
    "        \"\"\"Ensures it is always same order\"\"\"       \n",
    "        try:\n",
    "            return [self[key][o] for o in meta['col_names'][key+'_names']]       \n",
    "        except KeyError:\n",
    "            assert key in ['cat','con','ts_cat','ts_con']\n",
    "            \n",
    "    def get_np(self,meta:Meta, key):return np.array(self.get_ts(meta,key))            \n",
    "    def __len__(self):return self['_length']\n",
    "    \n",
    "def get_ts_datapoint(f):\n",
    "    return TS(orjson.loads(open(f,'rb').read()))\n",
    "\n",
    "def get_meta(path:Path):\n",
    "    classes = defaultdict(set)\n",
    "    f = path / '.ts_meta'\n",
    "    return Meta(json.load(open(f,'r')))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "path = Path('../data/test_data')\n",
    "ts = TS.load(path / '1.json')\n",
    "test_eq(set(ts.get_ts(get_meta(path), 'cat')),set(['rdam','b']))\n",
    "test_close(ts.get_ts(get_meta(path), 'con'),[10,0], 2)\n",
    "test_close(ts.get_np(get_meta(path), 'ts_con').shape,(3, len(ts)))\n",
    "test_close(ts.get_np(get_meta(path), 'ts_cat').shape,(2, len(ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def python_type(o):\n",
    "    if isinstance(o,int) or type(o) == np.int64:\n",
    "        return int(o)\n",
    "    elif isinstance(o,float) or type(o) == np.float64:\n",
    "        if int(o) == o:\n",
    "            return int(o)\n",
    "        return float(o)\n",
    "    elif type(o) == str:\n",
    "        return o\n",
    "    elif type(o) == pd.Series:\n",
    "        return [python_type(v) for k,v in dict(o).items()]\n",
    "    elif isinstance(o,list) or isinstance(o,L):\n",
    "        return [python_type(v) for v in o]\n",
    "    elif isinstance(o,np.ndarray):\n",
    "        return [python_type(v) for v in list(o.flatten())]\n",
    "    raise Exception(f\"{type(o)}, {o}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(python_type(np.array([0,0])),[0,0])\n",
    "test_eq(type(python_type(np.array([1.,0.]))[0]),int)\n",
    "test_eq(python_type(pd.Series(np.arange(10))),list(np.arange(10)))\n",
    "test_eq(python_type(np.arange(10)[None,:]),list(np.arange(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def add_dct(dct, k, o):\n",
    "    if type(o) == set:\n",
    "        o = list(o)\n",
    "        \n",
    "    if type(o) == list or type(o) == L:\n",
    "        if k in dct:\n",
    "            dct[k] = list(set(dct[k] +o))\n",
    "        else:\n",
    "            dct[k] = o\n",
    "    elif type(o) == dict or type(o) == collections.defaultdict:\n",
    "        if k not in dct:\n",
    "            dct[k] = {}            \n",
    "        for _k,v in o.items():\n",
    "            dct[k] = add_dct(dct[k], _k, v)\n",
    "    elif type(o) == int or type(o) == float:\n",
    "        dct[k] = o\n",
    "    else:\n",
    "        raise Exception(type(o))\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct={'foo':'bar'}\n",
    "dct = add_dct(dct, 'foo2',['bar2'])\n",
    "test_eq(len(dct), 2)\n",
    "dct = add_dct(dct, 'foodct',dict(a=1))\n",
    "test_eq(dct['foodct'] , dict(a=1))\n",
    "o = defaultdict(list)\n",
    "o[1].append(0)\n",
    "dct = add_dct(dct,'defaultdict',o )\n",
    "test_eq(dct['defaultdict'][1],[0])\n",
    "\n",
    "dct = add_dct(dct,'set',set([1,2,2]) )\n",
    "test_eq(dct['set'],[1,2])\n",
    "\n",
    "dct = add_dct(dct,'set2',{'set':set([1,2,2])} )\n",
    "test_eq(dct['set2']['set'],[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import json\n",
    "def _check_length(lst, length):    \n",
    "    if length is None:\n",
    "        length = len(lst)\n",
    "    else:\n",
    "        assert len(lst) == length\n",
    "    return length\n",
    "        \n",
    "def reconize_cols(datapoint:dict, con_names= [], cat_names=[], ts_con_names=[], ts_cat_names=[]):\n",
    "    \"\"\"Gets the con_names, cat_names, ts_con_names, ts_cat_names for the `datapoint`\"\"\"\n",
    "    length = None\n",
    "    classes = defaultdict(set)\n",
    "    for k,v in datapoint.items():\n",
    "        if k in [con_names+cat_names+ ts_con_names+ts_cat_names]:\n",
    "            if k in [cat_names+ts_cat_names]:\n",
    "                for _v in set(v):\n",
    "                    classes[k].add(_v)\n",
    "            continue\n",
    "        if type(v) == int or isinstance(v,float):\n",
    "            con_names.append(k)\n",
    "        elif type(v) == str:\n",
    "            cat_names.append(k)\n",
    "            classes[k] = [v]\n",
    "        elif isinstance(v,list) and (type(v[0]) == int or type(v[0]) == float):\n",
    "            ts_con_names.append(k)\n",
    "            length = _check_length(v, length)\n",
    "        elif isinstance(v, list) and (type(v[0]) == str):\n",
    "            ts_cat_names.append(k)\n",
    "            length = _check_length(v, length)\n",
    "            for _v in set(v):\n",
    "                classes[k].add(_v)\n",
    "        else:\n",
    "            raise TypeError(type(v), type(v[0]))\n",
    "    col_names = {k:list(set(v)) for k,v in zip('con_names, cat_names, ts_con_names, ts_cat_names'.split(', '),\n",
    "                                         [con_names, cat_names, ts_con_names, ts_cat_names],)}\n",
    "    return length, classes, col_names, [list(set(o)) for o in [con_names, cat_names, ts_con_names, ts_cat_names]]\n",
    "\n",
    "def make_compact(dp, con_names, cat_names, ts_con_names, ts_cat_names, **kwargs):\n",
    "    r = {'_'+k:v for k,v in kwargs.items()}  \n",
    "    r['con'] = {k:dp[k] for k in con_names}\n",
    "    r['cat'] = {k:dp[k] for k in cat_names}\n",
    "    r['ts_con'] = {k:[float(i) for i in dp[k]] for k in ts_con_names}\n",
    "    r['ts_cat'] = {k:dp[k] for k in ts_cat_names}\n",
    "    return r\n",
    "        \n",
    "def meta_file(path, **kwargs):\n",
    "    dct = {}\n",
    "    f = path / '.ts_meta'\n",
    "    if (path / '.ts_meta').exists():\n",
    "        dct = json.load(open(f))\n",
    "    for k,v in kwargs.items():\n",
    "        dct = add_dct(dct,k,v)\n",
    "    json.dump(dct, open(f,'w'), indent = 2, sort_keys = True)               \n",
    "\n",
    "@delegates(reconize_cols)\n",
    "def save_row(row, path:Path, fname='1', **kwargs):\n",
    "    if not path.exists(): path.mkdir()\n",
    "    if fname[-5:] is not '.json': fname += '.json'\n",
    "    o = {k:python_type(v) for k,v in dict(row).items()}   \n",
    "    length, classes, col_names, names = reconize_cols(o, **kwargs)  \n",
    "    o = make_compact(o, *names, length = length)\n",
    "    meta_file(path, classes=classes, col_names = col_names)\n",
    "    open(path / fname,'wb').write(orjson.dumps(o, ))\n",
    "    return path / fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([6])\n",
    "path = Path('../data/test_data')\n",
    "f = save_row(df.iloc[0,:], path)\n",
    "dct = orjson.loads(open(f,'rb').read())\n",
    "test_eq(dct['_length'],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(save_row)\n",
    "def save_df(df:pd.DataFrame, path:Path, **kwargs):\n",
    "    for i, row in df.iterrows():\n",
    "        save_row(row, path, fname=str(i), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['_length', 'con', 'cat', 'ts_con', 'ts_cat']),\n",
       " dict_keys(['_length', 'con', 'cat', 'ts_con', 'ts_cat']),\n",
       " dict_keys(['_length', 'con', 'cat', 'ts_con', 'ts_cat'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df([600, 888, 1200])\n",
    "path = Path('../data/test_data')\n",
    "save_df(df, path)\n",
    "[get_ts_datapoint(str(path / (str(i) + '.json'))).keys() for i in range(0,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Transform catagorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_classes(df, cat_cols, classes=None):    \n",
    "    classes = ifnone(classes, {})\n",
    "    if classes == {}:\n",
    "        for col in cat_cols:\n",
    "            classes[col] = unpack_list(list(df[col]))\n",
    "    return classes\n",
    "\n",
    "def _make_vocab_df(df,cat_cols, classes = None):\n",
    "    vocab,o2i = {},{}\n",
    "    classes = _get_classes(df, cat_cols, classes)\n",
    "    for col, vals in classes.items():\n",
    "        vocab[col], o2i[col] = uniqueify(vals, sort=True, bidir=True)\n",
    "    return vocab, o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _reverse_lst(lst):\n",
    "    return [[a for a in o] for o in list(np.array(lst).T)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "test_eq(_reverse_lst([[0,0],[1,1]]),[[0,1],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core.debugger import set_trace\n",
    "class TensorCatI(TensorBase):pass\n",
    "class CatSeqI(TensorSeq):pass\n",
    "def unpack_list(o, r=None):\n",
    "    r = ifnone(r,L())\n",
    "    for a in o:\n",
    "        if isinstance(a,list) or isinstance(a,L):\n",
    "            r = unpack_list(a, r)\n",
    "        else:\n",
    "            r.append(a)\n",
    "    return r\n",
    "\n",
    "class CatTfm(Transform):\n",
    "    def __init__(self, df:pd.DataFrame = None, cat_cols:[] = None,\n",
    "                 classes = None, vocab=None, o2i=None):\n",
    "        if vocab is not None and o2i is not None:\n",
    "            self.vocab,self.o2i = vocab, o2i\n",
    "        else:\n",
    "            self.vocab,self.o2i = _make_vocab_df(df,cat_cols)        \n",
    "            \n",
    "    def encodes(self, x: TensorCat):\n",
    "        r = []\n",
    "        for i, (o, key) in enumerate(zip(x.o, x._meta['label'])):\n",
    "            r.append(self.o2i[key][o])#TensorCat\n",
    "        return TensorCatI(r, label = x._meta['label'])\n",
    "\n",
    "    def decodes(self, x:TensorCatI):\n",
    "        if len(x.shape) == 1:\n",
    "            x = TensorCatI(x[None,:],**x._meta)\n",
    "        return TensorCat(_reverse_lst(self._decode(TensorCatI(x.T,**x._meta))),\n",
    "                         label = x._meta.get('label', None))    \n",
    "    \n",
    "    def encodes(self, x:CatSeq):\n",
    "        r = []\n",
    "        for i,(o, key) in enumerate(zip(x.o,x._meta['label'])):\n",
    "            r.append([])\n",
    "            for a in o:\n",
    "                r[i].append(self.o2i[key][a]) #CatSeq\n",
    "        return CatSeqI(r, label = x._meta['label'])\n",
    "    \n",
    "    def decodes(self, x:CatSeqI): \n",
    "        if len(x.shape) == 2:\n",
    "            x = CatSeqI(x[None,:],**x._meta)\n",
    "        r = []\n",
    "        for o in x:\n",
    "            r.append(self._decode(CatSeqI(o,**x._meta)))\n",
    "        return CatSeq(r, label = x._meta.get('label', None))\n",
    "    \n",
    "    def _decode(self, x):   \n",
    "        r = []        \n",
    "        for i, (o, key) in enumerate(zip(x, x._meta['label'])):\n",
    "            r.append([])\n",
    "            for a in o:\n",
    "                r[i].append(self.vocab[key][a])\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vocab = {'cat_0':['a','b'],'cat_1':['adam','rdam'],\n",
    "         'cat_ts_0':['a','b'],'cat_ts_1': ['david','john']}\n",
    "tfm = CatTfm(vocab = vocab,\n",
    "             o2i = {'cat_0': {'a': 0, 'b': 1},\n",
    "                     'cat_1': {'adam': 0, 'rdam': 1},\n",
    "                     'cat_ts_0': {'a': 0, 'b': 1},\n",
    "                     'cat_ts_1': {'david': 0, 'john': 1}})\n",
    "test_eq(tfm.vocab, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat b b 1 ['a', 'b']\n",
      "cat adam adam 0 ['adam', 'rdam']\n",
      "seq a a 0\n",
      "seq john john 1\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# check decode w batch\n",
    "n = np.random.choice(2,(64,2))\n",
    "o_d = tfm.decode(TensorCatI(n, label=['cat_0','cat_1']))\n",
    "test_eq(o_d.shape,(64,2))\n",
    "for i, label in zip(range(2),['cat_0','cat_1']):\n",
    "    pred, target =o_d.o[0][i], vocab[label][n[0,i]] \n",
    "    print('cat',pred,target, n[0,i], vocab[label])\n",
    "    test_eq(pred,target)\n",
    "\n",
    "n = np.random.choice(2,(64,2,84))\n",
    "o = CatSeqI(n.astype(int), label=['cat_ts_0','cat_ts_1'])\n",
    "o_d = tfm.decode(o)\n",
    "test_eq(o_d.shape,(64,2,84))\n",
    "for i, label in zip(range(2),['cat_ts_0','cat_ts_1']):\n",
    "    print('seq', o_d.o[0][i][0], vocab[label][n[0,i,0]], n[0,i,0])\n",
    "    test_eq(o_d.o[0][i][0],vocab[label][n[0,i,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "o = TensorCat(['a','adam'], label=['cat_0','cat_1'])\n",
    "test_eq(tfm.encodes(o),tensor([0,0]))\n",
    "o = CatSeq([['a'],['david']], label=['cat_ts_0','cat_ts_1'])\n",
    "test_eq(tfm.encodes(o),tensor([[0],[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a'], ['david']]], label = ['cat_ts_0', 'cat_ts_1'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(tfm.decode(TensorCatI([0,0], label=['cat_0','cat_1'])), \n",
    "        TensorCat(['a','adam'], label=['cat_0','cat_1']) )\n",
    "\n",
    "test_eq(tfm.decode(CatSeqI([[0],[0]], label=['cat_ts_0','cat_ts_1'])),\n",
    "       CatSeq([[['a'],['david']]], label=['cat_ts_0','cat_ts_1']))\n",
    "tfm.decode(CatSeqI([[0],[0]], label=['cat_ts_0','cat_ts_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCatI([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = CatSeq([['y','z','z','z'],['adam','rdam','adam','rdam']], label = ['cat_ts_1', 'cat_ts_0'])\n",
    "df = pd.DataFrame({'cat_ts_1':[[i] for i in 'xzy'],'cat_ts_0':[[i] for i in ['adam','rdam','adam']],\n",
    "                   'cat':['john','john','david'], 'cat1':['_john','_john','_david']})\n",
    "tmf = CatTfm(df, ['cat_ts_0','cat_ts_1','cat','cat1'])\n",
    "tmf(o)\n",
    "o = TensorCat(['david','_john'], label = ['cat','cat1'])\n",
    "tmf(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (#2) ['a','b']}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[[i,'a'] for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'], {})\n",
    "print(tmf.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a', 'b', 'a', 'a']]], label = ['a'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = CatSeq([['a','b','a','a']], label='a')\n",
    "o_tmf = tmf(o)\n",
    "test_eq(o_tmf, TensorCatI([[0, 1, 0, 0]]))\n",
    "test_eq(o_tmf._meta['label'], 'a')\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o.o[0],o.o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'])\n",
    "o_tmf = tmf(TensorCat(['a'], label='a'))\n",
    "test_eq_type(o_tmf,TensorCatI([0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a'],label = 'a'))\n",
    "\n",
    "o_tmf = tmf(TensorCat(['b'], label='a'))\n",
    "test_eq_type(o_tmf,TensorCatI([1]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['b'],label='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o_tmf = tmf(TensorCat(['a','b'], label = ['a','a_2']))\n",
    "test_eq_type(o_tmf,TensorCatI([0,0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a','b'],label = 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a', 'b', 'a', 'a'], ['b', 'b', 'c', 'c']]], label = ['a', 'a_2'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o = CatSeq([['a','b','a','a'],['b','b','c','c']], label=['a','a_2'])\n",
    "o_tmf = tmf(o)\n",
    "test_eq(o_tmf, CatSeqI([[0, 1, 0, 0],\n",
    "                        [0, 0, 1, 1]]))\n",
    "test_eq(o_tmf._meta['label'], ['a','a_2'])\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o.o[0],o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## make_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_classes(path:Path):\n",
    "    return get_meta(path)['classes']\n",
    "                    \n",
    "def make_vocab(path, classes = None):\n",
    "    if classes is None:\n",
    "        classes = get_classes(path)\n",
    "    vocab, o2i = {},{}\n",
    "    for col, vals in classes.items():\n",
    "        vocab[col], o2i[col] = uniqueify(vals, sort=True, bidir=True)\n",
    "    return vocab, o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_0': ['a', 'b'],\n",
       " 'cat_1': ['adam', 'rdam'],\n",
       " 'cat_ts_0': ['a', 'b'],\n",
       " 'cat_ts_1': ['david', 'john']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df([600, 888, 1200])\n",
    "path = Path('../data/test_data')\n",
    "save_df(df, path)\n",
    "get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_0': (#2) ['a','b'],\n",
       " 'cat_1': (#2) ['adam','rdam'],\n",
       " 'cat_ts_0': (#2) ['a','b'],\n",
       " 'cat_ts_1': (#2) ['david','john']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_vocab(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def make_ids(dl):  \n",
    "    \"\"\"Make ids if the sequence is shorter than `min_seq_len`, it will drop that sequence.\"\"\"\n",
    "    # Slice each time series into examples, assigning IDs to each\n",
    "    last_id = 0\n",
    "    n_dropped = 0\n",
    "    n_needs_padding = 0\n",
    "    dl._ids = {}\n",
    "    for f in dl.dataset:\n",
    "        dp = get_ts_datapoint(f)  \n",
    "        num_examples = (dp['_length'] - dl.lookback - dl.horizon + dl.step) // dl.step\n",
    "        # Time series shorter than the forecast horizon need to be dropped.\n",
    "        if dp['_length'] < dl.min_seq_len:\n",
    "            n_dropped += 1\n",
    "            continue\n",
    "        # For short time series zero pad the input\n",
    "        if dp['_length'] < dl.lookback + dl.horizon:\n",
    "            n_needs_padding += 1\n",
    "            num_examples = 1\n",
    "        for j in range(num_examples):\n",
    "            dl._ids[last_id + j] = (str(f), j * dl.step)\n",
    "        last_id += num_examples\n",
    "\n",
    "    # Inform user about time series that were too short\n",
    "    if n_dropped > 0:\n",
    "        print(\"Dropped {}/{} time series due to length.\".format(\n",
    "                n_dropped, len(dl.dataset)))\n",
    "\n",
    "    # Inform user about time series that were short\n",
    "    if n_needs_padding > 0:\n",
    "        print(\"Need to pad {}/{} time series due to length.\".format(\n",
    "                n_needs_padding, len(dl.dataset)))\n",
    "    # Store the number of training examples\n",
    "    dl.n = int(dl._ids.__len__() )\n",
    "    return dl, dl.n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# needs a test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## get_part_of_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x, lookback_id, length, pad=np.mean, t = tensor, **kwargs):\n",
    "    if x.shape[-1] < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = pad(x, -1)\n",
    "        x = t(np.pad(\n",
    "            x, # report issue https://github.com/numpy/numpy/issues/15606\n",
    "            pad_width=((0, 0), (length - x.shape[-1], 0)),\n",
    "            mode='constant',\n",
    "            constant_values=padding\n",
    "        ), **kwargs).float()\n",
    "        assert x.shape == (x.shape[0],length), f\"{x.shape}\\t,{lookback_id}, 'tsshape':{x.shape}\"\n",
    "    else:\n",
    "        x = t(x[:,lookback_id:lookback_id + length], **kwargs).float()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = np.vstack([np.arange(10.)]*2)\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.cat([torch.arange(2,7.)[None,:]]*2))\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                          [4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))\n",
    "\n",
    "# report issue https://github.com/numpy/numpy/issues/15606\n",
    "x = np.arange(10.)[None,:]\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "x = np.arange(10.)[None,:]\n",
    "o =get_part_of_ts(x, 0, 11, t = TensorBase, label='a')\n",
    "test_eq_type(o, TensorBase([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])) \n",
    "test_eq(o._meta, {'label':'a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x:list, lookback_id, length, t = L, **kwargs):\n",
    "    if len(x[0]) < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = [o[-1] for o in x]\n",
    "        pad_len = length - len(x[0])\n",
    "        x = [o[lookback_id:lookback_id + length] + [padding[i]]*pad_len for i,o in enumerate(x)]\n",
    "    else:\n",
    "        x = [o[lookback_id:lookback_id + length] for o in x]\n",
    "    return t(x, **kwargs)\n",
    "\n",
    "@typedispatch\n",
    "def get_part_of_ts(x:L, *args, **kwargs):\n",
    "    return get_part_of_ts(list(x),*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*5,['z','x']*5)\n",
    "o =get_part_of_ts(x, 1, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*2, ['z','x']*2)\n",
    "o =get_part_of_ts(x, 0, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "x = [[1,2]*2, [10,11]*2]\n",
    "o =get_part_of_ts(x, 0, 5, t = TensorSeq)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),TensorSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## get_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def split_ts_con(ts, y_name, meta:Meta):  \n",
    "    ts_con_names = [o for o in meta['col_names']['ts_con_names'] if o != y_name]\n",
    "    y = ts['ts_con'][y_name]\n",
    "    tsx = [ts['ts_con'][k] for k in ts_con_names]\n",
    "    return y, tsx, ts_con_names\n",
    "    \n",
    "\n",
    "def json2TSMulti(ts, lookback_id, y_name, lookback, horizon, meta:Meta):\n",
    "    y, tsx, ts_con_names = split_ts_con(ts, y_name, meta)\n",
    "    \n",
    "    y = get_part_of_ts([y], lookback_id, lookback + horizon,\n",
    "                       t = TensorSeq, label=[y_name + '_y'], m=['g'])\n",
    "    x = TensorSeq(y[:,:lookback], label=[y_name + '_x'], m=['g'])\n",
    "    tsx_con = get_part_of_ts(tsx, lookback_id, lookback + horizon,\n",
    "                             t = TensorSeq, label=ts_con_names)\n",
    "    tsx_cat = get_part_of_ts(ts.get_ts(meta,'ts_cat'), lookback_id, lookback + horizon,\n",
    "                             t = CatSeq, label=meta['col_names']['ts_cat_names'])        \n",
    "    r = [x, tsx_con, tsx_cat]\n",
    "    r.append(TensorCat(ts.get_ts(meta,'cat'), label=meta['col_names']['cat_names']))\n",
    "    r.append(TensorCon(ts.get_ts(meta,'con'), label=meta['col_names']['con_names']))      \n",
    "    r.append(y)\n",
    "    return TSMulti(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([2000, 2000, 2000])\n",
    "path = Path('../data/test_data')\n",
    "save_df(df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"<class 'fastseq.core.TensorSeq'>0\": torch.Size([1, 100]), \"<class 'fastseq.core.TensorSeq'>1\": torch.Size([2, 110]), \"<class 'fastseq.core.CatSeq'>2\": (2, 110), \"<class 'fastseq.core.TensorCat'>3\": (2,), \"<class 'fastseq.core.TensorCon'>4\": torch.Size([2]), \"<class 'fastseq.core.TensorSeq'>5\": torch.Size([1, 110])}\n"
     ]
    }
   ],
   "source": [
    "ts = get_ts_datapoint('../data/test_data/1.json')\n",
    "r = json2TSMulti(ts, 1000, 'x',100, 10, get_meta(path))\n",
    "test_eq(len(r), 6)\n",
    "print({str(type(a))+str(i):a.shape for i,a in enumerate(r)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Multi Tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TSMulti_(Tuple):\n",
    "    def _dict(self):\n",
    "        return {str(str(i)+'_'+str(type(a))):a.shape for i,a in enumerate(self)}\n",
    "\n",
    "class CatMultiTfm(ItemTransform):\n",
    "    @delegates(CatTfm.__init__)\n",
    "    def __init__(self, **kwargs): # maybe change to proccs\n",
    "        self.f = CatTfm(**kwargs)\n",
    "        \n",
    "    def encodes(self, o):\n",
    "        return TSMulti_(self.f(a) for a in o)\n",
    "    \n",
    "    def decodes(self, o): \n",
    "        return TSMulti(self.f.decode(a) for a in o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"0_<class 'torch.Tensor'>\": torch.Size([1]),\n",
       " \"1_<class 'torch.Tensor'>\": torch.Size([2])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSMulti_([Tensor([0]),Tensor([0,0])])._dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([[['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']]], label = ['cat_ts_1', 'cat_ts_0']), TensorCat([['a', 'adam']], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']], label = ['cat_ts_1', 'cat_ts_0']), TensorCat(['a', 'adam'], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e786d28dcbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mo_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_tmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTSMulti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([[['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']]], label = ['cat_ts_1', 'cat_ts_0']), TensorCat([['a', 'adam']], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']], label = ['cat_ts_1', 'cat_ts_0']), TensorCat(['a', 'adam'], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))"
     ]
    }
   ],
   "source": [
    "df = get_df([14,14,16])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "o = json2TSMulti(get_ts_datapoint(get_files(path,extensions='.json')[0]), 0, 'x', 10, 3, get_meta(path))\n",
    "\n",
    "vocab,o2i = make_vocab(get_files(path,extensions='.json'), get_meta(path)['classes'])\n",
    "t = CatMultiTfm(vocab = vocab, o2i=o2i)\n",
    "\n",
    "o_tmf = t(o)\n",
    "test_eq_type(o_tmf[2], CatSeqI([[o2i[k][a] for a in v] for k,v in o[2].dict().items()],\n",
    "                               label = ['cat_ts_1', 'cat_ts_0']))\n",
    "test_eq(type(o_tmf[3]), type(TensorCatI([0,0])))\n",
    "\n",
    "o_b = t.decodes(o_tmf)\n",
    "test_eq(o_b, o)\n",
    "test_eq(type(o_b), type(TSMulti(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# test the other route is still working\n",
    "df = get_df([14,14])\n",
    "Mtmf = CatMultiTfm(df=df, cat_cols=['cat_ts_1', 'cat_ts_0', 'cat_0','cat_1'])\n",
    "o = TSMulti(TensorBase([1]), TensorCat(['adam','b'], label=['cat_1','cat_0']), \n",
    "            CatSeq([['david','david'],['a','b']], label=['cat_ts_1','cat_ts_0']))\n",
    "o_tmf = Mtmf.encodes(o)\n",
    "test_eq(o_tmf,TSMulti_(TensorBase([1]), TensorCatI([0,1]), CatSeqI([[0,0],[0,1]])))\n",
    "o_b = Mtmf.decodes(o_tmf)\n",
    "test_eq(o_b, o)\n",
    "test_eq(type(o_b), type(TSMulti(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class MTSDataLoader(TfmdDL):    \n",
    "    @delegates(TfmdDL.__init__)\n",
    "    def __init__(self, dataset, meta:Meta, y_name = 'x', lookback=14, horizon=7, step=1, min_seq_len=None,\n",
    "                train = True, procs = None, vocab=None, o2i=None, **kwargs):\n",
    "        assert type(meta) == Meta or type(meta) == dict\n",
    "        store_attr(self,'dataset,y_name,lookback,horizon,step,meta')\n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback) \n",
    "        self, n = make_ids(self)\n",
    "        if vocab is None: # from MTSDataLoaders\n",
    "            vocab, o2i = make_vocab(dataset, classes = self.meta['classes'])\n",
    "        kwargs['after_item'] = kwargs.get('after_item', CatMultiTfm(vocab = vocab, o2i=o2i))        \n",
    "        super().__init__(dataset=self.dataset, **kwargs)\n",
    "        self.n = n\n",
    "        self.procs = Pipeline(L(procs))\n",
    "        self.procs.setup(self, train)\n",
    "        \n",
    "    @delegates(__init__)\n",
    "    @classmethod\n",
    "    def from_path(cls, path, **kwargs):\n",
    "        return cls(get_files(path, extensions='.json'), get_meta(path),**kwargs)\n",
    "    \n",
    "    @delegates(TfmdDL.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        for k,v in {k:getattr(self,k) for k in ['meta','horizon', 'lookback', 'step']}.items():\n",
    "            if k not in kwargs:\n",
    "                kwargs[k] = v\n",
    "        res = super().new(dataset = dataset,cls= cls, y_name= self.y_name, **kwargs)\n",
    "        res, n = make_ids(res)\n",
    "        res.n = n        \n",
    "        return res    \n",
    "    \n",
    "    def create_item(self, idx):\n",
    "        if idx>=self.n:\n",
    "            raise IndexError\n",
    "        fpath, lookback_id = self._ids[idx]\n",
    "        ts = get_ts_datapoint(fpath)\n",
    "        return json2TSMulti(ts, lookback_id, self.y_name, self.lookback, self.horizon, self.meta)         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([2000, 500, 6])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= 10, horizon = 2, num_workers = 0)\n",
    "\n",
    "for o in dl:\n",
    "    assert o[0].shape[1:] == (1,10), o[0].shape\n",
    "    assert o[0].shape[1:] == (1,10), o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _show_batch_class(self, b=None, max_n=9, ctxs=None, show=True, **kwargs):\n",
    "    if b is None: b = self.one_batch()\n",
    "    x, y, its = self._pre_show_batch(b, max_n=max_n)\n",
    "    x = self.after_item.decode(TSMulti_(x))\n",
    "    if not show: return x, y, its\n",
    "    show_batch(x,y,its, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "\n",
    "MTSDataLoader.show_batch = _show_batch_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai2.vision.data import get_grid\n",
    "@typedispatch\n",
    "def show_batch(x:TSMulti, y:TensorSeq, its, *args, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        o = TSMulti([type(o)(o,**o._meta) for o in its[i] if o.shape[-1] > 0])\n",
    "        ctx = o.show(ctx=ctx)\n",
    "    return ctxs\n",
    "\n",
    "@typedispatch\n",
    "def show_batch(x:TSMulti, y:None, its, *args, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        o = TSMulti([type(o)(o[i],**o[i]._meta) for o in x if o.shape[-1] > 0])\n",
    "        ctx = o.show(ctx=ctx)\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "horizon,lookback = 2,9\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= 10, horizon = 2,)\n",
    "dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# from fastseq.data.load_pd import *\n",
    "\n",
    "@typedispatch\n",
    "def show_results(x:TSMulti, y, its, outs, ctxs=None, max_n=9,rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        r = [type(o)(o,**o._meta) for o in its[i] if o.shape[-1] > 0] \n",
    "        r.append(type(its[i][-1])(outs[i][0], label=['pred_y'], m=['r']))\n",
    "        o = TSMulti(r)        \n",
    "        ctx = o.show(ctx=ctx) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = TensorSeq([0], label = ['a'])\n",
    "a._meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class RegModel(Module):\n",
    "    def __init__(self, in_f, out_f): \n",
    "        self.a,self.b = nn.Parameter(torch.ones(in_f,in_f+out_f)), nn.Parameter(torch.zeros(in_f+out_f))\n",
    "    def forward(self, x,*args): \n",
    "        assert x.shape[1:] == (1,10), x\n",
    "        return (torch.mm(x[:,0,:],self.a) + self.b)[:,None,:]\n",
    "    \n",
    "def synth_learner(lookback, horizon, cuda=False, lr=1e-3, data=None, **kwargs):\n",
    "    return Learner(data, RegModel(lookback,horizon), lr=lr, loss_func=MSELossFlat(),\n",
    "                   opt_func=partial(SGD, mom=0.9), **kwargs)\n",
    "\n",
    "horizon,lookback = 6, 10\n",
    "df = get_df([160, 160, 160])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= lookback, horizon = horizon)\n",
    "\n",
    "learn = synth_learner(lookback, horizon, data=DataLoaders(dl, dl))\n",
    "learn.fit(1)\n",
    "learn.show_results(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# wo tsx\n",
    "class RegModel(Module):\n",
    "    def __init__(self, in_f, out_f): \n",
    "        self.a,self.b = nn.Parameter(torch.randn(in_f,in_f+out_f)),nn.Parameter(torch.randn(in_f+out_f))\n",
    "    def forward(self, x, *args): return (torch.mm(x[:,0,:],self.a) + self.b)[:,None,:]\n",
    "    \n",
    "def synth_learner(lookback, horizon, cuda=False, lr=1e-3, data=None, **kwargs):\n",
    "    return Learner(data, RegModel(lookback,horizon), lr=lr, loss_func=MSELossFlat(),\n",
    "                   opt_func=partial(SGD, mom=0.9), **kwargs)\n",
    "horizon,lookback = 2,9\n",
    "df = get_df()\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= lookback, horizon = horizon)\n",
    "learn = synth_learner(lookback, horizon, data=DataLoaders(dl, dl))\n",
    "\n",
    "learn.fit(1)\n",
    "learn.show_results(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The data will be stored in pandas DataFrames. This can be use for time series by nesting series into a cell. An example is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data.load.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/tako/dev/fastseq/fastseq/data/load.py',\n",
       " '/home/tako/dev/fastseq/nbs/02_data.load.ipynb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_add('02_data.load.ipynb', commit_msg='delete_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24584"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path('../data/m5/rows').glob('*.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
