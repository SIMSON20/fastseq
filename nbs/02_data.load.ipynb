{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastseq.core import *\n",
    "from fastseq.data.external import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.tabular.core import *\n",
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Load Dataframe\n",
    "\n",
    "\n",
    "> Using the fastai2 `Datasets` to make an time series dataset.\n",
    "\n",
    "A multivaraite time-series dataloader. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Transform catagorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_classes(df, cat_cols, classes=None):    \n",
    "    classes = ifnone(classes, {})\n",
    "    if classes == {}:\n",
    "        for col in cat_cols:\n",
    "            classes[col] = unpack_list(list(df[col]))\n",
    "    return classes\n",
    "\n",
    "def _make_vocab_df(df,cat_cols, classes = None):\n",
    "    vocab,o2i = {},{}\n",
    "    classes = _get_classes(df, cat_cols, classes)\n",
    "    for col, vals in classes.items():\n",
    "        vocab[col], o2i[col] = uniqueify(vals, sort=True, bidir=True)\n",
    "    return vocab, o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core.debugger import set_trace\n",
    "class TensorCatI(TensorBase):pass\n",
    "class CatSeqI(TensorSeq):pass\n",
    "\n",
    "class CatTfm(Transform):\n",
    "    def __init__(self, df:pd.DataFrame = None, cat_cols:[] = None,\n",
    "                 classes = None, vocab=None, o2i=None):\n",
    "        if vocab is not None and o2i is not None:\n",
    "            self.vocab,self.o2i = vocab, o2i\n",
    "        else:\n",
    "            self.vocab,self.o2i = _make_vocab_df(df,cat_cols)        \n",
    "            \n",
    "    def encodes(self, x: TensorCat):\n",
    "        r = []\n",
    "        for i, (o, key) in enumerate(zip(x.o, x._meta['label'])):\n",
    "            r.append(self.o2i[key][o])#TensorCat\n",
    "        return TensorCatI(r, label = x._meta['label'])\n",
    "\n",
    "    def decodes(self, x:TensorCatI):\n",
    "        if len(x.shape) == 1:\n",
    "            x = TensorCatI(x[None,:],**x._meta)\n",
    "        return TensorCat(reverse_lst(self._decode(TensorCatI(x.T,**x._meta))),\n",
    "                         label = x._meta.get('label', None))    \n",
    "    \n",
    "    def encodes(self, x:CatSeq):\n",
    "        r = []\n",
    "        for i,(o, key) in enumerate(zip(x.o,x._meta['label'])):\n",
    "            r.append([])\n",
    "            for a in o:\n",
    "                r[i].append(self.o2i[key][a]) #CatSeq\n",
    "        return CatSeqI(r, label = x._meta['label'])\n",
    "    \n",
    "    def decodes(self, x:CatSeqI): \n",
    "        if len(x.shape) == 2:\n",
    "            x = CatSeqI(x[None,:],**x._meta)\n",
    "        r = []\n",
    "        for o in x:\n",
    "            r.append(self._decode(CatSeqI(o,**x._meta)))\n",
    "        return CatSeq(r, label = x._meta.get('label', None))\n",
    "    \n",
    "    def _decode(self, x):   \n",
    "        r = []        \n",
    "        for i, (o, key) in enumerate(zip(x, x._meta['label'])):\n",
    "            r.append([])\n",
    "            for a in o:\n",
    "                r[i].append(self.vocab[key][a])\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vocab = {'cat_0':['a','b'],'cat_1':['adam','rdam'],\n",
    "         'cat_ts_0':['a','b'],'cat_ts_1': ['david','john']}\n",
    "tfm = CatTfm(vocab = vocab,\n",
    "             o2i = {'cat_0': {'a': 0, 'b': 1},\n",
    "                     'cat_1': {'adam': 0, 'rdam': 1},\n",
    "                     'cat_ts_0': {'a': 0, 'b': 1},\n",
    "                     'cat_ts_1': {'david': 0, 'john': 1}})\n",
    "test_eq(tfm.vocab, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_reverse_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8f742fcc7d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# check decode w batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mo_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorCatI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.name}: {self.encodes} {self.decodes}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0madd_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Delegate to `decodes` to undo transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Delegate to `setups` to set up transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/dispatch.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9d9d02a7d884>\u001b[0m in \u001b[0;36mdecodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorCatI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         return TensorCat(_reverse_lst(self._decode(TensorCatI(x.T,**x._meta))),\n\u001b[0m\u001b[1;32m     24\u001b[0m                          label = x._meta.get('label', None))    \n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_reverse_lst' is not defined"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# check decode w batch\n",
    "n = np.random.choice(2,(64,2))\n",
    "o_d = tfm.decode(TensorCatI(n, label=['cat_0','cat_1']))\n",
    "test_eq(o_d.shape,(64,2))\n",
    "for i, label in zip(range(2),['cat_0','cat_1']):\n",
    "    pred, target =o_d.o[0][i], vocab[label][n[0,i]] \n",
    "    print('cat',pred,target, n[0,i], vocab[label])\n",
    "    test_eq(pred,target)\n",
    "\n",
    "n = np.random.choice(2,(64,2,84))\n",
    "o = CatSeqI(n.astype(int), label=['cat_ts_0','cat_ts_1'])\n",
    "o_d = tfm.decode(o)\n",
    "test_eq(o_d.shape,(64,2,84))\n",
    "for i, label in zip(range(2),['cat_ts_0','cat_ts_1']):\n",
    "    print('seq', o_d.o[0][i][0], vocab[label][n[0,i,0]], n[0,i,0])\n",
    "    test_eq(o_d.o[0][i][0],vocab[label][n[0,i,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "o = TensorCat(['a','adam'], label=['cat_0','cat_1'])\n",
    "test_eq(tfm.encodes(o),tensor([0,0]))\n",
    "o = CatSeq([['a'],['david']], label=['cat_ts_0','cat_ts_1'])\n",
    "test_eq(tfm.encodes(o),tensor([[0],[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a'], ['david']]], label = ['cat_ts_0', 'cat_ts_1'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(tfm.decode(TensorCatI([0,0], label=['cat_0','cat_1'])), \n",
    "        TensorCat(['a','adam'], label=['cat_0','cat_1']) )\n",
    "\n",
    "test_eq(tfm.decode(CatSeqI([[0],[0]], label=['cat_ts_0','cat_ts_1'])),\n",
    "       CatSeq([[['a'],['david']]], label=['cat_ts_0','cat_ts_1']))\n",
    "tfm.decode(CatSeqI([[0],[0]], label=['cat_ts_0','cat_ts_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCatI([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = CatSeq([['y','z','z','z'],['adam','rdam','adam','rdam']], label = ['cat_ts_1', 'cat_ts_0'])\n",
    "df = pd.DataFrame({'cat_ts_1':[[i] for i in 'xzy'],'cat_ts_0':[[i] for i in ['adam','rdam','adam']],\n",
    "                   'cat':['john','john','david'], 'cat1':['_john','_john','_david']})\n",
    "tmf = CatTfm(df, ['cat_ts_0','cat_ts_1','cat','cat1'])\n",
    "tmf(o)\n",
    "o = TensorCat(['david','_john'], label = ['cat','cat1'])\n",
    "tmf(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (#2) ['a','b']}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[[i,'a'] for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'], {})\n",
    "print(tmf.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a', 'b', 'a', 'a']]], label = ['a'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = CatSeq([['a','b','a','a']], label='a')\n",
    "o_tmf = tmf(o)\n",
    "test_eq(o_tmf, TensorCatI([[0, 1, 0, 0]]))\n",
    "test_eq(o_tmf._meta['label'], 'a')\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o.o[0],o.o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb']})\n",
    "tmf = CatTfm(df, ['a'])\n",
    "o_tmf = tmf(TensorCat(['a'], label='a'))\n",
    "test_eq_type(o_tmf,TensorCatI([0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a'],label = 'a'))\n",
    "\n",
    "o_tmf = tmf(TensorCat(['b'], label='a'))\n",
    "test_eq_type(o_tmf,TensorCatI([1]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['b'],label='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o_tmf = tmf(TensorCat(['a','b'], label = ['a','a_2']))\n",
    "test_eq_type(o_tmf,TensorCatI([0,0]))\n",
    "test_eq(tmf.decode(o_tmf),TensorCat(['a','b'],label = 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatSeq([[['a', 'b', 'a', 'a'], ['b', 'b', 'c', 'c']]], label = ['a', 'a_2'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[i for i in 'aabb'], 'a_2':[i for i in 'bccb'],})\n",
    "tmf = CatTfm(df, ['a','a_2'])\n",
    "o = CatSeq([['a','b','a','a'],['b','b','c','c']], label=['a','a_2'])\n",
    "o_tmf = tmf(o)\n",
    "test_eq(o_tmf, CatSeqI([[0, 1, 0, 0],\n",
    "                        [0, 0, 1, 1]]))\n",
    "test_eq(o_tmf._meta['label'], ['a','a_2'])\n",
    "dec_o = tmf.decode(o_tmf)\n",
    "test_eq(dec_o.o[0],o)\n",
    "dec_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## make_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_classes(path:Path):\n",
    "    return get_meta(path)['classes']\n",
    "                    \n",
    "def make_vocab(path, classes = None):\n",
    "    if classes is None:\n",
    "        classes = get_classes(path)\n",
    "    vocab, o2i = {},{}\n",
    "    for col, vals in classes.items():\n",
    "        vocab[col], o2i[col] = uniqueify(vals, sort=True, bidir=True)\n",
    "    return vocab, o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_0': ['a', 'b'],\n",
       " 'cat_1': ['adam', 'rdam'],\n",
       " 'cat_ts_0': ['a', 'b'],\n",
       " 'cat_ts_1': ['david', 'john']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df([600, 888, 1200])\n",
    "path = Path('../data/test_data')\n",
    "save_df(df, path)\n",
    "get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_0': (#2) ['a','b'],\n",
       " 'cat_1': (#2) ['adam','rdam'],\n",
       " 'cat_ts_0': (#2) ['a','b'],\n",
       " 'cat_ts_1': (#2) ['david','john']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_vocab(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def make_ids(dl):  \n",
    "    \"\"\"Make ids if the sequence is shorter than `min_seq_len`, it will drop that sequence.\"\"\"\n",
    "    # Slice each time series into examples, assigning IDs to each\n",
    "    last_id = 0\n",
    "    n_dropped = 0\n",
    "    n_needs_padding = 0\n",
    "    dl._ids = {}\n",
    "    for f in dl.dataset:\n",
    "        dp = get_ts_datapoint(f)  \n",
    "        num_examples = (dp['_length'] - dl.lookback - dl.horizon + dl.step) // dl.step\n",
    "        # Time series shorter than the forecast horizon need to be dropped.\n",
    "        if dp['_length'] < dl.min_seq_len:\n",
    "            n_dropped += 1\n",
    "            continue\n",
    "        # For short time series zero pad the input\n",
    "        if dp['_length'] < dl.lookback + dl.horizon:\n",
    "            n_needs_padding += 1\n",
    "            num_examples = 1\n",
    "        for j in range(num_examples):\n",
    "            dl._ids[last_id + j] = (str(f), j * dl.step)\n",
    "        last_id += num_examples\n",
    "\n",
    "    # Inform user about time series that were too short\n",
    "    if n_dropped > 0:\n",
    "        print(\"Dropped {}/{} time series due to length.\".format(\n",
    "                n_dropped, len(dl.dataset)))\n",
    "\n",
    "    # Inform user about time series that were short\n",
    "    if n_needs_padding > 0:\n",
    "        print(\"Need to pad {}/{} time series due to length.\".format(\n",
    "                n_needs_padding, len(dl.dataset)))\n",
    "    # Store the number of training examples\n",
    "    dl.n = int(dl._ids.__len__() )\n",
    "    return dl, dl.n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# needs a test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## get_part_of_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x, lookback_id, length, pad=np.mean, t = tensor, **kwargs):\n",
    "    if x.shape[-1] < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = pad(x, -1)\n",
    "        x = t(np.pad(\n",
    "            x, # report issue https://github.com/numpy/numpy/issues/15606\n",
    "            pad_width=((0, 0), (length - x.shape[-1], 0)),\n",
    "            mode='constant',\n",
    "            constant_values=padding\n",
    "        ), **kwargs).float()\n",
    "        assert x.shape == (x.shape[0],length), f\"{x.shape}\\t,{lookback_id}, 'tsshape':{x.shape}\"\n",
    "    else:\n",
    "        x = t(x[:,lookback_id:lookback_id + length], **kwargs).float()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = np.vstack([np.arange(10.)]*2)\n",
    "test_eq(get_part_of_ts(x, 2, 5), torch.cat([torch.arange(2,7.)[None,:]]*2))\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                          [4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))\n",
    "\n",
    "# report issue https://github.com/numpy/numpy/issues/15606\n",
    "x = np.arange(10.)[None,:]\n",
    "test_eq(get_part_of_ts(x, 0, 11), tensor([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "x = np.arange(10.)[None,:]\n",
    "o =get_part_of_ts(x, 0, 11, t = TensorBase, label='a')\n",
    "test_eq_type(o, TensorBase([[4.5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])) \n",
    "test_eq(o._meta, {'label':'a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def get_part_of_ts(x:list, lookback_id, length, t = L, **kwargs):\n",
    "    if len(x[0]) < length:\n",
    "        # If the time series is too short, we pad\n",
    "        padding = [o[-1] for o in x]\n",
    "        pad_len = length - len(x[0])\n",
    "        x = [o[lookback_id:lookback_id + length] + [padding[i]]*pad_len for i,o in enumerate(x)]\n",
    "    else:\n",
    "        x = [o[lookback_id:lookback_id + length] for o in x]\n",
    "    return t(x, **kwargs)\n",
    "\n",
    "@typedispatch\n",
    "def get_part_of_ts(x:L, *args, **kwargs):\n",
    "    return get_part_of_ts(list(x),*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*5,['z','x']*5)\n",
    "o =get_part_of_ts(x, 1, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = L(['a','b']*2, ['z','x']*2)\n",
    "o =get_part_of_ts(x, 0, 5)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "x = [[1,2]*2, [10,11]*2]\n",
    "o =get_part_of_ts(x, 0, 5, t = TensorSeq)\n",
    "test_eq(len(o), 2)\n",
    "for a in o:\n",
    "    test_eq(len(a),5)\n",
    "test_eq(type(o),TensorSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## get_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def split_ts_con(ts, y_name, meta:Meta):  \n",
    "    ts_con_names = [o for o in meta['col_names']['ts_con_names'] if o != y_name]\n",
    "    y = ts['ts_con'][y_name]\n",
    "    tsx = [ts['ts_con'][k] for k in ts_con_names]\n",
    "    return y, tsx, ts_con_names\n",
    "    \n",
    "\n",
    "def json2TSMulti(ts, lookback_id, y_name, lookback, horizon, meta:Meta):\n",
    "    y, tsx, ts_con_names = split_ts_con(ts, y_name, meta)\n",
    "    \n",
    "    y = get_part_of_ts([y], lookback_id, lookback + horizon,\n",
    "                       t = TensorSeq, label=[y_name + '_y'], m=['g'])\n",
    "    x = TensorSeq(y[:,:lookback], label=[y_name + '_x'], m=['g'])\n",
    "    tsx_con = get_part_of_ts(tsx, lookback_id, lookback + horizon,\n",
    "                             t = TensorSeq, label=ts_con_names)\n",
    "    tsx_cat = get_part_of_ts(ts.get_ts(meta,'ts_cat'), lookback_id, lookback + horizon,\n",
    "                             t = CatSeq, label=meta['col_names']['ts_cat_names'])        \n",
    "    r = [x, tsx_con, tsx_cat]\n",
    "    r.append(TensorCat(ts.get_ts(meta,'cat'), label=meta['col_names']['cat_names']))\n",
    "    r.append(TensorCon(ts.get_ts(meta,'con'), label=meta['col_names']['con_names']))      \n",
    "    r.append(y)\n",
    "    return TSMulti(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([2000, 2000, 2000])\n",
    "path = Path('../data/test_data')\n",
    "save_df(df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"<class 'fastseq.core.TensorSeq'>0\": torch.Size([1, 100]), \"<class 'fastseq.core.TensorSeq'>1\": torch.Size([2, 110]), \"<class 'fastseq.core.CatSeq'>2\": (2, 110), \"<class 'fastseq.core.TensorCat'>3\": (2,), \"<class 'fastseq.core.TensorCon'>4\": torch.Size([2]), \"<class 'fastseq.core.TensorSeq'>5\": torch.Size([1, 110])}\n"
     ]
    }
   ],
   "source": [
    "ts = get_ts_datapoint('../data/test_data/1.json')\n",
    "r = json2TSMulti(ts, 1000, 'x',100, 10, get_meta(path))\n",
    "test_eq(len(r), 6)\n",
    "print({str(type(a))+str(i):a.shape for i,a in enumerate(r)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Multi Tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class TSMulti_(Tuple):\n",
    "    def _dict(self):\n",
    "        return {str(str(i)+'_'+str(type(a))):a.shape for i,a in enumerate(self)}\n",
    "\n",
    "class CatMultiTfm(ItemTransform):\n",
    "    @delegates(CatTfm.__init__)\n",
    "    def __init__(self, **kwargs): # maybe change to proccs\n",
    "        self.f = CatTfm(**kwargs)\n",
    "        \n",
    "    def encodes(self, o):\n",
    "        return TSMulti_(self.f(a) for a in o)\n",
    "    \n",
    "    def decodes(self, o): \n",
    "        return TSMulti(self.f.decode(a) for a in o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"0_<class 'torch.Tensor'>\": torch.Size([1]),\n",
       " \"1_<class 'torch.Tensor'>\": torch.Size([2])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSMulti_([Tensor([0]),Tensor([0,0])])._dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([[['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']]], label = ['cat_ts_1', 'cat_ts_0']), TensorCat([['a', 'adam']], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']], label = ['cat_ts_1', 'cat_ts_0']), TensorCat(['a', 'adam'], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e786d28dcbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mo_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_tmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTSMulti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/env37/lib/python3.7/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([[['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']]], label = ['cat_ts_1', 'cat_ts_0']), TensorCat([['a', 'adam']], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))\n(TensorSeq([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]), TensorSeq([[-0.4199, -0.1673,  0.8318,  4.2033,  3.5605,  5.9692,  4.0763,  5.9643,\n          6.9324,  9.9193,  9.6206, 10.9779, 12.1044],\n        [ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n          8.0000,  9.0000, 10.0000, 11.0000, 12.0000]]), CatSeq([['david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david', 'john', 'david'], ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a']], label = ['cat_ts_1', 'cat_ts_0']), TensorCat(['a', 'adam'], label = ['cat_0', 'cat_1']), TensorCon([10.5795, -0.0716]), TensorSeq([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]]))"
     ]
    }
   ],
   "source": [
    "df = get_df([14,14,16])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "o = json2TSMulti(get_ts_datapoint(get_files(path,extensions='.json')[0]), 0, 'x', 10, 3, get_meta(path))\n",
    "\n",
    "vocab,o2i = make_vocab(get_files(path,extensions='.json'), get_meta(path)['classes'])\n",
    "t = CatMultiTfm(vocab = vocab, o2i=o2i)\n",
    "\n",
    "o_tmf = t(o)\n",
    "test_eq_type(o_tmf[2], CatSeqI([[o2i[k][a] for a in v] for k,v in o[2].dict().items()],\n",
    "                               label = ['cat_ts_1', 'cat_ts_0']))\n",
    "test_eq(type(o_tmf[3]), type(TensorCatI([0,0])))\n",
    "\n",
    "o_b = t.decodes(o_tmf)\n",
    "test_eq(o_b, o)\n",
    "test_eq(type(o_b), type(TSMulti(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# test the other route is still working\n",
    "df = get_df([14,14])\n",
    "Mtmf = CatMultiTfm(df=df, cat_cols=['cat_ts_1', 'cat_ts_0', 'cat_0','cat_1'])\n",
    "o = TSMulti(TensorBase([1]), TensorCat(['adam','b'], label=['cat_1','cat_0']), \n",
    "            CatSeq([['david','david'],['a','b']], label=['cat_ts_1','cat_ts_0']))\n",
    "o_tmf = Mtmf.encodes(o)\n",
    "test_eq(o_tmf,TSMulti_(TensorBase([1]), TensorCatI([0,1]), CatSeqI([[0,0],[0,1]])))\n",
    "o_b = Mtmf.decodes(o_tmf)\n",
    "test_eq(o_b, o)\n",
    "test_eq(type(o_b), type(TSMulti(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class MTSDataLoader(TfmdDL):    \n",
    "    @delegates(TfmdDL.__init__)\n",
    "    def __init__(self, dataset, meta:Meta, y_name = 'x', lookback=14, horizon=7, step=1, min_seq_len=None,\n",
    "                train = True, procs = None, vocab=None, o2i=None, **kwargs):\n",
    "        assert type(meta) == Meta or type(meta) == dict\n",
    "        store_attr(self,'dataset,y_name,lookback,horizon,step,meta')\n",
    "        self.min_seq_len = ifnone(min_seq_len, lookback) \n",
    "        self, n = make_ids(self)\n",
    "        if vocab is None: # from MTSDataLoaders\n",
    "            vocab, o2i = make_vocab(dataset, classes = self.meta['classes'])\n",
    "        kwargs['after_item'] = kwargs.get('after_item', CatMultiTfm(vocab = vocab, o2i=o2i))        \n",
    "        super().__init__(dataset=self.dataset, **kwargs)\n",
    "        self.n = n\n",
    "        self.procs = Pipeline(L(procs))\n",
    "        self.procs.setup(self, train)\n",
    "        \n",
    "    @delegates(__init__)\n",
    "    @classmethod\n",
    "    def from_path(cls, path, **kwargs):\n",
    "        return cls(get_files(path, extensions='.json'), get_meta(path),**kwargs)\n",
    "    \n",
    "    @delegates(TfmdDL.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        for k,v in {k:getattr(self,k) for k in ['meta','horizon', 'lookback', 'step']}.items():\n",
    "            if k not in kwargs:\n",
    "                kwargs[k] = v\n",
    "        res = super().new(dataset = dataset,cls= cls, y_name= self.y_name, **kwargs)\n",
    "        res, n = make_ids(res)\n",
    "        res.n = n        \n",
    "        return res    \n",
    "    \n",
    "    def create_item(self, idx):\n",
    "        if idx>=self.n:\n",
    "            raise IndexError\n",
    "        fpath, lookback_id = self._ids[idx]\n",
    "        ts = get_ts_datapoint(fpath)\n",
    "        return json2TSMulti(ts, lookback_id, self.y_name, self.lookback, self.horizon, self.meta)         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = get_df([2000, 500, 6])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= 10, horizon = 2, num_workers = 0)\n",
    "\n",
    "for o in dl:\n",
    "    assert o[0].shape[1:] == (1,10), o[0].shape\n",
    "    assert o[0].shape[1:] == (1,10), o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _show_batch_class(self, b=None, max_n=9, ctxs=None, show=True, **kwargs):\n",
    "    if b is None: b = self.one_batch()\n",
    "    x, y, its = self._pre_show_batch(b, max_n=max_n)\n",
    "    x = self.after_item.decode(TSMulti_(x))\n",
    "    if not show: return x, y, its\n",
    "    show_batch(x,y,its, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "\n",
    "MTSDataLoader.show_batch = _show_batch_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai2.vision.data import get_grid\n",
    "@typedispatch\n",
    "def show_batch(x:TSMulti, y:TensorSeq, its, *args, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        o = TSMulti([type(o)(o,**o._meta) for o in its[i] if o.shape[-1] > 0])\n",
    "        ctx = o.show(ctx=ctx)\n",
    "    return ctxs\n",
    "\n",
    "@typedispatch\n",
    "def show_batch(x:TSMulti, y:None, its, *args, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        o = TSMulti([type(o)(o[i],**o[i]._meta) for o in x if o.shape[-1] > 0])\n",
    "        ctx = o.show(ctx=ctx)\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "horizon,lookback = 2,9\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= 10, horizon = 2,)\n",
    "dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# from fastseq.data.load_pd import *\n",
    "\n",
    "@typedispatch\n",
    "def show_results(x:TSMulti, y, its, outs, ctxs=None, max_n=9,rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), add_vert=1, figsize=figsize, **kwargs)\n",
    "    for i, ctx in enumerate(ctxs):  \n",
    "        r = [type(o)(o,**o._meta) for o in its[i] if o.shape[-1] > 0] \n",
    "        r.append(type(its[i][-1])(outs[i][0], label=['pred_y'], m=['r']))\n",
    "        o = TSMulti(r)        \n",
    "        ctx = o.show(ctx=ctx) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = TensorSeq([0], label = ['a'])\n",
    "a._meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class RegModel(Module):\n",
    "    def __init__(self, in_f, out_f): \n",
    "        self.a,self.b = nn.Parameter(torch.ones(in_f,in_f+out_f)), nn.Parameter(torch.zeros(in_f+out_f))\n",
    "    def forward(self, x,*args): \n",
    "        assert x.shape[1:] == (1,10), x\n",
    "        return (torch.mm(x[:,0,:],self.a) + self.b)[:,None,:]\n",
    "    \n",
    "def synth_learner(lookback, horizon, cuda=False, lr=1e-3, data=None, **kwargs):\n",
    "    return Learner(data, RegModel(lookback,horizon), lr=lr, loss_func=MSELossFlat(),\n",
    "                   opt_func=partial(SGD, mom=0.9), **kwargs)\n",
    "\n",
    "horizon,lookback = 6, 10\n",
    "df = get_df([160, 160, 160])\n",
    "save_df(df, path)\n",
    "path = Path('../data/test_data')\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= lookback, horizon = horizon)\n",
    "\n",
    "learn = synth_learner(lookback, horizon, data=DataLoaders(dl, dl))\n",
    "learn.fit(1)\n",
    "learn.show_results(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# wo tsx\n",
    "class RegModel(Module):\n",
    "    def __init__(self, in_f, out_f): \n",
    "        self.a,self.b = nn.Parameter(torch.randn(in_f,in_f+out_f)),nn.Parameter(torch.randn(in_f+out_f))\n",
    "    def forward(self, x, *args): return (torch.mm(x[:,0,:],self.a) + self.b)[:,None,:]\n",
    "    \n",
    "def synth_learner(lookback, horizon, cuda=False, lr=1e-3, data=None, **kwargs):\n",
    "    return Learner(data, RegModel(lookback,horizon), lr=lr, loss_func=MSELossFlat(),\n",
    "                   opt_func=partial(SGD, mom=0.9), **kwargs)\n",
    "horizon,lookback = 2,9\n",
    "df = get_df()\n",
    "dl = MTSDataLoader.from_path(path, y_name = 'x', lookback= lookback, horizon = horizon)\n",
    "learn = synth_learner(lookback, horizon, data=DataLoaders(dl, dl))\n",
    "\n",
    "learn.fit(1)\n",
    "learn.show_results(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The data will be stored in pandas DataFrames. This can be use for time series by nesting series into a cell. An example is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data.load.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/tako/dev/fastseq/fastseq/data/load.py',\n",
       " '/home/tako/dev/fastseq/nbs/02_data.load.ipynb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_add('02_data.load.ipynb', commit_msg='delete_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24584"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path('../data/m5/rows').glob('*.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
