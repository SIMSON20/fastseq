{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nbeats.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Beats Callbacks\n",
    "\n",
    "> A basic architecture for time series forecasting.\n",
    "\n",
    "\n",
    "The approach is based on https://arxiv.org/abs/1905.10437\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.hook import num_features_model\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.torch_core import *\n",
    "from torch.autograd import Variable\n",
    "from fastseq.all import *\n",
    "\n",
    "from fastseq.nbeats.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsLossPart(Metric):\n",
    "    \"The loss according to the `loss_func` on a particular part of the time-serie.\"\n",
    "    def __init__(self, start, end, name, *args, **kwargs):\n",
    "        store_attr(self,\"start,end\")\n",
    "        self._name = name\n",
    "        \n",
    "    def reset(self):           self.total,self.count = 0.,0\n",
    "    def accumulate(self, learn):\n",
    "        bs = find_bs(learn.yb)      \n",
    "        pred, truth = learn.pred, learn.yb[0]\n",
    "        if len(pred.shape) == 2:\n",
    "            pred = pred[:,None,:]\n",
    "            truth = truth[:,None,:]\n",
    "        assert pred[:,0,self.start:self.end].shape == truth[:,0,self.start:self.end].shape \n",
    "        loss = to_detach(learn.loss_func(pred[:,0,self.start:self.end], truth[:,0,self.start:self.end])) / truth[:,0,self.start:self.end].shape[-1]\n",
    "        self.total += loss.mean()*bs        \n",
    "        self.count += bs\n",
    "    @property\n",
    "    def value(self): return self.total/self.count if self.count != 0 else None\n",
    "    @property\n",
    "    def name(self):  return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 85)\n",
      "Train:40; Valid: 20; Test 10\n",
      "(1, 85)\n",
      "Train:10; Valid: 160; Test 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>Last</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.335197</td>\n",
       "      <td>3.763645</td>\n",
       "      <td>0.078127</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.021630</td>\n",
       "      <td>4.713816</td>\n",
       "      <td>0.101483</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "horizon, lookback = 10,40\n",
    "items = dummy_data_generator(75, 10, nrows=10)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=3, valid_pct=.5\n",
    "                               )\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon,lookback = lookback, bs=32)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsLossPart(0,-10,'Last')],\n",
    "#                 cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "learn.loss_func\n",
    "learn.fit(2,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1020])\n",
      "Train:644; Valid: 18; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>Last</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.777536</td>\n",
       "      <td>2.382557</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.936579</td>\n",
       "      <td>1.758298</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataLoaders.from_folder(path, horizon = horizon, lookback = lookback, nrows = 3, step=3, max_std=5)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsLossPart(0,-10,'Last')],\n",
    "#                 cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "learn.loss_func\n",
    "learn.fit(2,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsBackwards(NBeatsLossPart):\n",
    "    \"The loss according to the `loss_func` on the backwards part of the time-serie.\"    \n",
    "    def __init__(self, lookback, *args, **kwargs):\n",
    "        super().__init__(0, lookback, 'b_loss', *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\n",
      "Need to pad 3/3 time series due to length.\n",
      "Train:3; Valid: 3; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>b_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>4.181420</td>\n",
       "      <td>0.069730</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.660353</td>\n",
       "      <td>6.155954</td>\n",
       "      <td>0.097354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "items = dummy_data_generator(50, 10, nrows=3)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon,lookback = lookback, bs=32)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsBackwards(lookback)],\n",
    "#                 cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "learn.loss_func\n",
    "learn.fit(2,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsForward(NBeatsLossPart):\n",
    "    \"The loss according to the `loss_func` on the forward part of the time-serie.\"  \n",
    "    def __init__(self, lookback, *args, **kwargs):\n",
    "        super().__init__(lookback, None, 'f_loss', *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\n",
      "Need to pad 3/3 time series due to length.\n",
      "Train:3; Valid: 3; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.235949</td>\n",
       "      <td>7.458382</td>\n",
       "      <td>0.358423</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.915194</td>\n",
       "      <td>5.401644</td>\n",
       "      <td>0.281416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.551182</td>\n",
       "      <td>11.299735</td>\n",
       "      <td>0.405245</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "items = dummy_data_generator(50, 10, nrows=3)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon,lookback = lookback, bs=32)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsForward(lookback)],\n",
    "               )\n",
    "learn.loss_func\n",
    "learn.fit(3,.1)\n",
    "test_eq(type(learn.metrics[0].value), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1020])\n",
      "Train:644; Valid: 18; Test 3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NBeatsTheta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-51c2ae9c4172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNBeatsNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=L(None)+L(mae, smape, NBeatsTheta(), \n\u001b[0m\u001b[1;32m      6\u001b[0m                                          NBeatsBackwards(lookback), NBeatsForward(lookback)),)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NBeatsTheta' is not defined"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataLoaders.from_folder(path, horizon = horizon, lookback = lookback, nrows = 3, step=3, max_std=5)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=L(None)+L(mae, smape, NBeatsTheta(), \n",
    "                                         NBeatsBackwards(lookback), NBeatsForward(lookback)),)\n",
    "\n",
    "learn.fit(3, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_key_from_nested_dct(dct, s_key, exclude = [], namespace=''):\n",
    "    r = {}\n",
    "    for key in dct.keys():\n",
    "        if sum([exc in key for exc in exclude])== 0 :\n",
    "            if type(dct[key]) == dict:\n",
    "                r.update(_get_key_from_nested_dct(dct[key], s_key, exclude, namespace=namespace+key))\n",
    "            if s_key in key:\n",
    "                r[namespace+key] = dct[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'foo':{'bar':1},'bar':2,'foo2':{'foo3':3},'ignore':{'bar':1000}}\n",
    "r = _get_key_from_nested_dct(dct,'bar',['ignore'])\n",
    "test_eq(r,{'foobar': 1, 'bar': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsTheta(Metric):\n",
    "    \"The sqaure of the `theta` for every block. \"\n",
    "    def reset(self):           self.total,self.count = 0.,0\n",
    "    def accumulate(self, learn):\n",
    "        bs = find_bs(learn.yb)   \n",
    "        theta_dct = _get_key_from_nested_dct(learn.model.dct,'theta',['bias','total','att'])\n",
    "        t = torch.sum(tensor([v.float().abs().mean() for k,v in theta_dct.items()]))\n",
    "        self.total += to_detach(t.abs().mean())*bs\n",
    "        self.count += bs\n",
    "    @property\n",
    "    def value(self): return self.total/self.count if self.count != 0 else None\n",
    "    @property\n",
    "    def name(self):  return \"theta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon, lookback = 7,10\n",
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataLoaders.from_folder(path, horizon = horizon, lookback = lookback, nrows = 3, step=3, max_std=5)\n",
    "\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsTheta()],\n",
    "               )\n",
    "\n",
    "learn.fit(3,.1)\n",
    "test_eq(type(learn.metrics[0].value),Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NBeatsAttention(Callback):  \n",
    "    def means(self, df=True):\n",
    "        theta_means = {k.replace('theta',''):v.float().cpu().data for k,v in _get_key_from_nested_dct(self.learn.model.dct,'theta',['total']).items()}\n",
    "        ret = {}\n",
    "        for k,v in theta_means.items():\n",
    "            ret[k] = {}\n",
    "            for i in range(v.shape[-1]):\n",
    "                ret[k].update({'theta_'+str(i)+'_mean': v[:,i].mean().numpy(),\n",
    "                               'theta_'+str(i)+'_std': v[:,i].std().numpy(),\n",
    "                              })\n",
    "            \n",
    "        att = {k.replace('attention','att_mean'):v.float().cpu().numpy() for k,v in _get_key_from_nested_dct(self.learn.model.dct,'att',['total']).items()}\n",
    "        for k in ret.keys():\n",
    "            for att_key in att.keys():\n",
    "                if k in att_key:\n",
    "                    ret[k].update({'att_mean':att[att_key].mean(),\n",
    "                                   'att_std':att[att_key].std(),\n",
    "                                  })\n",
    "                \n",
    "        if df:\n",
    "            return pd.DataFrame(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon, lookback = 7,10\n",
    "items = L(np.arange(-5,100)[None,:],np.arange(500,550)[None,:],np.arange(-110,-56)[None,:]).map(tensor)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                             )\n",
    "mdl = NBeatsNet(device = data.train.device,horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=L(mae, smape, NBeatsTheta(), \n",
    "                                         NBeatsBackwards(lookback), NBeatsForward(lookback)),\n",
    "                cbs=L( NBeatsAttention()\n",
    "                     )\n",
    "               )\n",
    "learn.fit(3,.1)\n",
    "df = learn.n_beats_attention.means()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def CombinedLoss(loss_func, lookback, ratio = [1,1]):\n",
    "    def _inner(pred, truth, *args, **kwargs):\n",
    "        if len(pred.shape) == 2:\n",
    "            pred = pred[:,None,:]\n",
    "            truth = truth[:,None,:]\n",
    "        loss = loss_func(pred[:,:,:lookback],truth[:,:,:lookback], *args, **kwargs) * ratio[0]\n",
    "        loss += loss_func(pred[:,:,lookback:],truth[:,:,lookback:], *args, **kwargs) * ratio[1]\n",
    "        return loss\n",
    "    \n",
    "    return _inner\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 7\n",
    "y, y_hat = torch.arange(10).float()[None,None,:], torch.arange(10)[None,None,:].float()+torch.randn(10)\n",
    "loss_fnc = CombinedLoss(F.mse_loss,lookback)\n",
    "test_eq(F.mse_loss(y[:,:,:7],y_hat[:,:,:7])+F.mse_loss(y[:,:,7:],y_hat[:,:,7:]),loss_fnc(y, y_hat))\n",
    "\n",
    "r = 10\n",
    "loss_fnc = CombinedLoss(F.mse_loss, lookback, ratio = [1,r])\n",
    "loss = loss_fnc(y, y_hat)\n",
    "test_eq(F.mse_loss(y[:,:,:7],y_hat[:,:,:7])+F.mse_loss(y[:,:,7:],y_hat[:,:,7:])*r,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "y, y_hat = torch.arange(10).float()[None,:], torch.arange(10)[None,:].float()+torch.randn(10)\n",
    "loss_fnc = CombinedLoss(F.mse_loss,lookback)\n",
    "test_eq(F.mse_loss(y[:,:7],y_hat[:,:7])+F.mse_loss(y[:,7:],y_hat[:,7:]),loss_fnc(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ClipLoss(Callback):\n",
    "    \"`Callback` that adds weights regularization the thetas in N-Beats training.\"\n",
    "    def __init__(self, clip=5):\n",
    "        self.clip = tensor([clip])\n",
    "\n",
    "    def after_loss(self):\n",
    "        self.learn.loss = torch.clamp(self.learn.loss, 0, self.clip.numpy()[0])\n",
    "        \n",
    "#     def after_backward(self):\n",
    "#         nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon, lookback = 2,10\n",
    "items = L(np.arange(-5,30)[None,:],np.arange(50)[None,:]).map(tensor)\n",
    "items[-1][:,-8:-5] = 1e10\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                             )\n",
    "mdl = NBeatsNet(device = data.train.device,horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, \n",
    "                cbs=L(ClipLoss()\n",
    "                     )\n",
    "               )\n",
    "\n",
    "learn.fit(10,.1)\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# old stuff\n",
    "###################################################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "class NBeatsBLoss(Callback): \n",
    "    def __init__(self,alpha = 1):store_attr(self,'alpha')\n",
    "    def after_loss(self):\n",
    "#         print('pre',self.learn.loss,self.n_beats_trainer.out['total_b_loss'].mean())\n",
    "        self.learn.loss = self.learn.loss + self.n_beats_trainer.out['total_b_loss'].mean()*self.alpha\n",
    "#         print('after',self.learn.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "horizon, lookback = 7,30\n",
    "items = L(np.arange(-5,100)[None,:],np.arange(250,550)[None,:],np.arange(-110,-56)[None,:]).map(tensor)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                               )\n",
    "thetas_dim= (2,4)\n",
    "mdl = NBeatsNet(device = data.train.device, nb_blocks_per_stack = 1, horizon=horizon, lookback=lookback, thetas_dim=thetas_dim)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics = [smape,NBeatsBackwards(lookback)],\n",
    "                cbs=L(NBeatsAttention(),\n",
    "                     )\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# test_eq(list(df.columns),[o+str(i)+'_0' for i,o in enumerate(stack_types)])\n",
    "# test_eq('att_mean' in list(df.axes[0]), True)\n",
    "# test_eq('att_std' in list(df.axes[0]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# TODO maybe add extra backwards loss also in a callback??\n",
    "class NBeatsTrainer(Callback):\n",
    "    \"`Callback` that adds weights regularization the thetas in N-Beats training.\"\n",
    "    def __init__(self, theta=0., b_loss=0.): \n",
    "        self.theta, self.b_loss = theta, b_loss\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        self.b = None\n",
    "\n",
    "    def begin_train(self): \n",
    "        self.out = defaultdict(dict)\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        \n",
    "    def begin_validate(self): \n",
    "        self.out = defaultdict(dict)\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        \n",
    "    def after_pred(self):\n",
    "        self.b = self.pred[1] \n",
    "        self.pred[2]['total_b'] = self.pred[1] \n",
    "        self.out = concat_dct(self.pred[2], self.out)   \n",
    "        self.learn.pred = self.pred[0]\n",
    "\n",
    "    def after_loss(self):        \n",
    "        # theta\n",
    "        value=tensor([0.])\n",
    "        for key in self.out.keys():\n",
    "            if 'bias' not in key and 'total' not in key and 'att' not in key:\n",
    "                v = self.out[key]['theta'].float().pow(2).mean()\n",
    "                if self.theta != 0.:     \n",
    "                    self.learn.loss += self.theta * v.item()\n",
    "                value = value + v\n",
    "        self.metrics['theta'] += value.clone().cpu().detach()\n",
    "        \n",
    "        # backwards \n",
    "        value = self.learn.loss_func(self.b.float(), *self.xb, reduction='mean') \n",
    "        if self.b_loss != 0.:\n",
    "            self.learn.loss += self.b_loss * value.mean() \n",
    "        self.metrics['b_loss'] += value.sum().clone().detach()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 05_nbeats.models.ipynb.\n",
      "Converted 06_nbeats.callbacks.ipynb.\n",
      "Converted 07_nbeats.learner.ipynb.\n",
      "Converted 08_nbeats.interpret.ipynb.\n",
      "Converted 11_metrics.ipynb.\n",
      "Converted 12_compare.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
