{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nbeats.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Beats metrics\n",
    "\n",
    "> A basic architecture for time series forecasting.\n",
    "\n",
    "\n",
    "The approach is based on https://arxiv.org/abs/1905.10437\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.hook import num_features_model\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.torch_core import *\n",
    "from torch.autograd import Variable\n",
    "from fastseq.all import *\n",
    "\n",
    "from fastseq.nbeats.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_key_from_nested_dct(dct, s_key, exclude = [], namespace=''):\n",
    "    r = {}\n",
    "    for key in dct.keys():\n",
    "        if sum([exc in key for exc in exclude])== 0 :\n",
    "            if type(dct[key]) == dict:\n",
    "                r.update(_get_key_from_nested_dct(dct[key], s_key, exclude, namespace=namespace+key))\n",
    "            if s_key in key:\n",
    "                r[namespace+key] = dct[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'foo':{'bar':1},'bar':2,'foo2':{'foo3':3},'ignore':{'bar':1000}}\n",
    "r = _get_key_from_nested_dct(dct,'bar',['ignore'])\n",
    "test_eq(r,{'foobar': 1, 'bar': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsTheta(Metric):\n",
    "    \"The sqaure of the `theta` for every block. \"\n",
    "    def reset(self):           self.total,self.count = 0.,0\n",
    "    def accumulate(self, learn):\n",
    "        bs = find_bs(learn.yb)         \n",
    "        theta_dct = _get_key_from_nested_dct(learn.n_beats_trainer.out,'theta',['bias','total','att'])\n",
    "        t = torch.cat([v.float() for k,v in theta_dct.items()])\n",
    "        self.total += to_detach(t.abs().mean())*bs\n",
    "        self.count += bs\n",
    "    @property\n",
    "    def value(self): return self.total/self.count if self.count != 0 else None\n",
    "    @property\n",
    "    def name(self):  return \"theta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:89; Valid: 33; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>theta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.241432</td>\n",
       "      <td>0.869343</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.196145</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.211596</td>\n",
       "      <td>0.653569</td>\n",
       "      <td>0.346030</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "horizon, lookback = 7,10\n",
    "items = L(np.arange(-5,100)[None,:],np.arange(500,550)[None,:],np.arange(-110,-56)[None,:]).map(tensor)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                               )\n",
    "\n",
    "mdl = NBeatsNet(device = data.train.device, stack_types=('trend','seaonality'), horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsTheta()],\n",
    "                cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "\n",
    "learn.fit(3,.1)\n",
    "test_eq(type(learn.metrics[0].value),Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsBackwards(Metric):\n",
    "    \"The loss according to the `loss_func` on the backwards part of the time-serie.\"\n",
    "    def reset(self):           self.total,self.count = 0.,0\n",
    "    def accumulate(self, learn):\n",
    "        bs = find_bs(learn.yb)   \n",
    "        b = learn.n_beats_trainer.out['total_b']\n",
    "        value = learn.loss_func(b.float(), *learn.xb, reduction='mean')\n",
    "        self.total += to_detach(value)*bs\n",
    "        self.count += bs\n",
    "    @property\n",
    "    def value(self): return self.total/self.count if self.count != 0 else None\n",
    "    @property\n",
    "    def name(self):  return \"b_loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-6d639892ec7d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-6d639892ec7d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    bs=32)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "horizon, lookback = 7,10\n",
    "items = L(np.arange(-5,100)[None,:],np.arange(500,550)[None,:],np.arange(-110,-56)[None,:]).map(tensor)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                             )\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsBackwards()],\n",
    "                cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "\n",
    "learn.fit(3,.1)\n",
    "test_eq(type(learn.metrics[0].value), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:60; Valid: 33; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>b_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32.654736</td>\n",
       "      <td>6.737724</td>\n",
       "      <td>26.960171</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22.758030</td>\n",
       "      <td>6.279469</td>\n",
       "      <td>26.019876</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.450945</td>\n",
       "      <td>6.912870</td>\n",
       "      <td>27.208954</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Using a target size (torch.Size([1, 1, 10])) that is different to the input size (torch.Size([33, 1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "items = dummy_data_generator(50, 10, nrows=3)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon,lookback = lookback, bs=32)\n",
    "mdl = NBeatsNet(device = data.train.device, horizon=horizon, lookback=lookback)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, metrics=[NBeatsBackwards()],\n",
    "                cbs=L(NBeatsTrainer())\n",
    "               )\n",
    "\n",
    "learn.fit(3,.1)\n",
    "test_eq(type(learn.metrics[0].value), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NBeatsAttention(Callback):  \n",
    "    def means(self, df=True):\n",
    "        theta_means = {k.replace('theta',''):v.float().cpu().data for k,v in _get_key_from_nested_dct(self.learn.n_beats_trainer.out,'theta',['total']).items()}\n",
    "        ret = {}\n",
    "        for k,v in theta_means.items():\n",
    "            ret[k] = {}\n",
    "            for i in range(v.shape[-1]):\n",
    "                ret[k].update({'theta_'+str(i)+'_mean': v[:,i].mean().numpy(),\n",
    "                               'theta_'+str(i)+'_std': v[:,i].std().numpy(),\n",
    "                              })\n",
    "            \n",
    "        att = {k.replace('attention','att_mean'):v.float().cpu().numpy() for k,v in _get_key_from_nested_dct(self.learn.n_beats_trainer.out,'att',['total']).items()}\n",
    "        for k in ret.keys():\n",
    "            for att_key in att.keys():\n",
    "                if k in att_key:\n",
    "                    ret[k].update({'att_mean':att[att_key].mean(),\n",
    "                                   'att_std':att[att_key].std(),\n",
    "                                  })\n",
    "                \n",
    "        if df:\n",
    "            return pd.DataFrame(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:89; Valid: 33; Test 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.125904</td>\n",
       "      <td>5.970752</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30.452126</td>\n",
       "      <td>4.298546</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24.662178</td>\n",
       "      <td>3.319638</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend0_0</th>\n",
       "      <th>seaonality1_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>theta_0_mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_0_std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_1_mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_1_std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_2_mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_2_std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_3_mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta_3_std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_std</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trend0_0 seaonality1_0\n",
       "theta_0_mean      0.0           1.0\n",
       "theta_0_std       0.0           0.0\n",
       "theta_1_mean      0.0           1.0\n",
       "theta_1_std       0.0           0.0\n",
       "theta_2_mean      0.0           NaN\n",
       "theta_2_std       0.0           NaN\n",
       "theta_3_mean      0.0           NaN\n",
       "theta_3_std       0.0           NaN\n",
       "att_mean            0             1\n",
       "att_std             0             0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon, lookback = 7,10\n",
    "items = L(np.arange(-5,100)[None,:],np.arange(500,550)[None,:],np.arange(-110,-56)[None,:]).map(tensor)\n",
    "data = TSDataLoaders.from_items(items, horizon = horizon, lookback=lookback, step=1, after_batch = NormalizeTS()\n",
    "                               )\n",
    "stack_types = ('trend','seaonality')\n",
    "thetas_dim= (4,2)\n",
    "mdl = NBeatsNet(device = data.train.device, stack_types=stack_types, nb_blocks_per_stack = 1, horizon=horizon, lookback=lookback, thetas_dim=thetas_dim)\n",
    "loss_func = F.mse_loss\n",
    "learn = Learner(data, mdl, loss_func=loss_func, opt_func= Adam, \n",
    "                cbs=L(NBeatsTrainer(), NBeatsAttention()\n",
    "                     )\n",
    "               )\n",
    "\n",
    "learn.fit(3,.1)\n",
    "df = learn.n_beats_attention.means()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "test_eq(list(df.columns),[o+str(i)+'_0' for i,o in enumerate(stack_types)])\n",
    "test_eq('att_mean' in list(df.axes[0]), True)\n",
    "test_eq('att_std' in list(df.axes[0]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# old stuff\n",
    "###################################################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# TODO\n",
    "def CombinedLoss(*losses, ratio:dict=None):\n",
    "    _ratio = defaultdict(lambda:1.)\n",
    "    if ratio is not None:\n",
    "        _ratio.update(ratio)    \n",
    "    ratio = _ratio\n",
    "    \n",
    "    def _inner(pred, truth, *args,**kwargs):\n",
    "        loss = None\n",
    "        for _loss in losses:\n",
    "            if loss is None:\n",
    "                loss = ratio[_loss.__name__] * _loss(pred, truth, *args,**kwargs)\n",
    "            else:\n",
    "                loss += ratio[_loss.__name__] * _loss(pred, truth, *args,**kwargs)\n",
    "        return loss\n",
    "    \n",
    "    return _inner\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "y, y_hat = torch.arange(10).float(), torch.arange(10).float()+torch.randn(10)\n",
    "loss_fnc = CombinedLoss(F.mse_loss,smape)\n",
    "test_eq(F.mse_loss(y,y_hat)+smape(y,y_hat),loss_fnc(y, y_hat))\n",
    "\n",
    "r = 10\n",
    "loss_fnc = CombinedLoss(F.mse_loss, smape, ratio = {'mse_loss':r})\n",
    "test_eq(r*F.mse_loss(y,y_hat)+smape(y,y_hat),loss_fnc(y, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# TODO maybe add extra backwards loss also in a callback??\n",
    "class NBeatsTrainer(Callback):\n",
    "    \"`Callback` that adds weights regularization the thetas in N-Beats training.\"\n",
    "    def __init__(self, theta=0., b_loss=0.): \n",
    "        self.theta, self.b_loss = theta, b_loss\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        self.b = None\n",
    "\n",
    "    def begin_train(self): \n",
    "        self.out = defaultdict(dict)\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        \n",
    "    def begin_validate(self): \n",
    "        self.out = defaultdict(dict)\n",
    "        self.metrics = {'theta':tensor([0.]), 'b_loss':tensor([0.])}\n",
    "        \n",
    "    def after_pred(self):\n",
    "        self.b = self.pred[1] \n",
    "        self.pred[2]['total_b'] = self.pred[1] \n",
    "        self.out = concat_dct(self.pred[2], self.out)   \n",
    "        self.learn.pred = self.pred[0]\n",
    "\n",
    "    def after_loss(self):        \n",
    "        # theta\n",
    "        value=tensor([0.])\n",
    "        for key in self.out.keys():\n",
    "            if 'bias' not in key and 'total' not in key and 'att' not in key:\n",
    "                v = self.out[key]['theta'].float().pow(2).mean()\n",
    "                if self.theta != 0.:     \n",
    "                    self.learn.loss += self.theta * v.item()\n",
    "                value = value + v\n",
    "        self.metrics['theta'] += value.clone().cpu().detach()\n",
    "        \n",
    "        # backwards \n",
    "        value = self.learn.loss_func(self.b.float(), *self.xb, reduction='mean') \n",
    "        if self.b_loss != 0.:\n",
    "            self.learn.loss += self.b_loss * value.mean() \n",
    "        self.metrics['b_loss'] += value.sum().clone().detach()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_nbeats.models.ipynb.\n",
      "Converted 06_nbeats.metrics.ipynb.\n",
      "Converted 07_nbeats.learner.ipynb.\n",
      "Converted 10_interpret.ipynb.\n",
      "Converted 11_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
