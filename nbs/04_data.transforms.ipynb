{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# hide \n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.all import *\n",
    "# from pyts.image import GramianAngularField, MarkovTransitionField, RecurrencePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "> Basic function to process time-series data before assembling it in a `DataLoaders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NormalizeTS(Transform):\n",
    "    \"Normalize the Time-Series.\"\n",
    "    order = 2\n",
    "    def setups(self, dsets): \n",
    "        print([o[0] for o in dsets])\n",
    "        self.means,self.stds = 50,2\n",
    "    def encodes(self, to): \n",
    "        return (to-self.means) / self.stds\n",
    "    def decodes(self, to): \n",
    "        return (to*self.stds ) + self.means\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TSTensorSeq([[[  0,   1,   2,   3,   4]],\n",
      "\n",
      "        [[100, 101, 102, 103, 104]]])]\n",
      "(TSTensorSeq([[[-25, -24, -24, -23, -23]],\n",
      "\n",
      "        [[ 25,  25,  26,  26,  27]]]), TSTensorSeqy([[[-22, -22]],\n",
      "\n",
      "        [[ 27,  28]]]))\n"
     ]
    }
   ],
   "source": [
    "from fastseq.data.load import *\n",
    "horizon,lookback = 2,5\n",
    "ints = L(np.arange(7)[None,:], np.arange(100,107)[None,:]).map(tensor)\n",
    "\n",
    "dl = TSDataLoader(ints, horizon = horizon, lookback = lookback, bs=2, after_item=NormalizeTS())\n",
    "for o in dl:\n",
    "    print(o)\n",
    "  \n",
    "# x = np.array([0,1,2,3,4])\n",
    "# m,s = x.mean(),x.std()\n",
    "# test_eq(norm.means['a'], m)\n",
    "# test_close(norm.stds['a'], s)\n",
    "# test_close(to['a'].values, (x-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# TODO normalize proc\n",
    "def norm_items(self, items, norm):\n",
    "    items = items.map(tensor)\n",
    "    r=L()\n",
    "    for i,ts in enumerate(items):\n",
    "        ts = ts.float()\n",
    "        if norm:\n",
    "            ts = (ts - torch.mean(ts.float(), -1, keepdim = True))/(torch.std(ts.float(), -1, keepdim = True)+1e-8)\n",
    "        r.append(ts)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_models.nbeats.ipynb.\n",
      "Converted 07_interpret.ipynb.\n",
      "Converted 100_readme_alt.ipynb.\n",
      "Converted 21_data.loadpandas.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
