{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavenet model\n",
    "\n",
    "> The WaveNet` architecture for time series forecasting. <https://arxiv.org/pdf/1609.03499.pdf>\n",
    "\n",
    "Mostly copied from <https://github.com/MSRDL/Deep4Cast>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ConcreteDropout(torch.nn.Module):\n",
    "    \"\"\"Applies Dropout to the input, even at prediction time and learns dropout probability\n",
    "    from the data.\n",
    "    \n",
    "    In convolutional neural networks, we can use dropout to drop entire channels using\n",
    "    the 'channel_wise' argument.\n",
    "    \n",
    "    Arguments:\n",
    "        * dropout_regularizer (float): Should  be set to 2 / N, where N is the number of training examples.\n",
    "        * init_range (tuple): Initial range for dropout probabilities.\n",
    "        * channel_wise (boolean): apply dropout over all input or across convolutional channels.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dropout_regularizer=1e-5,\n",
    "                 init_range=(0.1, 0.3),\n",
    "                 channel_wise=False):\n",
    "        super(ConcreteDropout, self).__init__()\n",
    "        self.dropout_regularizer = dropout_regularizer\n",
    "        self.init_range = init_range\n",
    "        self.channel_wise = channel_wise\n",
    "\n",
    "        # Initialize dropout probability\n",
    "        init_min = np.log(init_range[0]) - np.log(1. - init_range[0])\n",
    "        init_max = np.log(init_range[1]) - np.log(1. - init_range[1])\n",
    "        self.p_logit = torch.nn.Parameter(\n",
    "            torch.empty(1).uniform_(init_min, init_max))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Returns input but with randomly dropped out values.\"\"\"\n",
    "        # Get the dropout probability\n",
    "        p = torch.sigmoid(self.p_logit)\n",
    "\n",
    "        # Apply Concrete Dropout to input\n",
    "        out = self._concrete_dropout(x, p)\n",
    "\n",
    "        # Regularization term for dropout parameters\n",
    "        dropout_regularizer = p * torch.log(p)\n",
    "        dropout_regularizer += (1. - p) * torch.log(1. - p)\n",
    "\n",
    "        # The size of the dropout regularization depends on the kind of input\n",
    "        if self.channel_wise:\n",
    "            # Dropout only applied to channel dimension\n",
    "            input_dim = x.shape[1]\n",
    "        else:\n",
    "            # Dropout applied to all dimensions\n",
    "            input_dim = np.prod(x.shape[1:])\n",
    "        dropout_regularizer *= self.dropout_regularizer * input_dim\n",
    "\n",
    "        return out, dropout_regularizer.mean()\n",
    "\n",
    "    def _concrete_dropout(self, x, p):\n",
    "        # Empirical parameters for the concrete distribution\n",
    "        eps = 1e-7\n",
    "        temp = 0.1\n",
    "\n",
    "        # Apply Concrete dropout channel wise or across all input\n",
    "        if self.channel_wise:\n",
    "            unif_noise = torch.rand_like(x[:, :, [0]])\n",
    "        else:\n",
    "            unif_noise = torch.rand_like(x)\n",
    "\n",
    "        drop_prob = (torch.log(p + eps)\n",
    "                     - torch.log(1 - p + eps)\n",
    "                     + torch.log(unif_noise + eps)\n",
    "                     - torch.log(1 - unif_noise + eps))\n",
    "        drop_prob = torch.sigmoid(drop_prob / temp)\n",
    "        random_tensor = 1 - drop_prob\n",
    "\n",
    "        # Need to make sure we have the right shape for the Dropout mask\n",
    "        if self.channel_wise:\n",
    "            random_tensor = random_tensor.repeat([1, 1, x.shape[2]])\n",
    "\n",
    "        # Drop weights\n",
    "        retain_prob = 1 - p\n",
    "        x = torch.mul(x, random_tensor)\n",
    "        x /= retain_prob\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class WaveNet(torch.nn.Module):\n",
    "    \"\"\"Implements `WaveNet` architecture for time series forecasting. Inherits \n",
    "    from pytorch `Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_.\n",
    "    Vector forecasts are made via a fully-connected linear layer.\n",
    "    References:\n",
    "        - `WaveNet: A Generative Model for Raw Audio <https://arxiv.org/pdf/1609.03499.pdf>`_\n",
    "    \n",
    "    Arguments:\n",
    "        * input_channels (int): Number of covariates in input time series.\n",
    "        * output_channels (int): Number of target time series.\n",
    "        * horizon (int): Number of time steps to forecast.\n",
    "        * hidden_channels (int): Number of channels in convolutional hidden layers.\n",
    "        * skip_channels (int): Number of channels in convolutional layers for skip connections.\n",
    "        * n_layers (int): Number of layers per Wavenet block (determines receptive field size).\n",
    "        * n_blocks (int): Number of Wavenet blocks.\n",
    "        * dilation (int): Dilation factor for temporal convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 output_channels,\n",
    "                 horizon,\n",
    "                 hidden_channels=64,\n",
    "                 skip_channels=64,\n",
    "                 n_layers=7,\n",
    "                 n_blocks=1,\n",
    "                 dilation=2):\n",
    "        \"\"\"Inititalize variables.\"\"\"\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.output_channels = output_channels\n",
    "        self.horizon = horizon\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.n_layers = n_layers\n",
    "        self.n_blocks = n_blocks\n",
    "        self.dilation = dilation\n",
    "        self.dilations = [dilation**i for i in range(n_layers)] * n_blocks\n",
    "\n",
    "        # Set up first layer for input\n",
    "        self.do_conv_input = ConcreteDropout(channel_wise=True)\n",
    "        self.conv_input = torch.nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "        # Set up main WaveNet layers\n",
    "        self.do, self.conv, self.skip, self.resi = [], [], [], []\n",
    "        for d in self.dilations:\n",
    "            self.do.append(ConcreteDropout(channel_wise=True))\n",
    "            self.conv.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=hidden_channels,\n",
    "                                             kernel_size=2,\n",
    "                                             dilation=d))\n",
    "            self.skip.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=skip_channels,\n",
    "                                             kernel_size=1))\n",
    "            self.resi.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=hidden_channels,\n",
    "                                             kernel_size=1))\n",
    "        self.do = torch.nn.ModuleList(self.do)\n",
    "        self.conv = torch.nn.ModuleList(self.conv)\n",
    "        self.skip = torch.nn.ModuleList(self.skip)\n",
    "        self.resi = torch.nn.ModuleList(self.resi)\n",
    "\n",
    "        # Set up nonlinear output layers\n",
    "        self.do_conv_post = ConcreteDropout(channel_wise=True)\n",
    "        self.conv_post = torch.nn.Conv1d(\n",
    "            in_channels=skip_channels,\n",
    "            out_channels=skip_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        self.do_linear_mean = ConcreteDropout()\n",
    "        self.do_linear_std = ConcreteDropout()\n",
    "        self.do_linear_df = ConcreteDropout()\n",
    "        self.linear_mean = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "        self.linear_std = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "        self.linear_df = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        output, reg_e = self.encode(inputs)\n",
    "        output_df, reg_d = self.decode(output)\n",
    "\n",
    "        # Regularization\n",
    "        regularizer = reg_e + reg_d\n",
    "\n",
    "        return output_df # , 'loc': output_mean, 'scale': output_std, 'regularizer': regularizer}\n",
    "\n",
    "    def encode(self, inputs: torch.Tensor):\n",
    "        \"\"\"Returns embedding vectors.\n",
    "        \n",
    "        Arguments:\n",
    "            * inputs: time series input to make forecasts for\n",
    "        \"\"\"\n",
    "        # Input layer\n",
    "        output, res_conv_input = self.do_conv_input(inputs)\n",
    "        output = self.conv_input(output)\n",
    "\n",
    "        # Loop over WaveNet layers and blocks\n",
    "        regs, skip_connections = [], []\n",
    "        for do, conv, skip, resi in zip(self.do, self.conv, self.skip, self.resi):\n",
    "            layer_in = output\n",
    "            output, reg = do(layer_in)\n",
    "            output = conv(output)\n",
    "            output = torch.nn.functional.relu(output)\n",
    "            skip = skip(output)\n",
    "            output = resi(output)\n",
    "            output = output + layer_in[:, :, -output.size(2):]\n",
    "            regs.append(reg)\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "        # Sum up regularizer terms and skip connections\n",
    "        regs = sum(r for r in regs)\n",
    "        output = sum([s[:, :, -output.size(2):] for s in skip_connections])\n",
    "\n",
    "        # Nonlinear output layers\n",
    "        output, res_conv_post = self.do_conv_post(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output = self.conv_post(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output = output[:, :, [-1]]\n",
    "        output = output.transpose(1, 2)\n",
    "\n",
    "        # Regularization terms\n",
    "        regularizer = res_conv_input \\\n",
    "            + regs \\\n",
    "            + res_conv_post\n",
    "\n",
    "        return output, regularizer\n",
    "\n",
    "    def decode(self, inputs: torch.Tensor):\n",
    "        \"\"\"Returns forecasts based on embedding vectors.\n",
    "        \n",
    "        Arguments:\n",
    "            * inputs: embedding vectors to generate forecasts for\n",
    "        \"\"\"\n",
    "        # Apply dense layer to match output length\n",
    "        output_mean, res_linear_mean = self.do_linear_mean(inputs)\n",
    "        output_std, res_linear_std = self.do_linear_std(inputs)\n",
    "        output_df, res_linear_df = self.do_linear_df(inputs)\n",
    "        output_mean = self.linear_mean(output_mean)\n",
    "        output_std = self.linear_std(output_std).exp()\n",
    "        output_df = self.linear_df(output_df).exp()\n",
    "\n",
    "        # Reshape the layer output to match targets\n",
    "        # Shape is (batch_size, output_channels, horizon)\n",
    "        batch_size = inputs.shape[0]\n",
    "        output_mean = output_mean.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "        output_std = output_std.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "        output_df = output_df.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "\n",
    "        # Regularization terms\n",
    "        regularizer = res_linear_mean + res_linear_std + res_linear_df\n",
    "\n",
    "        return output_df, regularizer\n",
    "\n",
    "    @property\n",
    "    def n_parameters(self):\n",
    "        \"\"\"Returns the number of model parameters.\"\"\"\n",
    "        par = list(self.parameters())\n",
    "        s = sum([np.prod(list(d.size())) for d in par])\n",
    "        return s\n",
    "\n",
    "    @property\n",
    "    def receptive_field_size(self):\n",
    "        \"\"\"Returns the length of the receptive field.\"\"\"\n",
    "        return self.dilation * max(self.dilations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogTransform(Transform):\n",
    "    r\"\"\"Natural logarithm of target covariate + `offset`.\n",
    "    \n",
    "    .. math:: y_i = log_e ( x_i + \\mbox{offset} )\n",
    "    Args:\n",
    "        * offset (float): amount to add before taking the natural logarithm\n",
    "        * targets (list): list of indices to transform.\n",
    "    Example:\n",
    "        >>> transforms.LogTransform(targets=[0], offset=1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_dim=None, offset=0.0):\n",
    "        self.offset = offset\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "    def encodes(self, sample):\n",
    "        X = sample[0]\n",
    "        y = sample[1]\n",
    "\n",
    "        if self.target_dim:\n",
    "            X[:,self.target_dim, :] = torch.log(self.offset + X[:,self.target_dim, :])\n",
    "            y[:,self.target_dim, :] = torch.log(self.offset + y[:,self.target_dim, :])\n",
    "        else:\n",
    "            X = torch.log(self.offset + X)\n",
    "            y = torch.log(self.offset + y)\n",
    "        return X,y\n",
    "\n",
    "    def decodes(self, sample):\n",
    "        X, y = sample[0], sample[1]\n",
    "\n",
    "        if self.target_dim:\n",
    "            X[:, self.target_dim, :] = torch.exp(X[:, self.target_dim, :]) - self.offset\n",
    "        else:\n",
    "            X = torch.exp(X) - self.offset\n",
    "            y = torch.exp(y) - self.offset\n",
    "\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmf = LogTransform([0], offset=1.0)\n",
    "x, y = tensor([[[0.0,1.0,2.1]]]), torch.randn(1,1,3)\n",
    "_x,_y = tmf((x,y))\n",
    "test_eq(_x, torch.log(1.0 + tensor([[[0.0,1.0,2.1]]])))\n",
    "__a,_b = tmf.decode((_x,_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(WaveNet.__init__)\n",
    "def wavelet_learner(dbunch, output_channels=None, metrics=None, hidden_channels=89, skip_channels =199, **kwargs):\n",
    "    \"Build a dnn style learner\"\n",
    "    output_channels = ifnone(output_channels,dbunch.train[0][0].shape[0])\n",
    "    \n",
    "    model = WaveNet(input_channels=dbunch.train[0][0].shape[0],\n",
    "                    output_channels=output_channels, \n",
    "                    horizon = dbunch.train_dl.horizon,\n",
    "                    hidden_channels=hidden_channels,\n",
    "                    skip_channels=skip_channels,\n",
    "                    **kwargs\n",
    "                   )\n",
    "    dbunch.after_batch.add(LogTransform([0], offset=1.0))\n",
    "    learn = Learner(dbunch, model, loss_func=F.mse_loss, opt_func= Adam, metrics=L(metrics)+L(mae, smape))#\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Skip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-92289923e4da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURLs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm4_daily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSkip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Skip' is not defined"
     ]
    }
   ],
   "source": [
    "from fastseq.all import *\n",
    "from fastai2.basics import *\n",
    "\n",
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataBunch.from_folder(path, horizon = 14, lookback = 128, skiprows=Skip(.9))\n",
    "len(data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = wavelet_learner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.callback.all import *\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>smape</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.405499</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [inf,inf,nan]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 02_deep4cast_m4_example.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_models.wavenet.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
