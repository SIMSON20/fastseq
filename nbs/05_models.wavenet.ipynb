{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavenet model\n",
    "\n",
    "> The WaveNet` architecture for time series forecasting. <https://arxiv.org/pdf/1609.03499.pdf>\n",
    "\n",
    "Mostly copied from <https://github.com/MSRDL/Deep4Cast>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/dev/env37/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "from fastai2.basics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ConcreteDropout(torch.nn.Module):\n",
    "    \"\"\"Applies Dropout to the input, even at prediction time and learns dropout probability\n",
    "    from the data.\n",
    "    \n",
    "    In convolutional neural networks, we can use dropout to drop entire channels using\n",
    "    the 'channel_wise' argument.\n",
    "    \n",
    "    Arguments:\n",
    "        * dropout_regularizer (float): Should  be set to 2 / N, where N is the number of training examples.\n",
    "        * init_range (tuple): Initial range for dropout probabilities.\n",
    "        * channel_wise (boolean): apply dropout over all input or across convolutional channels.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dropout_regularizer=1e-5,\n",
    "                 init_range=(0.1, 0.3),\n",
    "                 channel_wise=False):\n",
    "        super(ConcreteDropout, self).__init__()\n",
    "        self.dropout_regularizer = dropout_regularizer\n",
    "        self.init_range = init_range\n",
    "        self.channel_wise = channel_wise\n",
    "\n",
    "        # Initialize dropout probability\n",
    "        init_min = np.log(init_range[0]) - np.log(1. - init_range[0])\n",
    "        init_max = np.log(init_range[1]) - np.log(1. - init_range[1])\n",
    "        self.p_logit = torch.nn.Parameter(\n",
    "            torch.empty(1).uniform_(init_min, init_max))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Returns input but with randomly dropped out values.\"\"\"\n",
    "        # Get the dropout probability\n",
    "        p = torch.sigmoid(self.p_logit)\n",
    "\n",
    "        # Apply Concrete Dropout to input\n",
    "        out = self._concrete_dropout(x, p)\n",
    "\n",
    "        # Regularization term for dropout parameters\n",
    "        dropout_regularizer = p * torch.log(p)\n",
    "        dropout_regularizer += (1. - p) * torch.log(1. - p)\n",
    "\n",
    "        # The size of the dropout regularization depends on the kind of input\n",
    "        if self.channel_wise:\n",
    "            # Dropout only applied to channel dimension\n",
    "            input_dim = x.shape[1]\n",
    "        else:\n",
    "            # Dropout applied to all dimensions\n",
    "            input_dim = np.prod(x.shape[1:])\n",
    "        dropout_regularizer *= self.dropout_regularizer * input_dim\n",
    "\n",
    "        return out, dropout_regularizer.mean()\n",
    "\n",
    "    def _concrete_dropout(self, x, p):\n",
    "        # Empirical parameters for the concrete distribution\n",
    "        eps = 1e-7\n",
    "        temp = 0.1\n",
    "\n",
    "        # Apply Concrete dropout channel wise or across all input\n",
    "        if self.channel_wise:\n",
    "            unif_noise = torch.rand_like(x[:, :, [0]])\n",
    "        else:\n",
    "            unif_noise = torch.rand_like(x)\n",
    "\n",
    "        drop_prob = (torch.log(p + eps)\n",
    "                     - torch.log(1 - p + eps)\n",
    "                     + torch.log(unif_noise + eps)\n",
    "                     - torch.log(1 - unif_noise + eps))\n",
    "        drop_prob = torch.sigmoid(drop_prob / temp)\n",
    "        random_tensor = 1 - drop_prob\n",
    "\n",
    "        # Need to make sure we have the right shape for the Dropout mask\n",
    "        if self.channel_wise:\n",
    "            random_tensor = random_tensor.repeat([1, 1, x.shape[2]])\n",
    "\n",
    "        # Drop weights\n",
    "        retain_prob = 1 - p\n",
    "        x = torch.mul(x, random_tensor)\n",
    "        x /= retain_prob\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class WaveNet(torch.nn.Module):\n",
    "    \"\"\"Implements `WaveNet` architecture for time series forecasting. Inherits \n",
    "    from pytorch `Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_.\n",
    "    Vector forecasts are made via a fully-connected linear layer.\n",
    "    References:\n",
    "        - `WaveNet: A Generative Model for Raw Audio <https://arxiv.org/pdf/1609.03499.pdf>`_\n",
    "    \n",
    "    Arguments:\n",
    "        * input_channels (int): Number of covariates in input time series.\n",
    "        * output_channels (int): Number of target time series.\n",
    "        * horizon (int): Number of time steps to forecast.\n",
    "        * hidden_channels (int): Number of channels in convolutional hidden layers.\n",
    "        * skip_channels (int): Number of channels in convolutional layers for skip connections.\n",
    "        * n_layers (int): Number of layers per Wavenet block (determines receptive field size).\n",
    "        * n_blocks (int): Number of Wavenet blocks.\n",
    "        * dilation (int): Dilation factor for temporal convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 output_channels,\n",
    "                 horizon,\n",
    "                 hidden_channels=64,\n",
    "                 skip_channels=64,\n",
    "                 n_layers=7,\n",
    "                 n_blocks=1,\n",
    "                 dilation=2):\n",
    "        \"\"\"Inititalize variables.\"\"\"\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.output_channels = output_channels\n",
    "        self.horizon = horizon\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.n_layers = n_layers\n",
    "        self.n_blocks = n_blocks\n",
    "        self.dilation = dilation\n",
    "        self.dilations = [dilation**i for i in range(n_layers)] * n_blocks\n",
    "\n",
    "        # Set up first layer for input\n",
    "        self.do_conv_input = ConcreteDropout(channel_wise=True)\n",
    "        self.conv_input = torch.nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "        # Set up main WaveNet layers\n",
    "        self.do, self.conv, self.skip, self.resi = [], [], [], []\n",
    "        for d in self.dilations:\n",
    "            self.do.append(ConcreteDropout(channel_wise=True))\n",
    "            self.conv.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=hidden_channels,\n",
    "                                             kernel_size=2,\n",
    "                                             dilation=d))\n",
    "            self.skip.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=skip_channels,\n",
    "                                             kernel_size=1))\n",
    "            self.resi.append(torch.nn.Conv1d(in_channels=hidden_channels,\n",
    "                                             out_channels=hidden_channels,\n",
    "                                             kernel_size=1))\n",
    "        self.do = torch.nn.ModuleList(self.do)\n",
    "        self.conv = torch.nn.ModuleList(self.conv)\n",
    "        self.skip = torch.nn.ModuleList(self.skip)\n",
    "        self.resi = torch.nn.ModuleList(self.resi)\n",
    "\n",
    "        # Set up nonlinear output layers\n",
    "        self.do_conv_post = ConcreteDropout(channel_wise=True)\n",
    "        self.conv_post = torch.nn.Conv1d(\n",
    "            in_channels=skip_channels,\n",
    "            out_channels=skip_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        self.do_linear_mean = ConcreteDropout()\n",
    "        self.do_linear_std = ConcreteDropout()\n",
    "        self.do_linear_df = ConcreteDropout()\n",
    "        self.linear_mean = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "        self.linear_std = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "        self.linear_df = torch.nn.Linear(\n",
    "            skip_channels, horizon*output_channels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        output, reg_e = self.encode(inputs)\n",
    "        output_df, reg_d = self.decode(output)\n",
    "\n",
    "        # Regularization\n",
    "        regularizer = reg_e + reg_d\n",
    "\n",
    "        return output_df # , 'loc': output_mean, 'scale': output_std, 'regularizer': regularizer}\n",
    "\n",
    "    def encode(self, inputs: torch.Tensor):\n",
    "        \"\"\"Returns embedding vectors.\n",
    "        \n",
    "        Arguments:\n",
    "            * inputs: time series input to make forecasts for\n",
    "        \"\"\"\n",
    "        # Input layer\n",
    "        output, res_conv_input = self.do_conv_input(inputs)\n",
    "        output = self.conv_input(output)\n",
    "\n",
    "        # Loop over WaveNet layers and blocks\n",
    "        regs, skip_connections = [], []\n",
    "        for do, conv, skip, resi in zip(self.do, self.conv, self.skip, self.resi):\n",
    "            layer_in = output\n",
    "            output, reg = do(layer_in)\n",
    "            output = conv(output)\n",
    "            output = torch.nn.functional.relu(output)\n",
    "            skip = skip(output)\n",
    "            output = resi(output)\n",
    "            output = output + layer_in[:, :, -output.size(2):]\n",
    "            regs.append(reg)\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "        # Sum up regularizer terms and skip connections\n",
    "        regs = sum(r for r in regs)\n",
    "        output = sum([s[:, :, -output.size(2):] for s in skip_connections])\n",
    "\n",
    "        # Nonlinear output layers\n",
    "        output, res_conv_post = self.do_conv_post(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output = self.conv_post(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output = output[:, :, [-1]]\n",
    "        output = output.transpose(1, 2)\n",
    "\n",
    "        # Regularization terms\n",
    "        regularizer = res_conv_input \\\n",
    "            + regs \\\n",
    "            + res_conv_post\n",
    "\n",
    "        return output, regularizer\n",
    "\n",
    "    def decode(self, inputs: torch.Tensor):\n",
    "        \"\"\"Returns forecasts based on embedding vectors.\n",
    "        \n",
    "        Arguments:\n",
    "            * inputs: embedding vectors to generate forecasts for\n",
    "        \"\"\"\n",
    "        # Apply dense layer to match output length\n",
    "        output_mean, res_linear_mean = self.do_linear_mean(inputs)\n",
    "        output_std, res_linear_std = self.do_linear_std(inputs)\n",
    "        output_df, res_linear_df = self.do_linear_df(inputs)\n",
    "        output_mean = self.linear_mean(output_mean)\n",
    "        output_std = self.linear_std(output_std).exp()\n",
    "        output_df = self.linear_df(output_df).exp()\n",
    "\n",
    "        # Reshape the layer output to match targets\n",
    "        # Shape is (batch_size, output_channels, horizon)\n",
    "        batch_size = inputs.shape[0]\n",
    "        output_mean = output_mean.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "        output_std = output_std.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "        output_df = output_df.reshape(\n",
    "            (batch_size, self.output_channels, self.horizon)\n",
    "        )\n",
    "\n",
    "        # Regularization terms\n",
    "        regularizer = res_linear_mean + res_linear_std + res_linear_df\n",
    "\n",
    "        return output_df, regularizer\n",
    "\n",
    "    @property\n",
    "    def n_parameters(self):\n",
    "        \"\"\"Returns the number of model parameters.\"\"\"\n",
    "        par = list(self.parameters())\n",
    "        s = sum([np.prod(list(d.size())) for d in par])\n",
    "        return s\n",
    "\n",
    "    @property\n",
    "    def receptive_field_size(self):\n",
    "        \"\"\"Returns the length of the receptive field.\"\"\"\n",
    "        return self.dilation * max(self.dilations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogTransform(Transform):\n",
    "    r\"\"\"Natural logarithm of target covariate + `offset`.\n",
    "    \n",
    "    .. math:: y_i = log_e ( x_i + \\mbox{offset} )\n",
    "    Args:\n",
    "        * offset (float): amount to add before taking the natural logarithm\n",
    "        * targets (list): list of indices to transform.\n",
    "    Example:\n",
    "        >>> transforms.LogTransform(targets=[0], offset=1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_dim=None, offset=0.0):\n",
    "        self.offset = offset\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "    def encodes(self, sample):\n",
    "        X = sample[0]\n",
    "        y = sample[1]\n",
    "\n",
    "        if self.target_dim:\n",
    "            X[:,self.target_dim, :] = torch.log(self.offset + X[:,self.target_dim, :])\n",
    "            y[:,self.target_dim, :] = torch.log(self.offset + y[:,self.target_dim, :])\n",
    "        else:\n",
    "            X = torch.log(self.offset + X)\n",
    "            y = torch.log(self.offset + y)\n",
    "        return X,y\n",
    "\n",
    "    def decodes(self, sample):\n",
    "        X, y = sample[0], sample[1]\n",
    "\n",
    "        if self.target_dim:\n",
    "            X[:, self.target_dim, :] = torch.exp(X[:, self.target_dim, :]) - self.offset\n",
    "        else:\n",
    "            X = torch.exp(X) - self.offset\n",
    "            y = torch.exp(y) - self.offset\n",
    "\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmf = LogTransform([0], offset=1.0)\n",
    "x, y = tensor([[[0.0,1.0,2.1]]]), torch.randn(1,1,3)\n",
    "_x,_y = tmf((x,y))\n",
    "test_eq(_x, torch.log(1.0 + tensor([[[0.0,1.0,2.1]]])))\n",
    "__a,_b = tmf.decode((_x,_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(WaveNet.__init__)\n",
    "def wavelet_learner(dbunch, output_channels=None, metrics=None, hidden_channels=89, skip_channels =199, **kwargs):\n",
    "    \"Build a dnn style learner\"\n",
    "    output_channels = ifnone(output_channels,dbunch.train[0][0].shape[0])\n",
    "    \n",
    "    model = WaveNet(input_channels=dbunch.train[0][0].shape[0],\n",
    "                    output_channels=output_channels, \n",
    "                    horizon = dbunch.train_dl.horizon,\n",
    "                    hidden_channels=hidden_channels,\n",
    "                    skip_channels=skip_channels,\n",
    "                    **kwargs\n",
    "                   )\n",
    "    dbunch.after_batch.add(LogTransform([0], offset=1.0))\n",
    "    learn = Learner(dbunch, model, loss_func=F.mse_loss, opt_func= Adam, metrics=L(metrics)+L(mae, smape))\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastseq.all import *\n",
    "from fastseq.core import *\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataBunch.from_folder(path, horizon = 14, lookback = 128, bs=16, nrows=100, device='cpu')\n",
    "\n",
    "test_eq(data.train_dl.one_batch()[0].is_cuda,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.m4_daily)\n",
    "data = TSDataBunch.from_folder(path, horizon = 14, lookback = 128, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = wavelet_learner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU5dnH8e+dPZBAAtkIIQQIYYcAQUVFNhfcd627ra3VurTqa2vrWy2+ttbiUq37Umtb12oVtIpSBUFZwyI7ISxhJwsEEkL2+/1jRos0kITMmTOTuT/XNZczZ+accz8Zkx9neZ5HVBVjjDHmcGFuF2CMMSYwWUAYY4xpkgWEMcaYJllAGGOMaZIFhDHGmCZZQBhjjGlShNsFtERSUpJmZWW5XYYxxgSVxYsXl6pq8rGuHxQBkZWVRX5+vttlGGNMUBGRorasb6eYjDHGNMnxgBCRcBFZKiIfel/3EpEFIlIoIm+JSJTTNRhjjGk9fxxB/BRYc8jrh4HHVTUb2Avc4IcajDHGtJKjASEiGcDZwEve1wJMAN7xfuRV4AInazDGGHNsnD6C+CPwc6DR+7orUK6q9d7X24DuTa0oIjeKSL6I5JeUlDhcpjHGmMM5FhAicg5QrKqLj2V9VX1BVfNUNS85+Zjv0jLGGHOMnLzN9STgPBE5C4gBOgFPAAkiEuE9isgAtjtYQ1Bas3M/vZI6EhMZ7nYpxpgQ5tgRhKr+UlUzVDUL+B7wuapeBcwELvF+7DpgqlM1BKNNpQc4+8k5PDNrg9ulGGNCnBv9IH4B3CkihXiuSbzsQg0B6/UFRTQqTF22HZvMyRjjJr/0pFbVWcAs7/ONwHH+2G+wqa5r4B+Lt9E5NpKisiq+3raP3B4JbpdljAlR1pM6gHy8ciflVXU8fPEQosLDmLZsh9slGWNCmAVEAPn7/C30TurIGYPSGNcvmQ+W76Ch0U4zGWPcYQERINbs3M/ior1ceXwmIsL5ud0pqahhwcYyt0szxoQoC4gA8dqCIqIiwrh4RAYAEwek0DEqnKl2mskY4xILiABQWVPPe0u2c87QbiR29IxdGBMZzhmD0vh45U5q6htcrtAYE4osIALAtGU7OFDbwFXH9/zO8nNz09lfXc/sglKXKjPGhDILCJepKn+fX0T/tHhGZH73ltaTs5Po0jGKqcuss7kxxv8sIFy2bGs5q3fu5+oTeuIZ7PY/IsPDOGtIGv9es5sDNfVH2IIxxjjDAsJlf5+/hY5R4VwwvMlBbTk/tzvVdY3MWL3bz5UZY0KdBYSLyqtq+XD5Di4Y3p246KY7tY/MTCS9cwzTvra7mYwx/mUB4aJ3l2ynpr6RK4/PPOJnwsKEc4elM7ughL0Hav1YnTEm1FlAuERVeW1BEcMzExiU3vmonz0vN536RuWjlTv9VJ0xxlhAuGbexjI2lhzg6sNubW3KwG6dSO8cw9wN1qvaGOM/FhAueW3BFjrHRnL20G7NflZEGNEzkSVFe/1QmTHGeFhAuKCkooZPVu7ikpEZLZ41bkRmIjv3VbNz30GHqzPGGA8LCBe8nb+V+kY96sXpw43omQjAkqJyp8oyxpjvsIDws4ZG5fUFWzixT1f6JMe1eL2B3ToRHRHGYjvNZIzxEwsIP5tdUML28oP/Ne5Sc6Iiwhia0ZklWywgjDH+YQHhZ68tKCIpLprTBqa2et0RmYms2rGP6job3dUY4zwLCD/aXn6Qz9cWc/moDKIiWv+jH9EzkboGZdWOfQ5UZ4wx32UB4UdvLtyCAlcc1/KL04cakem5UG3XIYwx/mAB4Sd1DY28uWgr4/ulkJHY4Zi2kRwfTY8usXYnkzHGLywg/OSzNcWUVNRw5TEePXxjRGYii7fsRVV9VJkxxjTNAsJP3lq0hdRO0Yzrl9ym7YzsmUhJRQ3b9lqHOWOMsxwLCBGJEZGFIvK1iKwSkcne5RNFZImILBORL0Uk26kaAsXOfQf5oqCES0f2ICK8bT/yb65D2O2uxhinOXkEUQNMUNVhQC4wSUROAJ4FrlLVXOB14H8drCEgvJO/jUaFy/J6tHlb/dPiiY0MZ+kWuw5hjHFW07PU+IB6TpJXel9Geh/qfXTyLu8MtOuZcBoblbcXb+XEPl3J7HpsF6cPFREexrAe1mHOGOM8R69BiEi4iCwDioEZqroA+CHwkYhsA64Bfn+EdW8UkXwRyS8pKXGyTEfN21jG1j0HuXxU248evjEiM5HVO/ZzsNY6zBljnONoQKhqg/dUUgZwnIgMBu4AzlLVDOAV4LEjrPuCquapal5yctsu7LrprUVb6RwbyRmD0ny2zRGZidQ3Ksu32WkmY4xz/HIXk6qWAzOBM4Fh3iMJgLeAE/1RgxvKq2qZvmoXF+Smt3hY75b4dmRXuw5hjHGQk3cxJYtIgvd5LHAasAboLCI53o99s6xden/pdmrrG7l8VNv6PhyuS8coeiV1tB7VxhhHOXaRGugGvCoi4XiC6G1V/VBEfgS8KyKNwF7gBw7W4BpV5c1FWxma0ZmB6Z2aX6GVhmcm8MW6ElQVEfH59o0xxsm7mJYDw5tY/h7wnlP7DRQrtu9j7a4KHrxgsCPbH5GZyD+XbGfLnip6du3oyD6MMaHNelI75M1FW4mJDOO83HRHtj+yp3WYM8Y4ywLCAVW19XywbAdnDelGp5hIR/aRkxpPfHQEcwvLHNm+McZYQDhg1roSKmrquXSk7/o+HC48TDhjcBofr9xFVW29Y/sxxoQuCwgHzC4oIT4mglFZiY7u57K8HlTW1PPRil2O7scYE5osIHxMVZmzvpST+iS1eWC+5ozKSqRXUkfezt/q6H6MMaHJAsLHNpYeYHv5QcbkJDm+LxHh0rwMFm7aw6bSA47vzxgTWiwgfGxOgWfcqFP6+md4kEtGZBAeJnYUYYzxOQsIH5u9vpReSR3p0aXtI7e2REqnGMblJPPu4m3UNzT6ZZ/GmNBgAeFDNfUNzNtQxpi+zp9eOtRlo3pQXFHDFwXBO+qtMSbwWED40JKicg7WNTDGT6eXvjGhfwpJcVF2mskY41MWED40e30JEWHCCb27+HW/keFhXDQig8/WFFNSUePXfRtj2i8LCB+as76EEZmJxDvUe/poLsvLoL5ReX/pdr/v2xjTPllA+EhZZQ0rt+/nFD/c3tqU7JR4RmQm8Fb+VjyzvRpjTNtYQPjIl4WlAH6//nCoy0f1oLC4kqVbA3siocZGCzBjgoEFhI/MLigloUMkg7t3dq2Gs4em0yEqnL/O3exaDUejqrw0ZyMD7pvOT15bbBMeGRPgLCB8wDO8RgknZScRHube5D1x0RFcd2IW7y/bwYKNgTXKa219I/e8u4IH/7WGwd078+X6Ui5+di4XPvMVH63YaX04jAlAFhA+ULC7kuKKGsa6eHrpG7dP6EtGYiz3vr+S2vrA+KO750AtV7+8gLfyt3LbhGz+8ePRzPvlRCafN4g9B2r5yWtLGDtlFn/8dwFFZTZkiDGBwgLCB2Z7O6id7OcOck2JjQrngfMHUVhcyYtzNrpdDgW7Kzj/6S9ZtrWcJ76Xy12n9yMsTOjoPdr5/K5xPH/NSDK7dOCJz9YzdsosLn52Ln+bX8TeA7Vul29MSHNyTuqQMXt9CdkpcaQnxLpdCgAT+qdy5uA0nvxsPecM7ebalKRrdu7n0ufmERsVzls3nsDwzP8e/jw8TDhjUBpnDEpjR/lBpi7bwXtLt/Hr91cyedoquiXEkBIfQ2qnaFLiY0jpFE33hFh6du1IZpcOJHaItDm5jXGIBUQbVdc1sHDTHq48PtPtUr7j/nMHMWd9Kb+euopXvz/KlT+if5i+lohwYeotJ7UoPNMTYrl5XB9uGtub1Tv3M33lLrbuqWL3/hrW7apgTkEpFTXfnRwpPjqCHl06MCi9E6OyujCqVxeyunaw0DDGBywg2mjR5j3U1Df6bfTWlkrrHMNdp+cw+YPVfLh8J+cOc2Zu7CNZsmUvM9eV8PNJ/Vp9ZCUiDErvzKD0/74j7EBNPdvLD1JUVsWWPVVs3VPFptIDzFizm38s3gZAUlw0o7ISOXtoN84c3M3VGweMCWYWEG00d0MZEWHCcb38O7xGS1w7Oot/LtnOAx+u5pScZDrH+q+H9+MzCujaMYrrRmf5dLsdoyPISY0nJzX+O8sbG5UNJZUs2ryXRZv3MH9jGR+v3EXvpAJ+Mj6b83PTiXR4Aidj2hv7jWmjeRvKGNYjgY7RgZe14WHCby8cTFllDXe+tYzt5Qf9st9Fm/cwZ30pN43t47efS1iY0Dc1niuPz+Txy3P58hcTeOaqEURHhvM///ia8Y/M4u/zi6iua/BLPca0BxYQbVBZU8+K7fv8PjhfawzNSOCeM/szZ30p46fM4oEPVlNa6eyAfo/PKCApLpqrT+jp6H6OJjxMOGtINz66/WT+fH0eyfHR/O/7K8l78N/c/sZSPl6xk6ra+uY3ZEwIc+yfdyISA8wGor37eUdV7xfP1cMHgUuBBuBZVX3SqTqctGjzHhoaldG93b+99WhuPKUPZw9N54l/F/CXuZt4a9EWbji5FzeM6e3z007zNpQxd0MZ950zkNiocJ9u+1iICBP6pzK+XwrzN+5h6rLtfLp6N9O+3kF0RBhjc5I5dUAqo/t0dWySp6IyzzS0o3t3tYvnJqiIUwO7eYOgo6pWikgk8CXwU2AAMB64XlUbRSRFVYuPtq28vDzNz893pM62eOijNfz5q00sv/+MgPhj2BKFxZU8PqOAf63YSWS4MLJnImNzUjglJ4mB3Tq16Q+YqnL5C/MpKjvAF3ePJyYyMH8m9Q2N5BftZfrKXUxfuYtd+6sByEiM5cQ+XTmxTxIn9ulKSqeYY97+ki3lfLZmN5+tLaawuBKA0wem8shlw+jkwmi/JjSJyGJVzTvm9f0x8qeIdMATEDcDfwKuVNXClq4fqAFx/lNfEhURxj9uOtHtUlpt5fZ9fPD1Dr4oKGHtrgoAkuOjOXNwGrdN6EtyfHSrt/lVYSlXvbSAB84fxLU+vjjtFFVlfXGl98inlPkb97DvYB0A/VLjGdM3iTE5yRyX1aXZfwQUV1Tz0pxNvJ2/lfKqOiLDheN7dWXigBSq6xp55NN1ZHbpwLNXj6B/Wid/NM+EuIAOCBEJBxYD2cDTqvoLESkDHgMuBEqA21V1fRPr3gjcCJCZmTmyqKjIsTqPxf7qOnInf8qt47O58/R+bpfTJrv3VzO7oIRZBSV8snIXMZHh3D4xm+tP7EVURMsuU6kqFz87l137qpl59ziiIwLz6KE5DY3Kmp37+aqwlDnrS1m4eQ+19Y1EhYcxqlciY3OSGZuTQk5q3LdHWzv3HeT5LzbyxsIt1DU0cuaQbpw9pBtj+iZ9Z26QhZv2cMvrS6isruehi4ZwwfDubjXThIiADohvdyKSALwH3AbMB+5X1UdF5CLgDlUdc7T1A/EI4rM1u7nh1Xxe/+HxnJgd2NcgWmNDSSUPfriametKyOragXvPHsipA1KOeupJVXl17mZ+88FqfnfhkIDrNNgWB2sbWLR5D7MLSpizvpR1uz1HW2mdYhibk0xYGLy7eDuNqlw0ojs3j8umV9KRe64X76/m1teXsnDzHq4d3ZNfnTUgYE/FmeAXFAEBICL3AVXAD4EzVXWT9zpFuaoedYzsQAyI3/5rNa/OLWL5b05vl7/gs9YV838frmZDyQFOyu7KPZMGMCTjv7+miuo6fvnPFXy4fCen5CTz0rV5LT7qCEY7yg8yu6CELwpK+HJ9KTX1jVyal8FNY/u0+CJ3XUMjf5i+lhfnbKJ3UkcevmQoo7IC9044E7wCNiBEJBmoU9VyEYkFPgUeBk4GClT1zyIyDpiiqqOOtq1ADIhz/jSHjlERvPXj0W6X4pi6hkb+Pr+IJz9bz96qOs4e0o07T8+hT3IcAMu3lXPr60vZXn6Qu07P4aZT+hAWQr2W6xoaqa1vPOa+HnPWl3DPuyvYse8g157Qk59P6h+Q/WlM8ArkgBgKvAqE4+lv8baqPuA93fQakAlUAjep6tdH21agBcS+qjpy/+9Tbp/QlztOy3G7HMdVVNfx4pxNvDRno+dfzCMz6Nm1I4/NWEdyXDRPXjGcPPsX8DE5UFPPlE/W8eq8zaR3juX3Fw9xdVZC074EbED4UqAFxIzVu/nRX/N588YTOKF3V7fL8ZvSyhqe+ryQ1xYUUdegnDoglUcuHUpChyi3Swt6izbv4RfvLGdj6QHOGpLGPZMGkNnVmX4ZJnS0NSDsePYYzNtQRnREGLk9Etwuxa+S4qL5zXmDuOHkXqzdVdHsxWvTcqOyuvDRT8fw3BcbeP6Ljfx7dTHfPymLWyZkW78J45r2ezXRQfM3ljEiM7FdXpxuiR5dOnDawFQLBx+LiQznZ6fmMPN/xnHusHSen72RcVNm8bf5RTYlq3GFBUQrlVfVsmbXfkb3CZ1TS8a/0jrH8Ohlw/jg1pPpmxLHr99fyVlPzvl25kJj/MUCopXmb9yDKhYQxnFDMjrz5o0n8NzVI6mpb+TaPy/kB39Z9O3QHcY4zQKileZvLCMmMoyhTfQJMMbXRIRJg9P49I5T+NVZ/Vm0aQ+T/jib30xbxR6bs9s4zAKileZvLCOvZ5egHUrCBKfoiHBuPKUPM+8ex2WjevDXeZsZ8/DnTPlkLeVVFhTGGRYQrVBWWcPaXRV2esm4Jikumt9dOIRP7ziF8f1TeGbWBk5+eCaPfbqOfVV1bpdn2hm7zbUVvtpQBhDQEwSZ0JCdEs9TV47gtl0VPPFZAU9+XsgrczeTkxpPVHgY0ZFh3v+GkxAbSXJ8tOcR5/lvdkqc9do2zbL/Q1qovqGRpz5fT2aXDgzNCK3+DyZw9UuL55mrRrJ6x35e+nIju/dXU1vfSNWBemrqG6mpb6S8qpa9hx1dRIYLo7K6MK5fMuP6pdA3Jc5uWzb/xQKihd5YuIWC3ZU8d/VIIsPtzJwJLAPTO/HYZblHfL+2vpHSyhpKKmrYvb+axUV7mbWuhN99tJbffbSW7gmxnDUkjWtHZzk2s54JPjbURgvsq6pj3CMz6Z/Widd/dLz9S8u0GzvKD/JFQQmfry1m5tpiGtUzhMr3T+rFCb272P/rQc6G2vCDP35WwL6Ddfz6nIH2C2PalfSEWK44LpMrjstk175q/jZ/M68v2MKnq3fTPy2eC4d3p3+3TuSkxpHWKcb+/w8xFhDNKCyu5G/zirh8VCYD022aSNN+pXWO4e4z+nPbhL5MXbadV77azEMfr/32/fiYCPqlxnN+bjrXBMmUsqZtLCCa8eC/VhMbGc5dp7f/Yb2NAc+YUJePyuTyUZnsPVBLwe4KCoorKdhVQX7RXn49dRUD0zszsmei26Uah1lAHMXMdcXMWlfCvWcNICku2u1yjPG7xI5RHN+7K8d7h7U/UFPPxEe/4L6pK5l268mEh9AEUaHIbsc5grqGRh78cDVZXTtw3YlZbpdjTEDoGB3B/54zgFU79vP6giK3yzEOs4A4gjcWbmFDyQHuPXtgu55j2ZjWOntIN07K7sqUT9ZRVlnjdjnGQfaXrwk19Q08M3MDo7ISOXVAitvlGBNQRITJ5w2iqraBh6evbX4FE7QsIJrwj/xt7Npfze0T+9ptfcY0ITslnhvG9OLt/G0sLtrrdjnGIRYQh6mtb+TZWRsYnpnAydlJbpdjTMC6fUJf0jrFcN/UlTQ0Bn6HW9N6FhCHeW/pNraXH7SjB2OaYRes2z8LiEPUNzTy9MwNDM3ozLicZLfLMSbgfXPB+tEZBVTW1LtdjvGxFgWEiPQRkWjv83EicruItLshTacu28GWPVXcNsGOHoxpCRHhf07vR3lVHW8s2OJ2OcbHWnoE8S7QICLZwAtAD+D1o60gIjEislBEvhaRVSIy+bD3nxSRgJlct6FReXpmIQO6dbI7l4xpheGZiZzYpysvztlITX2D2+UYH2ppQDSqaj1wIfAnVb0b6NbMOjXABFUdBuQCk0TkBAARyQMCqp/+h8t3sLH0ALdPyLajB2Na6Zbx2RRX1PDu4u1ul2J8qKUBUSciVwDXAR96l0UebQX1qDzks5GAikg4MAX4+THU64jGRuWpzwvJSY3jjEFpbpdjTNA5sU9XhmV05rkvNlDf0Oh2OcZHWhoQ3wdGA79V1U0i0gv4W3MriUi4iCwDioEZqroAuBWYpqo7j7VoX5u+ahfriyu5dUJfwmxsGWNaTUS4eVw2W/ZU8a8VAfOrbdqoRQGhqqtV9XZVfUNEEoF4VX24Bes1qGoukAEcJyKnAJcCf2puXRG5UUTyRSS/pKSkJWUek/qGRh6bUUCf5I6cPaS5s2bGmCM5fWAq2SlxPDtrA8EwEZlpXkvvYpolIp1EpAuwBHhRRB5r6U5UtRyYCYwHsoFCEdkMdBCRwiOs84Kq5qlqXnKyc7ecvrtkG4XFldx9Rn8bmdKYNggLE24e24e1uyr4fG2x2+UYH2jpKabOqrofuAj4q6oeD5x6tBVEJPmbW2FFJBY4DVisqmmqmqWqWUCVqmYfe/ltc7C2gcdnrGd4ZgJnDEp1qwxj2o3zctPpnhDL0zML7SiiHWhpQESISDfgMv5zkbo53YCZIrIcWITnGkRL1/WLv8zdzK791dwzqb/duWSMD0SGh/Hjsb1ZsqWcBZv2uF2OaaOWBsQDwCfABlVdJCK9gfVHW0FVl6vqcFUdqqqDVfWBJj4T1/qSfaO8qpZnZhUysX/Kt5OhGGPa7rK8HiTFRfH0zCbPHpsg0tKL1P/w/qG/2ft6o6pe7Gxpznpm1gYqa+r5+aT+bpdiTLsSExnOD8f0Zs76Ur4ocO4GE+O8ll6kzhCR90Sk2Pt4V0QynC7OKdvLD/KXuZu5eEQG/dLi3S7HmHbn+ydl0SupI/dPXUl1nfWuDlYtPcX0CjANSPc+PvAuC0qPzygA4I7TclyuxJj2KToinMnnDWJzWRUvzN7odjnmGLU0IJJV9RVVrfc+/gIE5XCna3ft590l27j+xCy6J8S6XY4x7dYpOcmcPaQbT88sZEtZldvlmGPQ0oAoE5GrvT2jw0XkaqDMycKcMmX6OuKiI/jJuD5ul2JMu/frcwYSESbcP22l3fYahFoaED/Ac4vrLmAncAlwvUM1OSZ/8x4+W1vMTWP7kNAhyu1yjGn30jrH8LNTc5i5roRPV+92uxzTSi29i6lIVc9T1WRVTVHVC4CguotJVXl4+lqS46P5/klZbpdjTMi4/qQsclLjeOCD1VTV2qRCwaQtM8rd6bMq/GDWuhIWbd7L7RP70iEqwu1yjAkZkeFhPHjBELaXH+Spz61vRDBpS0AETdfjxkbP0UNmlw5cntfD7XKMCTnH9erCRSO68+KcjazfXeF2OaaF2hIQQXPF6YPlO1i7q4K7Ts8hKsKm4TbGDb86awAdoiK49327YB0sjvrXUkQqRGR/E48KPP0hAl5tfSOPflpA/7R4zh0aFCUb0y4lxUVzz5n9WbhpD+8s3uZ2OaYFjhoQqhqvqp2aeMSralCcyH8rfytb9lTxi0n9bTIgY1x2eV4PRvZM5HcfrWHvgVq3yzHNaNfnW6pq63nys/WMykpkXL+g7NdnTLsSFib89sLBVFTX89DHa9wuxzSjXQfEK19tpqSihp/bcN7GBIz+aZ24YUwv3s7fxkIbEjygteuAKCyuZGL/FEZldXG7FGPMIX46sS/dE2K5970V1NY3ul2OOYJ2HRCPX57L01eNcLsMY8xhOkRF8MD5g1hfXMmLc2wwv0DVrgMCPGPTG2MCz8QBqZwxKJUnP1vP1j02mF8gavcBYYwJXPefO4gwER7812q3SzFNsIAwxrgmPSGWW8b34ZNVu5mz3mafCzQWEMYYV/1wTG8yu3Rg8gerqWuwC9aBxALCGOOqmMhw7jtnIIXFlbw6d7Pb5ZhDWEAYY1w3cUAK4/ol88d/r6e4otrtcoyXBYQxxnUiwn3nDKSmvoGHP17ndjnGywLCGBMQeifHccPJvXl3yTYWF+11uxyDgwEhIjEislBEvhaRVSIy2bv8NRFZJyIrReTPIhLpVA3GmOBy24RsUjtF85tpq2hotCHB3ebkEUQNMEFVhwG5wCQROQF4DegPDAFigR86WIMxJoh0jI7gV2cNYMX2ffx9fpHb5YQ8xwJCPSq9LyO9D1XVj7zvKbAQyHCqBmNM8DlvWDqn5CTzh+lr2V5+0O1yQpqj1yBEJFxElgHFwAxVXXDIe5HANcB0J2swxgQXEeF3Fw5GgXvfW2Gzz7nI0YBQ1QZVzcVzlHCciAw+5O1ngNmqOqepdUXkRhHJF5H8khLrYWlMKMlI7MDdZ/Rj1roSpi7b4XY5IcsvdzGpajkwE5gEICL3A8nAnUdZ5wVVzVPVvORkm+zHmFBz7egshmcmMPmDVZRV1rhdTkhy8i6mZBFJ8D6PBU4D1orID4EzgCtU1frVG2OaFB4mPHzxUCpr6pn8gQ3m5wYnjyC6ATNFZDmwCM81iA+B54BUYJ6ILBOR+xyswRgTxHJS47llfDbTvt7B52t3u11OyIlwasOquhwY3sRyx/ZpjGl/fjIum49W7OTe91by6R1diI+xrlP+Yj2pjTEBLSoijIcvHsqu/dVM+cSG4fAnCwhjTMAbnpnIdaOz+Nv8IhuGw48sIIwxQeF/zuhHt04x3PPucmrr7f4Wf7CAMMYEhbjoCB68cDDriyt5dtYGt8sJCRYQxpigMaF/KucM7cbTMwspLK5wu5x2zwLCGBNU7j93ELFR4fzynytotBFfHWUBYYwJKsnx0dx79gAWbd7L6wu3uF1Ou2YBYYwJOpeOzODEPl15+OO17NpnU5Q6xQLCGBN0PCO+DqG2oZHfTFvldjntlgWEMSYoZSV15PaJfZm+ahczVtswHE6wgDDGBK0fjelNTmoc909dyYGaerfLaXcsIIwxQSsqIoyHLhrCjn3VPPppgdvltDsWEMaYoDayZxeuOj6Tv8zdxIpt+9wup12xgDDGBL2fT+pP17ho7vnncuobbBgOX7GAMMYEvc6xkUw+bxCrduznL3M3u11Ou2EBYYxpF84cnMbE/ik8+mkB2/ZWuV1Ou2ABYYxpF0SEB6aLHWAAAA5YSURBVC4YTJjAz95cRp2damozCwhjTLvRPSGWhy4eSn7RXh6xyYXazALCGNOunDcsnauOz+T52Rv5bI11oGsLCwhjTLvz63MGMii9E3e+/bVdj2gDCwhjTLsTExnO01eOoKFRufX1pTYD3TGygDDGtEtZSR35wyVDWba1nIenr3W7nKAU4XYBxhjjlLOGdOO60T15+ctNxMdE8IOTe9EpJtLtsoKGHUEYY9q1X509gNMHpvLHf6/npN9/zpRP1lJaWeN2WUFBVJ2Zsk9EYoDZQDSeI5V3VPV+EekFvAl0BRYD16hq7dG2lZeXp/n5+Y7UaYwJDSu27eOZWYVMX7WL6Igwvjcqk1vGZ5McH+12aY4RkcWqmnes6zt5BFEDTFDVYUAuMElETgAeBh5X1WxgL3CDgzUYYwwAQzI68+zVI5lxx1jOGZrO3+cXcdnz89i932akOxLHAkI9Kr0vI70PBSYA73iXvwpc4FQNxhhzuOyUOB65dBhv/Xg0xfurufLF+ZRU2Cmnpjh6DUJEwkVkGVAMzAA2AOWq+s3MHtuA7kdY90YRyReR/JKSEifLNMaEoJE9E3nl+8exo7yaq16aT5ldl/gvjgaEqjaoai6QARwH9G/Fui+oap6q5iUnJztWozEmdB3XqwsvX5/Hlj1VXPXSAvYeOOrl0JDjl7uYVLUcmAmMBhJE5JvbazOA7f6owRhjmnJinyRevDaPjaUHuPrlBeyrqnO7pIDhWECISLKIJHifxwKnAWvwBMUl3o9dB0x1qgZjjGmJMX2Tef6akazfXcmP/55vkw55OXkE0Q2YKSLLgUXADFX9EPgFcKeIFOK51fVlB2swxpgWGd8vhYcuGsL8jXt4bIbNbw0O9qRW1eXA8CaWb8RzPcIYYwLKxSMzyC/awzOzNjCyZyITB6S6XZKrrCe1McYc4v5zBzEovRN3vLWMrXtCeyRYCwhjjDlETGQ4z141EgVufm0x1XUNbpfkGgsIY4w5TGbXDjx2WS4rt+/n/z5c/e1yVWXnvoPMLihhQ0nlUbbQPthorsYY04TTBqby47G9ef6LjZRW1rB7fw2FxZVU1nj6+SbFRTPr7nHERbffP6N2BGGMMUdw9+n9mDQojSVbyukQFc7FI7rzf+cPYsolQymtrOG5WRvcLtFR7Tf6jDGmjSLCw3jumpFNvvdlYSkvztnIlcdnkp4Q6+fK/MOOIIwx5hj8fJJn5KApn6xzuRLnWEAYY8wx6J4Qyw/H9OK9pdv5emu52+U4wgLCGGOO0c3jskmKi+LBf63GqcnX3GQBYYwxxyguOoI7T+vHos17+WTVLrfL8TkLCGOMaYPL8jLolxrPQx+vpaa+fXWqs4Awxpg2iAgP41dnD6CorIq/zStyuxyfsoAwxpg2GpuTzNicZB6fUcDm0gNul+MzFhDGGOMDD100hIjwMG57Yym19e1jPgkLCGOM8YH0hFimXDKUFdv38Yfpa90uxycsIIwxxkdOH5TGtaN78tKXm5i5rtjtctrMAsIYY3zoV2cNoH9aPHe9/TW791e7XU6bWEAYY4wPxUSG89SVwzlY28Adby2joTF4O9BZQBhjjI9lp8Qz+bxBzN1QxrOzCt0u55jZaK7GGOOAS/My+LKwlEc+LaBTbCTXjs5yu6RWs4AwxhgHiAh/uGQoB+sauG/qKiqq67llfLbbZbWKnWIyxhiHxESG88xVIzg/N50pn6zj4elrg2pQPzuCMMYYB0WGh/H4Zbl0jI7g2VkbqKyuZ/J5gwgLE7dLa5YFhDHGOCwsTPjtBYOJj47g+dkbqapt4JFLhyIS2CHh2CkmEekhIjNFZLWIrBKRn3qX54rIfBFZJiL5InKcUzUYY0ygEBHuObM/P53Yl3eXbOOVrza7XVKznLwGUQ/cpaoDgROAW0RkIPAHYLKq5gL3eV8bY0y7JyL87NS+TOyfwu8/XsvK7fvcLumoHAsIVd2pqku8zyuANUB3QIFO3o91BnY4VYMxxgQaEWHKpcNI7BjJ7W8s5UBNvdslHZFf7mISkSxgOLAA+BkwRUS2Ao8AvzzCOjd6T0Hll5SU+KNMY4zxiy4do3j88lw2lR3g/mmr3C7niBwPCBGJA94Ffqaq+4GbgTtUtQdwB/ByU+up6guqmqeqecnJyU6XaYwxfnVinyRuHZ/NO4u3MXXZdrfLaZKjASEikXjC4TVV/ad38XXAN8//AdhFamNMSPrpxL7k9Uzk3vdWUlT2n4mGVJWK6joKiyupa3BvbgnHbnMVz/1bLwNrVPWxQ97aAYwFZgETgPVO1WCMMYEsIjyMP34vl7OemMM1Ly8krXMMxfur2b2/hoN1nvmtP79rLL2T49ypz8FtnwRcA6wQkWXeZb8CfgQ8ISIRQDVwo4M1GGNMQMtI7MATVwxnyvR1AAzJSGBifDSpnaJJ7RRD17ho12pzLCBU9UvgSL1ARjq1X2OMCTbj+6Uwvl+K22X8FxuLyRhjTJMsIIwxxjTJAsIYY0yTLCCMMcY0yQLCGGNMkywgjDHGNMkCwhhjTJMsIIwxxjRJgmF+VBEpAcqBQwdP73yU14c+TwJKfVTK4ftsy2eP9H5Ty5tbdqSfhS/bfqQ6jvWzbWl/KH/3gd725j7f2veCrf2B9t33VNVjH+1UVYPiAbzQ0teHPc93qoa2fPZI7ze1vLllR/pZ+LLtgdT+UP7uA73tzX2+te8FW/vb23cfTKeYPmjF68Pfc6qGtnz2SO83tby5Zc39bHwlUNofyt99oLe9uc+39r1ga3+7+u6D4hRTW4hIvqrmuV2HG0K57RDa7Q/ltkNot9+XbQ+mI4hj9YLbBbgolNsOod3+UG47hHb7fdb2dn8EYYwx5tiEwhGEMcaYY2ABYYwxpkkWEMYYY5oU0gEhImNE5DkReUlE5rpdjz+JSJiI/FZE/iQi17ldj7+JyDgRmeP9/se5XY+/iUhHEckXkXPcrsWfRGSA9zt/R0RudrsefxORC0TkRRF5S0ROb+7zQRsQIvJnESkWkZWHLZ8kIutEpFBE7jnaNlR1jqreBHwIvOpkvb7ki7YD5wMZQB2wzalaneCj9itQCcQQRO33UdsBfgG87UyVzvDR7/wa7+/8ZcBJTtbraz5q//uq+iPgJuDyZvcZrHcxicgpeH7B/6qqg73LwoEC4DQ8v/SLgCuAcOChwzbxA1Ut9q73NnCDqlb4qfw28UXbvY+9qvq8iLyjqpf4q/628lH7S1W1UURSgcdU9Sp/1d8WPmr7MKArnnAsVdUP/VN92/jqd15EzgNuBv6mqq/7q/628vHfvEeB11R1ydH2GeHTFviRqs4WkazDFh8HFKrqRgAReRM4X1UfApo8lBaRTGBfsIQD+KbtIrINqPW+bHCuWt/z1XfvtReIdqJOJ/joux8HdAQGAgdF5CNVbXSybl/w1feuqtOAaSLyLyBoAsJH370Avwc+bi4cIIgD4gi6A1sPeb0NOL6ZdW4AXnGsIv9pbdv/CfxJRMYAs50szE9a1X4RuQg4A0gAnnK2NMe1qu2qei+AiFyP90jK0eqc1drvfRxwEZ5/FHzkaGX+0drf+9uAU4HOIpKtqs8dbePtLSBaTVXvd7sGN6hqFZ5wDEmq+k88IRmyVPUvbtfgb6o6C5jlchmuUdUngSdb+vmgvUh9BNuBHoe8zvAuCwWh3HYI7fZb2/8jlNoODre/vQXEIqCviPQSkSjge8A0l2vyl1BuO4R2+63todl2cLj9QRsQIvIGMA/oJyLbROQGVa0HbgU+AdYAb6vqKjfrdEIotx1Cu/3W9tBsO7jT/qC9zdUYY4yzgvYIwhhjjLMsIIwxxjTJAsIYY0yTLCCMMcY0yQLCGGNMkywgjDHGNMkCwgQlEan08/5eEpGBPtpWg4gsE5GVIvKBiCQ08/kEEfmJL/ZtTGtYPwgTlESkUlXjfLi9CG+nI8cdWruIvAoUqOpvj/L5LODDb4Z4NsZf7AjCtBsikiwi74rIIu/jJO/y40RknogsFZG5ItLPu/x6EZkmIp8Dn4lnlrlZ4pltbK2IvOYdHhnv8jzv80rxzMb3tYjM984pgYj08b5eISIPtvAoZx6eETkRkTgR+UxElni3cb73M78H+niPOqZ4P3u3t43LRWSyD3+MxnzLAsK0J08Aj6vqKOBi4CXv8rXAGFUdDtwH/O6QdUYAl6jqWO/r4cDP8MyV0JumZx3rCMxX1WF4hkr/0SH7f0JVh9CCWeq8k71M5D9j51QDF6rqCGA88Kg3oO4BNqhqrqreLZ6pIvvimQsgFxjpnUzGGJ8K+eG+TbtyKjDQ+49+gE4iEgd0Bl4Vkb54phqNPGSdGaq655DXC1V1G4CILAOygC8P208tnmlqARbjmc0LYDRwgff568AjR6gz1rvt7njGz5nhXS7A77x/7Bu976c2sf7p3sdS7+s4PIHRHub1MAHEAsK0J2HACapafehCEXkKmKmqF3rP58865O0Dh22j5pDnDTT9O1Kn/7l4d6TPHM1BVc0VkQ54Blm7Bc8Y/VcBycBIVa0Tkc14pgU9nAAPqerzrdyvMa1ip5hMe/IpnhmzABCRXO/TzvxnjPzrHdz/fDyntsAz7PJReSdtuh24S0Qi8NRZ7A2H8UBP70crgPhDVv0E+IH36AgR6S4iKT5qgzHfsoAwwaqDd8jjbx534vljm+e9cLsauMn72T8AD4nIUpw9av4ZcKeILAeygX3NraCqS4HleCaafw1P/SuAa/FcO0FVy4CvvLfFTlHVT/Gcwprn/ew7fDdAjPEJu83VGB/xnjI6qKoqIt8DrlDV85tbz5hAZdcgjPGdkcBT3juPyoEfuFyPMW1iRxDGGGOaZNcgjDHGNMkCwhhjTJMsIIwxxjTJAsIYY0yTLCCMMcY0yQLCGGNMk/4fJ7ZpUw6aVvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.callback.all import *\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>smape</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>35.231789</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [inf,inf,nan]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.transforms.ipynb.\n",
      "Converted 05_models.wavenet.ipynb.\n",
      "Converted 06_models.dnn.ipynb.\n",
      "Converted 08_metrics.ipynb.\n",
      "Converted 09_learner.ipynb.\n",
      "Converted 20_models.cnn.learner.ipynb.\n",
      "Converted 21_models.cnn.transforms.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env37",
   "language": "python",
   "name": "env37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
