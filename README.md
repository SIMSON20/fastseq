<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

# Fastseq

> A way to use fastai with sequence data


This file will become your README and also the index of your documentation.

## How to use
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
from fastseq.core import *
from fastseq.data.external import *
from fastseq.data.load import *
from fastai2.basics import *
from fastseq.models.wavenet import *
```

</div>

</div>

Getting the data fastai style:
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
path = untar_data(URLs.m4_daily)
path
```

</div>
<div class="output_area" markdown="1">




    Path('/home/tako/.fastai/data/m4_daily')



</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
df_train = pd.read_csv(path/'train.csv',skiprows=skip)
df_test = pd.read_csv(path/'val.csv')
df_test.head()
```

</div>
<div class="output_area" markdown="1">




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>D1</td>
      <td>2039.20</td>
      <td>2035.00</td>
      <td>2051.80</td>
      <td>2061.8</td>
      <td>2063.50</td>
      <td>2069.5</td>
      <td>2054.00</td>
      <td>2057.00</td>
      <td>2062.80</td>
      <td>2066.40</td>
      <td>2067.40</td>
      <td>2071.40</td>
      <td>2083.80</td>
      <td>2080.60</td>
    </tr>
    <tr>
      <th>1</th>
      <td>D2</td>
      <td>2986.00</td>
      <td>3001.20</td>
      <td>2975.90</td>
      <td>2996.1</td>
      <td>2981.90</td>
      <td>2985.5</td>
      <td>2975.80</td>
      <td>2956.20</td>
      <td>2964.70</td>
      <td>2989.00</td>
      <td>2991.40</td>
      <td>3024.90</td>
      <td>3070.80</td>
      <td>3076.90</td>
    </tr>
    <tr>
      <th>2</th>
      <td>D3</td>
      <td>1120.70</td>
      <td>1117.90</td>
      <td>1115.10</td>
      <td>1112.3</td>
      <td>1109.50</td>
      <td>1106.7</td>
      <td>1103.90</td>
      <td>1101.10</td>
      <td>1098.30</td>
      <td>1095.50</td>
      <td>1092.70</td>
      <td>1089.90</td>
      <td>1087.10</td>
      <td>1084.30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>D4</td>
      <td>1190.00</td>
      <td>1162.00</td>
      <td>1134.00</td>
      <td>1106.0</td>
      <td>1078.00</td>
      <td>1050.0</td>
      <td>1022.00</td>
      <td>994.00</td>
      <td>966.00</td>
      <td>938.00</td>
      <td>910.00</td>
      <td>1428.00</td>
      <td>1400.00</td>
      <td>1372.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>D5</td>
      <td>5904.67</td>
      <td>5917.05</td>
      <td>5922.58</td>
      <td>5928.8</td>
      <td>5935.29</td>
      <td>6002.8</td>
      <td>6009.47</td>
      <td>6014.82</td>
      <td>6020.19</td>
      <td>6072.49</td>
      <td>6077.72</td>
      <td>6080.23</td>
      <td>6082.75</td>
      <td>6108.07</td>
    </tr>
  </tbody>
</table>
</div>



</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
horizon = 12
lookback = 128
```

</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
train = df_train.iloc[:, 1:].values
test = df_test.iloc[:, 1:].values
```

</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
train_dl = DataLoader(TimeSeriesDataset(ts_lists(train),
                                     lookback,
                                     horizon,
                                     step=1,
                                     static_covs = [1,2,2,2,2],
                                     transform = ToTensor()
                                    ),
                   batch_size=64,
                   shuffle=True,
                   pin_memory=True,
                   num_workers=1,                  
                  )

test_dl = DataLoader(TimeSeriesDataset(ts_lists(test),
                                     lookback,
                                     horizon,
                                     step=1,
                                     static_covs = [1,2,2,2,2],
                                     transform = [ToTensor(),Cuda()]
                                    ),
                   batch_size=64,
                   shuffle=False,
                   pin_memory=True,
                   num_workers=1,                  
                  )
```

</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
model = WaveNet(input_channels=1,
                output_channels=1,
                horizon=horizon,
                    
               )

print('Number of model parameters: {}.'.format(model.n_parameters))
print('Receptive field size: {}.'.format(model.receptive_field_size))

# # .. and the loss
# loss = torch.distributions.StudentT
```

</div>
<div class="output_area" markdown="1">

    Number of model parameters: 122672.
    Receptive field size: 128.


</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
data = DataBunch(train_dl, test_dl).cuda()
learn = Learner(data, model, loss_func= F.mse_loss, opt_func= Adam, metrics=accuracy)
```

</div>

</div>
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
from fastai2.callback.all import *
learn.lr_find()
```

</div>
<div class="output_area" markdown="1">






    ---------------------------------------------------------------------------

    RuntimeError                              Traceback (most recent call last)

    <ipython-input-11-bd8b18fd11a5> in <module>
          1 from fastai2.callback.all import *
    ----> 2 learn.lr_find()
    

    ~/dev/fastai2/fastai2/callback/schedule.py in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot)
        195     n_epoch = num_it//len(self.dbunch.train_dl) + 1
        196     cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div)
    --> 197     with self.no_logging(): self.fit(n_epoch, cbs=cb)
        198     if show_plot: self.recorder.plot_lr_find()


    ~/dev/fastai2/fastai2/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
        286                     try:
        287                         self.epoch=epoch;          self('begin_epoch')
    --> 288                         self._do_epoch_train()
        289                         self._do_epoch_validate()
        290                     except CancelEpochException:   self('after_cancel_epoch')


    ~/dev/fastai2/fastai2/learner.py in _do_epoch_train(self)
        261         try:
        262             self.dl = self.dbunch.train_dl;                  self('begin_train')
    --> 263             self.all_batches()
        264         except CancelTrainException:                         self('after_cancel_train')
        265         finally:                                             self('after_train')


    ~/dev/fastai2/fastai2/learner.py in all_batches(self)
        239     def all_batches(self):
        240         self.n_iter = len(self.dl)
    --> 241         for o in enumerate(self.dl): self.one_batch(*o)
        242 
        243     def one_batch(self, i, b):


    ~/dev/fastai2/fastai2/learner.py in one_batch(self, i, b)
        245         try:
        246             self._split(b);                                  self('begin_batch')
    --> 247             self.pred = self.model(*self.xb);                self('after_pred')
        248             if len(self.yb) == 0: return
        249             self.loss = self.loss_func(self.pred, *self.yb); self('after_loss')


    ~/dev/env3.7/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
        539             result = self._slow_forward(*input, **kwargs)
        540         else:
    --> 541             result = self.forward(*input, **kwargs)
        542         for hook in self._forward_hooks.values():
        543             hook_result = hook(self, input, result)


    ~/dev/fastseq/fastseq/models/wavenet.py in forward(self, inputs)
        174     def forward(self, inputs):
        175         """Forward function."""
    --> 176         output, reg_e = self.encode(inputs)
        177         output_df, reg_d = self.decode(output)
        178 


    ~/dev/fastseq/fastseq/models/wavenet.py in encode(self, inputs)
        190         # Input layer
        191         output, res_conv_input = self.do_conv_input(inputs)
    --> 192         output = self.conv_input(output)
        193 
        194         # Loop over WaveNet layers and blocks


    ~/dev/env3.7/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
        539             result = self._slow_forward(*input, **kwargs)
        540         else:
    --> 541             result = self.forward(*input, **kwargs)
        542         for hook in self._forward_hooks.values():
        543             hook_result = hook(self, input, result)


    ~/dev/env3.7/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)
        200                             _single(0), self.dilation, self.groups)
        201         return F.conv1d(input, self.weight, self.bias, self.stride,
    --> 202                         self.padding, self.dilation, self.groups)
        203 
        204 


    RuntimeError: Expected object of scalar type Double but got scalar type Float for argument #2 'weight' in call to _thnn_conv2d_forward


</div>

</div>
