# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['TSeries', 'no_emp_dim', 'show_graph', 'test_graph_exists', 'show_graphs', 'TensorSeq', 'skip', 'ts_lists',
           'ToElapsed', 'make_interval', 'melted_ts_2_lists']

# Cell
from fastcore.all import *
from fastai2.basics import *
import pandas as pd

# Cell
class TSeries(TensorBase):pass

# Cell

def no_emp_dim(x):
    if len(x.shape)==1 :
        x = x[None,:]
    return np.vstack(x)

def show_graph(array, ax=None, figsize=None, title=None, ctx=None, tx=None, **kwargs):
    "Show an array on `ax`."
    # Handle pytorch axis order
    if hasattrs(array, ('data','cpu','permute')):
        array = array.data.cpu()
    elif not isinstance(array,np.ndarray):
        array=array(array)
    arrays = no_emp_dim(array)
    ax = ifnone(ax,ctx)
    if figsize is None: figsize = (5,5)
    if ax is None: _,ax = plt.subplots(figsize=figsize)
    tx = ifnone(tx,np.arange(arrays[0].shape[0]))
    for a, c in zip(arrays, ['b', 'c', 'm', 'y', 'k',]):
        ax.plot(tx, a, '-*'+c, **kwargs)

    if title is not None: ax.set_title(title)
#     ax.axis('off')
    return ax

# Cell
def test_graph_exists(ax):
    "Test there is a graph displayed in `ax`"
    assert ax

# Cell
@delegates(subplots)
def show_graphs(arrays, rows=1, titles=None, **kwargs):
    "Show all images `arrays` as subplots with `rows` using `titles`"
    cols = int(math.ceil(len(arrays)/rows))
    if titles is None: titles = [None]*len(arrays)
    axs = subplots(rows,cols,**kwargs)[1].flat
    for a,t,ax in zip(arrays, titles, axs):
        show_graph(a, ax=ax, title=t)

# Cell
class TensorSeq(TensorBase):
    def show(self, ctx=None, **kwargs):
        return show_graph(self, ctx=ctx, **kwargs)

# Cell
def skip(x,percentage = .9):
    if (np.random.rand() > percentage or x == 0):
        return False
    return True

# Cell
def ts_lists(ts:np.ndarray)-> L:
    """Transforms a `np.ndarray` of shape (timeseries, max_time) to a list of timeseries with shape (1,time).

    where:

    max_time = the length of the longest timeserie

    time = the length of the non-nan values of that specific timeserie
    """
    lst = L()
    for time_series in ts:
        lst.append(time_series[~np.isnan(time_series)][None,:])
    return lst

# Cell
class ToElapsed():
    changed = False
    def __call__(self, s):
        if pd.api.types.is_datetime64_any_dtype(s.dtype):
            self.changed = True
            return s.astype(np.int64) // 10 ** 9
        return s

    def decode(self, s):
        if self.changed:
            return pd.Series(pd.to_datetime(s *(10 ** 9)))
        return s


# Cell
def make_interval(
    df: pd.DataFrame,
    to_split_col:str='datetime',
    interval=3600,
    max_splits=100000,
    callback_error=None,
) -> L(pd.DataFrame):
    """Will check if column `to_split_col` in `df` has interval size of `interval`,
    if not will make it happen and return a list where this is done.

    This works both when type of `to_split_col` is numeric or `pd.Timestamp`

    """
    tmf = ToElapsed()
    df[to_split_col] = tmf(df[to_split_col])
    df.index = df[to_split_col]
    df = df.sort_index()
    index = df.index.to_numpy()
    df["delta"] = abs(
        (df[to_split_col] - df[to_split_col].shift(1))
    )
    mask = df["delta"] != interval
    starts = np.arange(len(mask))[mask]
    ends = list(starts[1:])+L(len(mask))

    del df["delta"]

    if len(ends) > max_splits:
        if callback_error:
            callback_error()
        raise Exception(
            f"number of splits {len(not_hour)} > {max_splits}: \n{not_hour}"
        )
#     print(starts,ends)
    dfs = L()
    for start, end in zip(starts, ends):
        _df = df.iloc[start: end,:]
        _df.loc[:,to_split_col] = tmf.decode(_df[to_split_col])
        dfs.append(_df)

    return dfs

# Cell
def melted_ts_2_lists(ts:pd.DataFrame, melted_col_name:str, fn=noop, **kwargs)->L:
    dfs = L()
    for c in set(ts[melted_col_name]):
        _df = ts[ts[melted_col_name] == c]
        r = fn(_df,**kwargs)
        dfs += r
    return dfs