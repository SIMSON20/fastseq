# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_data.load.ipynb (unless otherwise specified).

__all__ = ['pad_zeros', 'TSTensorSeq', 'TSTensorSeqy', 'TSTensorSeqyCreate', 'TSDataLoader']

# Cell
from ..core import *
from .external import *
from fastcore.utils import *
from fastcore.imports import *
from fastai2.basics import *
from fastai2.tabular.core import *
from .transforms import *

# Cell
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader

# Cell
def pad_zeros(X, lenght):
    return  np.pad(
                X,
                pad_width=((0, 0), (lenght - X.shape[-1], 0)),
                mode='constant',
                constant_values=0
            )

# Cell
class TSTensorSeq(TensorSeq): pass
class TSTensorSeqy(TensorSeq):

    @classmethod
    def create(cls, t)->None:
        "Convert an array or a list of points `t` to a `Tensor`"
        return cls(tensor(t).view(-1, 1).float())

    def show(self, ctx=None, **kwargs):
        if 'figsize' in kwargs:
            del kwargs['figsize']
        array=np.array(self.cpu())
        x_len = getattr(self._meta,'x_len',0)
        print(np.arange(x_len,x_len+len(array)), array)
        ctx.scatter(np.arange(x_len,x_len+len(array)), array, '-*r', **kwargs)
        return ctx

# Cell
TSTensorSeqyCreate = Transform(TSTensorSeqy.create)
TSTensorSeqyCreate.loss_func = MSELossFlat()
TSTensorSeqy.create = TSTensorSeqyCreate

# Cell
# TODO maybe incl. start where the last one ended and therefor keep hidden state
@delegates()
class TSDataLoader(TfmdDL):
    def __init__(self, time_series, horizon, lookback=72, step=1, bs=64,  num_workers=0, **kwargs):
        self.items, self.horizon, self.lookback, self.step = time_series, horizon, lookback, step
        self.make_ids()
        super().__init__(dataset=time_series, bs=bs, num_workers=num_workers, **kwargs)

    def make_ids(self):
        # Slice each time series into examples, assigning IDs to each
        last_id = 0
        n_dropped = 0
        self._ids = {}
        for i, ts in enumerate(self.items):
            if isinstance(ts,tuple):
                ts = ts[0] # no idea why they become tuples
            num_examples = (ts.shape[-1] - self.lookback - self.horizon + self.step) // self.step
            # Time series shorter than the forecast horizon need to be dropped.
            if ts.shape[-1] < self.horizon:
                n_dropped += 1
                continue
            # For short time series zero pad the input
            if ts.shape[-1] < self.lookback + self.horizon:
                num_examples = 1
            for j in range(num_examples):
                self._ids[last_id + j] = (i, j * self.step)
            last_id += num_examples

            # Inform user about time series that were too short
        if n_dropped > 0:
            print("Dropped {}/{} time series due to length.".format(
                    n_dropped, len(self.items)))
        # Store the number of training examples
        self.n = int(self._ids.__len__() )

    def get_id(self,idx):
        # Get time series
        ts_id, lookback_id = self._ids[idx]
        ts = self.items[ts_id]
        if isinstance(ts,tuple):
            ts = ts[0] # no idea why they become tuples
        # Prepare input and target. Zero pad if necessary.
        if ts.shape[-1] < self.lookback + self.horizon:
            # If the time series is too short, we zero pad
            x = ts[:, :-self.horizon]
            x = np.pad(
                x,
                pad_width=((0, 0), (self.lookback - x.shape[-1], 0)),
                mode='constant',
                constant_values=0
            )
            y = ts[:,-self.horizon:]
        else:
            x = ts[:,lookback_id:lookback_id + self.lookback]
            y = ts[:,lookback_id + self.lookback:lookback_id + self.lookback + self.horizon]
        return x, y

    def shuffle_fn(self, idxs):
        self.items.shuffle()
        return idxs

    def create_item(self, idx):
        if idx>=self.n: raise IndexError
        x, y = self.get_id(idx)
        return TSTensorSeq(x),TSTensorSeqy(y)


# Cell
# @patch
# def truncate(self:TitledStr, n):
#     words = self.split(' ')[:n]
#     return TitledStr(' '.join(words))
# @typedispatch
# def show_batch(x:TensorImage, y:TensorImage, samples, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):
#     if ctxs is None: ctxs = get_grid(min(len(samples), max_n), rows=rows, cols=cols, add_vert=1, figsize=figsize)
#     ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)
#     return ctxs

from fastai2.vision.data import *

@typedispatch
def show_batch(x: TensorSeq, y, samples, ctxs=None, max_n=10,rows=None, cols=None, figsize=None, **kwargs):
    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), rows=rows, cols=cols, add_vert=1, figsize=figsize)
    ctxs = show_batch[object](x, y=y, samples=samples, ctxs=ctxs, max_n=max_n, **kwargs)
    return ctxs

@typedispatch
def show_batch(x: TSTensorSeq, y: TSTensorSeq, samples, ctxs=None, max_n=10, **kwargs):
    print(samples[0][0].shape,samples[0][1].shape, x.shape, y.shape,type(samples[0]))
    return TSTensorxy.show_batch(samples, ctxs=ctxs, max_n=max_n, **kwargs)
# show_batch[TSTensorSeq](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)
