# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/050_nbeats.models_multi.ipynb (unless otherwise specified).

__all__ = ['make_base_rnn', 'DependentModel', 'DependentBlock', 'NBeatsMNet']

# Cell
from fastcore.utils import *
from fastcore.imports import *
from fastai2.basics import *
from fastai2.callback.hook import num_features_model
from fastai2.callback.all import *
from fastai2.layers import *
from fastai2.torch_core import *
from torch.autograd import Variable
from ..all import *
from .model import *

# Cell
# TODO
def make_base_rnn(u_in, layers, use_bn, ps):
    pass

# Cell
class DependentModel(object):
    """Returns the result of polynominal function on the dependent variable."""
    def __init__(self, norm=True):
        self.norm = norm

    def __call__(self, thetas, t, *args):
        p = thetas.size()[-1]
        t = (t - t.mean())/t.std()
        thetas = thetas.flatten()
        assert p < 6, f"thetas_dim is too big. p = {p}"
        S = [(t*thetas[i]**i)[None,:] for i in range(p)]
        o = torch.cat(S).sum(0)
        return o

# Cell
class DependentBlock(Block):
    def __init__(
        self, layers:L, thetas_dim:int, device, lookback=10, horizon=5, use_bn=True, norm = True,
            bn_final=False, ps:L=None, share_thetas=True, y_range=[-.5,.5], att=True, scale_exp = 2, stand_alone=False, base = None, **kwargs
    ):
        store_attr(self,"y_range,device,layers,thetas_dim,use_bn,ps,lookback,horizon,bn_final,share_thetas,att,stand_alone,base" )
        self.scale = 1*scale_exp**-(torch.arange(float(self.thetas_dim))).to(self.device)
        super().__init__(DependentModel(norm))
        self.to(device)

    def forward(self,x, xts, *args):
        if self.stand_alone:
            dct = super().forward(x[:,0,:], xts[:,0,self.lookback:], xts[:,0,:self.lookback])
            return torch.cat([dct['b'][:,None,:], dct['f'][:,None,:]],dim=-1)
        else:
            return super().forward(x, t[self.lookback:], t[:self.lookback])

# Cell

# not pritty but still works better
def _select_block(o):
    if isinstance(o,int):
        if o == 0:
            return SeasonalityBlock
        elif o == 1:
            return TrendBlock
        elif o == 2:
            return BaisBlock
        else:
            return GenericBlock
    else:
        if o == 'seasonality':
            return SeasonalityBlock
        elif o == 'trend':
            return TrendBlock
        elif o =='bias':
            return BiasBlock
        else:
            return GenericBlock

_default_thetas={'seasonality':6,'trend':4,'bais':2}

# Cell
class NBeatsMNet(Module):
    def __init__(
        self,
        device,
        stack_types=('trend', 'seasonality'),
        nb_blocks_per_stack=3,
        horizon=5,
        lookback=10,
        thetas_dim=None,
        share_weights_in_layers=True,
        layers= [1024,512],
        norm=False,
        **kwargs,
    ):
        thetas_dim = ifnone(thetas_dim,[_default_thetas[o] for o in L(stack_types)])
        stack_types= L(stack_types)
        self.eps, self.m, self.s = Variable(tensor(1e-7), requires_grad=False).to(device),Variable(tensor(1e-7), requires_grad=True).to(device),Variable(tensor(1e-7), requires_grad=True).to(device)
        store_attr(self,'device,horizon,lookback,layers,nb_blocks_per_stack,share_weights_in_layers,stack_types,thetas_dim,device,norm,kwargs')
        self.stacks = []
        self._str = "| N-Beats\n"

        self.bn = BatchNorm(lookback, ndim=2)
        stacks = OrderedDict()
        self.base = None
        if self.share_weights_in_layers:
            self.base = make_base(self.lookback, self.layers, True, None)
        for stack_id in range(len(self.stack_types)):
            stacks[str(self.stack_types[stack_id]) + str(stack_id)] = self.create_stack(stack_id)
        self.stacks = nn.Sequential(stacks)

    def create_stack(self, stack_id):
        stack_type = self.stack_types[stack_id]
        self._str += f"| --  Stack {stack_type.title()} (#{stack_id}) (share_weights_in_stack={self.share_weights_in_layers})\n"

        blocks = []
        for thetas_dim in range(3,self.thetas_dim[stack_id]+1):
            block_init = _select_block(stack_type)
            block = block_init(
                layers = self.layers,
                thetas_dim = thetas_dim,
                device = self.device,
                lookback = self.lookback,
                horizon = self.horizon,
                base = self.base,
                **self.kwargs
                )
            self._str += f"     | -- {block}\n"
            blocks.append(block)

        return nn.Sequential(*blocks)

    def iter_blocks(self):
        for stack_id, names in enumerate(self.stacks.named_children()):
            name = names[0]
            for block_id in range(len(self.stacks[stack_id])):
                yield name, stack_id, block_id, self.stacks[stack_id][block_id]

    def forward(self, x):
        self.dct = None
        if self.norm:
            self.m, self.s = torch.mean(x,-1,keepdim=True), x.std(-1,keepdim=True) + self.eps
            x = (x-self.m)/self.s
#             print('requires_grad',x.requires_grad)

        backcast_res = x.view([-1,x.shape[-1]])
        backcast = torch.zeros(
            size=(backcast_res.size()[0], self.lookback,)
        )
        forecast = torch.zeros(
            size=(backcast.size()[0], self.horizon,)
        )  # maybe batch size here.

        dct = defaultdict(dict)
        for stack_id, names in enumerate(self.stacks.named_children()):
            name = names[0]
            for block_id in range(len(self.stacks[stack_id])):
                _dct = self.stacks[stack_id][block_id](backcast_res)
                backcast_res = backcast_res.to(self.device) - _dct['b']

                backcast = backcast.to(self.device) + _dct['b']
                forecast = forecast.to(self.device) + _dct['f']
                _dct['_full'] = torch.cat([_dct['b'] , _dct['f']], dim=-1)
                dct[name+'_'+str(block_id)] = _dct

        dct['f'] = forecast[:,None,:]
        dct['b'] = backcast[:,None,:]
        self.dct = dct
        res = torch.cat([backcast[:,None,:], forecast[:,None,:]], dim=-1)
        if self.norm:
            return (res*self.s)+self.m
        return res

    def __setattr__(self, key, value):
        if key in ['lookback','horizon']:
            if hasattr(self,'stacks'):
                for name, stack_id, block_id, stack in self.iter_blocks():
                    setattr(stack, key, value)
        super().__setattr__(key, value)