# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/06_models.dnn.ipynb (unless otherwise specified).

__all__ = ['DNN', 'dnn_learner']

# Cell
from fastcore.utils import *
from fastcore.imports import *
from fastai2.basics import *
from fastai2.callback.hook import num_features_model
from fastai2.callback.all import *

# Cell
class DNN(torch.nn.Module):
    """Implements a simple `DNN` architecture for time series forecasting. Inherits
    from pytorch `Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_.

    Arguments:
        * input_channels (int): Number of covariates in input time series.
        * output_channels (int): Number of target time series.
        * horizon (int): Number of time steps to forecast.
        * lookback (int): Number of time steps to lookback.
        * hidden_channels (int): Number of channels in convolutional hidden layers.
        * p_dropout (float): Probality of dropout.
    """
    split = -1
    def __init__(self,
                 input_channels,
                 output_channels,
                 horizon,
                 lookback,
                 hidden_channels=64,
                 p_dropout=.2,
                 ks=3,
                ):
        """Inititalize variables."""
        super(DNN, self).__init__()
        self.output_channels = output_channels
        self.horizon = horizon
        self.hidden_channels = hidden_channels

        # Set up first layer for input
        conv_input = ConvLayer(input_channels, hidden_channels//4, ks=ks, ndim=1, stride = 2)
        conv_2 = ConvLayer(hidden_channels//4, hidden_channels//2, ks=ks, ndim=1, stride = 2)
        conv_3 = ConvLayer(hidden_channels//2, hidden_channels, ks=ks, ndim=1, stride = 2)
#         adaptive_pool()
        # Set up nonlinear output layers
        self.body = nn.Sequential(conv_input,conv_2, conv_3, Flatten())
        out = int((hidden_channels/8)*lookback)
        self.dnn = LinBnDrop(out,horizon*output_channels)

    def forward(self, inputs):
        """Forward function."""
        hid = self.body(inputs.float())
        out= self.dnn(hid).view(hid.size(0),self.output_channels,-1).float()
        return out

    @property
    def n_parameters(self):
        """Returns the number of model parameters."""
        par = list(self.parameters())
        s = sum([np.prod(list(d.size())) for d in par])
        return s


# Cell
from fastai2.basics import *
from ..all import *

@delegates(DNN.__init__)
def dnn_learner(dbunch, output_channels=None, metrics=None, **kwargs):
    "Build a dnn style learner"
    output_channels = ifnone(output_channels,dbunch.train[0][0].shape[0])

    model = DNN(input_channels=dbunch.train[0][0].shape[0],
        output_channels=output_channels,
        horizon = dbunch.train_dl.horizon,
        lookback = dbunch.train_dl.lookback,
        **kwargs
       )

    learn = Learner(dbunch, model, loss_func=F.mse_loss, opt_func= Adam, metrics=L(metrics)+L(mae, smape))
    return learn